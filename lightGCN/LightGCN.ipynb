{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install all required packages"
      ],
      "metadata": {
        "id": "3vj6qFkCK7Ll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "CSJq-IvKKtua",
        "outputId": "cafa7fea-3e32-4978-b1f2-ad120349a148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.5.0\n",
            "  Downloading matplotlib-3.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (21.3)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (7.1.2)\n",
            "Collecting setuptools-scm>=4\n",
            "  Downloading setuptools_scm-7.0.5-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 476 kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib==3.5.0) (57.4.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib==3.5.0) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from setuptools-scm>=4->matplotlib==3.5.0) (4.4.0)\n",
            "Installing collected packages: setuptools-scm, fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed fonttools-4.38.0 matplotlib-3.5.0 setuptools-scm-7.0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install matplotlib==3.5.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.__version__\n",
        "assert matplotlib.__version__ == '3.5.0' # if this fails, makes sure you ran the matplotlib installation above AND restarted your runtime"
      ],
      "metadata": {
        "id": "B1VWftyDLAU7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install torch-scatter -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "pip install torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "pip install torch-geometric\n",
        "pip install torch-cluster -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "pip install torch-spline-conv -f https://data.pyg.org/whl/torch-1.13.0+cu116.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1vwltDgLDH4",
        "outputId": "7087e690-669c-4333-f963-866f9d593c6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.15%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.21.6)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.15+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric) (1.0.2)\n",
            "Collecting psutil>=5.8.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 62.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773302 sha256=a0347671956cc8b559f241fcd508299ca5a3055c5d29200410469de0559ec8c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/a3/20/198928106d3169865ae73afcbd3d3d1796cf6b429b55c65378\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: psutil, torch-geometric\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed psutil-5.9.4 torch-geometric-2.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.21.6)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_spline_conv-1.2.1%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (873 kB)\n",
            "\u001b[K     |████████████████████████████████| 873 kB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.1+pt113cu116\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric import seed_everything\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import degree\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation, rc\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import HTML\n",
        "import networkx as nx\n",
        "from networkx.algorithms import bipartite\n",
        "\n",
        "seed_everything(5) # set random seed"
      ],
      "metadata": {
        "id": "dqDjvFPJLOHv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlainData(Data):\n",
        "    \"\"\"\n",
        "    Custom Data class for use in PyG. Basically the same as the original Data class from PyG, but\n",
        "    overrides the __inc__ method because otherwise the DataLoader was incrementing indices unnecessarily.\n",
        "    Now it functions more like the original DataLoader from PyTorch itself.\n",
        "    See here for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html\n",
        "    \"\"\"\n",
        "    def __inc__(self, key, value, *args, **kwargs):\n",
        "        return 0\n",
        "\n",
        "class BIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset object containing the supervision/evaluation edges. This will be used by the DataLoader to load\n",
        "    batches of edges to calculate loss or evaluation metrics on. Here, get(idx) will return ALL outgoing edges of the graph\n",
        "    corresponding to playlist \"idx.\" This is because when calculating metrics such as recall@k, we need all of the\n",
        "    user's positive edges in the same batch.\n",
        "    \"\"\"\n",
        "    def __init__(self, root, edge_index, transform=None, pre_transform=None):\n",
        "        self.edge_index = edge_index\n",
        "        self.unique_idxs = torch.unique(edge_index[0,:]).tolist() # playlists will all be in row 0, b/c sorted by RandLinkSplit\n",
        "        self.num_nodes = len(self.unique_idxs)\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "    def len(self):\n",
        "        return self.num_nodes\n",
        "\n",
        "    def get(self, idx): # returns all outgoing edges associated with playlist idx\n",
        "        edge_index = self.edge_index[:, self.edge_index[0,:] == idx]\n",
        "        return PlainData(edge_index=edge_index)"
      ],
      "metadata": {
        "id": "8EpmGYnYLRhQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"\n",
        "    A single LightGCN layer. Extends the MessagePassing class from PyTorch Geometric\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(LightGCN, self).__init__(aggr='add') # aggregation function is 'add\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        \"\"\"\n",
        "        Specifies how to perform message passing during GNN propagation. For LightGCN, we simply pass along each\n",
        "        source node's embedding to the target node, normalized by the normalization term for that node.\n",
        "        args:\n",
        "          x_j: node embeddings of the neighbor nodes, which will be passed to the central node (shape: [E, emb_dim])\n",
        "          norm: the normalization terms we calculated in forward() and passed into propagate()\n",
        "        returns:\n",
        "          messages from neighboring nodes j to central node i\n",
        "        \"\"\"\n",
        "        # Here we are just multiplying the x_j's by the normalization terms (using some broadcasting)\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Performs the LightGCN message passing/aggregation/update to get updated node embeddings\n",
        "\n",
        "        args:\n",
        "          x: current node embeddings (shape: [N, emb_dim])\n",
        "          edge_index: message passing edges (shape: [2, E])\n",
        "        returns:\n",
        "          updated embeddings after this layer\n",
        "        \"\"\"\n",
        "        # Computing node degrees for normalization term in LightGCN (see LightGCN paper for details on this normalization term)\n",
        "        # These will be used during message passing, to normalize each neighbor's embedding before passing it as a message\n",
        "        row, col = edge_index\n",
        "        deg = degree(col)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Begin propagation. Will perform message passing and aggregation and return updated node embeddings.\n",
        "        return self.propagate(edge_index, x=x, norm=norm)"
      ],
      "metadata": {
        "id": "EFWv7GcNLklE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Overall graph neural network. Consists of learnable user/item embeddings\n",
        "    and LightGCN layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim, num_nodes, num_start, num_layers):\n",
        "        super(GNN, self).__init__()\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_nodes = num_nodes         # total number of nodes (users + items / items + sellers) in dataset\n",
        "        self.num_start = num_start # total number of users/items in dataset\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Initialize embeddings for all users and items / items and sellers. Users/Items will have indices from 0...num_users/num_items-1,\n",
        "        # items/sellers will have indices from num_users/num_items...num_nodes-1\n",
        "        self.embeddings = torch.nn.Embedding(num_embeddings=self.num_nodes, embedding_dim=self.embedding_dim)\n",
        "        torch.nn.init.normal_(self.embeddings.weight, std=0.1)\n",
        "\n",
        "        self.layers = torch.nn.ModuleList() # LightGCN layers\n",
        "        for _ in range(self.num_layers):\n",
        "            self.layers.append(LightGCN())\n",
        "\n",
        "        self.sigmoid = torch.sigmoid\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError(\"forward() has not been implemented for the GNN class. Do not use\")\n",
        "\n",
        "    def gnn_propagation(self, edge_index_mp):\n",
        "        \"\"\"\n",
        "        Performs the linear embedding propagation (using the LightGCN layers) and calculates final (multi-scale) embeddings\n",
        "        for each user/item, which are calculated as a weighted sum of that user/item's embeddings at each layer (from\n",
        "        0 to self.num_layers). Technically, the weighted sum here is the average, which is what the LightGCN authors recommend.\n",
        "\n",
        "        args:\n",
        "          edge_index_mp: a tensor of all (undirected) edges in the graph, which is used for message passing/propagation and\n",
        "              calculating the multi-scale embeddings. (In contrast to the evaluation/supervision edges, which are distinct\n",
        "              from the message passing edges and will be used for calculating loss/performance metrics).\n",
        "        returns:\n",
        "          final multi-scale embeddings for all users/items\n",
        "        \"\"\"\n",
        "        x = self.embeddings.weight        # layer-0 embeddings\n",
        "\n",
        "        x_at_each_layer = [x]             # stores embeddings from each layer. Start with layer-0 embeddings\n",
        "        for i in range(self.num_layers):  # now performing the GNN propagation\n",
        "            x = self.layers[i](x, edge_index_mp)\n",
        "            x_at_each_layer.append(x)\n",
        "        final_embs = torch.stack(x_at_each_layer, dim=0).mean(dim=0) # take average to calculate multi-scale embeddings\n",
        "        return final_embs\n",
        "\n",
        "    def predict_scores(self, edge_index, embs):\n",
        "        \"\"\"\n",
        "        Calculates predicted scores for each user/item and item/seller pair in the list of edges. Uses dot product of their embeddings.\n",
        "\n",
        "        args:\n",
        "          edge_index: tensor of edges (between users and items/ items and seller) whose scores we will calculate.\n",
        "          embs: node embeddings for calculating predicted scores (typically the multi-scale embeddings from gnn_propagation())\n",
        "        returns:\n",
        "          predicted scores for each user/item and item/seller pair in edge_index\n",
        "        \"\"\"\n",
        "        scores = embs[edge_index[0,:], :] * embs[edge_index[1,:], :] # taking dot product for each playlist/song pair\n",
        "        scores = scores.sum(dim=1)\n",
        "        scores = self.sigmoid(scores)\n",
        "        return scores\n",
        "\n",
        "    def calc_loss(self, data_mp, data_pos, data_neg):\n",
        "        \"\"\"\n",
        "        The main training step. Performs GNN propagation on message passing edges, to get multi-scale embeddings.\n",
        "        Then predicts scores for each training example, and calculates Bayesian Personalized Ranking (BPR) loss.\n",
        "\n",
        "        args:\n",
        "          data_mp: tensor of edges used for message passing / calculating multi-scale embeddings\n",
        "          data_pos: set of positive edges that will be used during loss calculation\n",
        "          data_neg: set of negative edges that will be used during loss calculation\n",
        "        returns:\n",
        "          loss calculated on the positive/negative training edges\n",
        "        \"\"\"\n",
        "        # Perform GNN propagation on message passing edges to get final embeddings\n",
        "        final_embs = self.gnn_propagation(data_mp.edge_index)\n",
        "\n",
        "        # Get edge prediction scores for all positive and negative evaluation edges\n",
        "        pos_scores = self.predict_scores(data_pos.edge_index, final_embs)\n",
        "        neg_scores = self.predict_scores(data_neg.edge_index, final_embs)\n",
        "        print('pos_score: ' + str(torch.mean(pos_scores)))\n",
        "        print('neg_score: ' + str(torch.mean(neg_scores)))\n",
        "\n",
        "        # Calculate loss (using variation of Bayesian Personalized Ranking loss, similar to the one used in official\n",
        "        # LightGCN implementation at https://github.com/gusye1234/LightGCN-PyTorch/blob/master/code/model.py#L202)\n",
        "        loss = -torch.log(self.sigmoid(pos_scores - neg_scores)).mean()\n",
        "        return loss\n",
        "\n",
        "    def evaluation(self, data_mp, data_pos, k,  flag = 1):\n",
        "        \"\"\"\n",
        "        Performs evaluation on validation or test set. Calculates recall@k.\n",
        "\n",
        "        args:\n",
        "          data_mp: message passing edges to use for propagation/calculating multi-scale embeddings\n",
        "          data_pos: positive edges to use for scoring metrics. Should be no overlap between these edges and data_mp's edges\n",
        "          k: value of k to use for recall@k\n",
        "        returns:\n",
        "          dictionary mapping playlist ID -> recall@k on that playlist\n",
        "        \"\"\"\n",
        "        # Run propagation on the message-passing edges to get multi-scale embeddings\n",
        "        final_embs = self.gnn_propagation(data_mp.edge_index)\n",
        "\n",
        "        # Get embeddings of all unique users/items in the batch of evaluation edges\n",
        "        unique_start = torch.unique_consecutive(data_pos.edge_index[0,:])\n",
        "        start_emb = final_embs[unique_start, :] # has shape [number of users/items in batch, 64]\n",
        "        \n",
        "        # Get embeddings of ALL items/sellers in dataset\n",
        "        end_emb = final_embs[self.num_start:, :] # has shape [total number of items/sellers in dataset, 64]\n",
        "\n",
        "        # All ratings for each user/item in batch to each item/seller in entire dataset (using dot product as the scoring function)\n",
        "        ratings = self.sigmoid(torch.matmul(start_emb, end_emb.t())) \n",
        "\n",
        "        # Calculate recall@k\n",
        "        result,result_2 = recall_at_k(ratings.cpu(), k, self.num_start, data_pos.edge_index.cpu(), \n",
        "                             unique_start.cpu(), data_mp.edge_index.cpu(),flag = flag)\n",
        "        return result,result_2 "
      ],
      "metadata": {
        "id": "Ab-aNdfiLu07"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(all_ratings, k, num_start, ground_truth, unique_start, data_mp, flag):\n",
        "   \"\"\"\n",
        "   Calculates recall@k during validation/testing for a single batch.\n",
        "\n",
        "   args:\n",
        "     all_ratings: array of shape \n",
        "     k: the value of k to use for recall@k\n",
        "     num_start: the number of start in the dataset\n",
        "     ground_truth: array of shape [2, X] where each column is a pair of (buyer/item_idx, positive item/seller idx). This is the\n",
        "        batch that we are calculating metrics on.\n",
        "     unique_start: 1D vector of length [number of users/items in batch], which specifies which user/item corresponds\n",
        "        to each row of all_ratings\n",
        "     data_mp: an array of shape [2, Y]. This is all of the known message-passing edges. We will use this to make sure we\n",
        "        don't recommend items/sellers that are already known.\n",
        "  \n",
        "   \"\"\"\n",
        "   # We don't want to recommend items/sellers that are already known\n",
        "   # Set those to a low rating so they won't be recommended\n",
        "   known_edges = data_mp[:, data_mp[0,:] < num_start] # removing duplicate edges (since data_mp is undirected). also makes it so\n",
        "                                                          # that for each column, start idx is in row 0 and song idx is in row 1\n",
        "   start_to_idx_in_batch = {start: i for i, start in enumerate(unique_start.tolist())}\n",
        "   exclude_start, exclude_end = [], [] # already-known links. Don't want to recommend these again\n",
        "   for i in range(known_edges.shape[1]): # looping over all known edges\n",
        "      st, end = known_edges[:,i].tolist()\n",
        "      if st in start_to_idx_in_batch: # don't need the edges in data_mp that are from start that are not in this batch\n",
        "         exclude_start.append(start_to_idx_in_batch[st])\n",
        "         exclude_end.append(end - num_start) # subtract num_start to get indexing into all_ratings correct\n",
        "   if flag:\n",
        "      all_ratings[exclude_start, exclude_end] = -10000 # setting to a very low score so they won't be recommended\n",
        "   \n",
        "   # Get top k recommendations for each start\n",
        "   rate, top_k = torch.topk(all_ratings, k=k, dim=1)\n",
        "   top_k += num_start # topk returned indices of end in ratings, which doesn't include start.\n",
        "                          # Need to shift up by num_start to get the actual end indices\n",
        "    \n",
        "   # Calculate recall@k\n",
        "   ret = {}\n",
        "   # record exact indices\n",
        "   ret_2 = defaultdict(list)\n",
        "   for i, start in enumerate(unique_start):\n",
        "      pos_end = ground_truth[1, ground_truth[0, :] == start]\n",
        "\n",
        "      k_recs = top_k[i, :] # top k recommendations for start\n",
        "    \n",
        "      ret_2[start].append({'ground_truth':pos_end.numpy()})\n",
        "      ret_2[start].append({'top_k':k_recs.numpy()})\n",
        "      recall = len(np.intersect1d(pos_end, k_recs)) / len(pos_end)\n",
        "      ret[start] = recall\n",
        "   return ret, ret_2"
      ],
      "metadata": {
        "id": "sGYdbPunNiVm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_negative_edges(batch, num_start, num_nodes):\n",
        "    # Randomly samples end for each start. Here we sample 1 negative edge \n",
        "    # for each positive edge in the graph, so we will\n",
        "    # end up having a balanced 1:1 ratio of positive to negative edges.\n",
        "    negs = []\n",
        "    for i in batch.edge_index[0,:]:  # looping over start\n",
        "        assert i < num_start     # just ensuring that i is a start\n",
        "        rand = torch.randint(num_start, num_nodes, (1,))  # randomly sample an end\n",
        "        negs.append(rand.item())\n",
        "    edge_index_negs = torch.row_stack([batch.edge_index[0,:], torch.LongTensor(negs)])\n",
        "    return Data(edge_index=edge_index_negs)"
      ],
      "metadata": {
        "id": "PebPJ6_5PWxK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_mp, loader, opt, num_start, num_nodes, device):\n",
        "    \"\"\"\n",
        "    Main training loop\n",
        "\n",
        "    args:\n",
        "       model: the GNN model\n",
        "       data_mp: message passing edges to use for performing propagation/calculating multi-scale embeddings\n",
        "       loader: DataLoader that loads in batches of supervision/evaluation edges\n",
        "       opt: the optimizer\n",
        "       num_start: the number of start in the entire dataset\n",
        "       num_nodes: the number of nodes (start + end) in the entire dataset\n",
        "       device: whether to run on CPU or GPU\n",
        "    returns:\n",
        "       the training loss for this epoch\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "    model.train()\n",
        "    for batch in loader:\n",
        "        del batch.batch; del batch.ptr # delete unwanted attributes\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        negs = sample_negative_edges(batch, num_start, num_nodes)  # sample negative edges\n",
        "        data_mp, batch, negs = data_mp.to(device), batch.to(device), negs.to(device)\n",
        "        loss = model.calc_loss(data_mp, batch, negs)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        num_examples = batch.edge_index.shape[1]\n",
        "        total_loss += loss.item() * num_examples\n",
        "        total_examples += num_examples\n",
        "    avg_loss = total_loss / total_examples\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "0LTkG3cyPl8H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_mp, loader, k, device, save_dir, epoch,flag =1):\n",
        "    \"\"\"\n",
        "    Evaluation loop for validation/testing.\n",
        "\n",
        "    args:\n",
        "       model: the GNN model\n",
        "       data_mp: message passing edges to use for propagation/calculating multi-scale embeddings\n",
        "       loader: DataLoader that loads in batches of evaluation (i.e., validation or test) edges\n",
        "       k: value of k to use for recall@k\n",
        "       device: whether to use CPU or GPU\n",
        "       save_dir: directory to save multi-scale embeddings for later analysis. If None, doesn't save any embeddings.\n",
        "       epoch: the number of the current epoch\n",
        "    returns:\n",
        "       recall@k for this epoch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_recalls = {}\n",
        "    with torch.no_grad():\n",
        "        # Save multi-scale embeddings if save_dir is not None\n",
        "        data_mp = data_mp.to(device)\n",
        "        if save_dir is not None:\n",
        "            embs_to_save = model.gnn_propagation(data_mp.edge_index)\n",
        "            torch.save(embs_to_save, os.path.join(save_dir, f\"embeddings_epoch_{epoch}.pt\"))\n",
        "\n",
        "        # Run evaluation\n",
        "        result_2 = {}\n",
        "        for batch in loader:\n",
        "            del batch.batch; del batch.ptr # delete unwanted attributes\n",
        "            batch = batch.to(device)\n",
        "            recalls,res_2 = model.evaluation(data_mp, batch, k,flag)\n",
        "            result_2.update(res_2)\n",
        "            for start_idx in recalls:\n",
        "                assert start_idx not in all_recalls\n",
        "            all_recalls.update(recalls)\n",
        "    recall_at_k = np.mean(list(all_recalls.values()))\n",
        "    return recall_at_k,result_2"
      ],
      "metadata": {
        "id": "K6ik91oPPy9i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "VQOSofpDQEK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \".\"\n",
        "data_bi = torch.load(os.path.join(base_dir, \"buyer_item.pt\"))\n",
        "data_is = torch.load(os.path.join(base_dir, \"item_seller.pt\"))"
      ],
      "metadata": {
        "id": "WxIS5r-0QFiu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_bi)\n",
        "print(data_is)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFi-S-HuQLeF",
        "outputId": "930f3653-4c5c-482a-89d9-b8c582e443fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 49764], edge_attr=[49764, 1], num_nodes=12041)\n",
            "Data(edge_index=[2, 33266], edge_attr=[33266, 1], num_nodes=7175)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Val Test Split"
      ],
      "metadata": {
        "id": "TXWrOTlJQPk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val/test split 0.7 0.15 0.15\n",
        "transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False, neg_sampling_ratio=0,\n",
        "                            num_val=0.15, num_test=0.15)\n",
        "\n",
        "train_split_bi, val_split_bi, test_split_bi = transform(data_bi)\n",
        "# Confirm that every node appears in every set above\n",
        "assert train_split_bi.num_nodes == val_split_bi.num_nodes and train_split_bi.num_nodes == test_split_bi.num_nodes\n",
        "\n",
        "train_split_is, val_split_is, test_split_is = transform(data_is)\n",
        "# Confirm that every node appears in every set above\n",
        "assert train_split_is.num_nodes == val_split_is.num_nodes and train_split_is.num_nodes == test_split_is.num_nodes"
      ],
      "metadata": {
        "id": "GmkyemPzQSMG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val/test split 0.5 0 0.5\n",
        "transform = RandomLinkSplit(is_undirected=True, add_negative_train_samples=False, neg_sampling_ratio=0,\n",
        "                            num_val=0, num_test=0.5)\n",
        "\n",
        "train_split_bi_55, val_split_bi_55, test_split_bi_55 = transform(data_bi)\n",
        "# Confirm that every node appears in every set above\n",
        "assert train_split_bi_55.num_nodes == val_split_bi_55.num_nodes and train_split_bi_55.num_nodes == test_split_bi_55.num_nodes\n",
        "\n",
        "train_split_is_55, val_split_is_55, test_split_is_55 = transform(data_is)\n",
        "# Confirm that every node appears in every set above\n",
        "assert train_split_is_55.num_nodes == val_split_is_55.num_nodes and train_split_is_55.num_nodes == test_split_is_55.num_nodes"
      ],
      "metadata": {
        "id": "2BmytLtvQ02H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_split_bi)\n",
        "print(val_split_bi)\n",
        "print(test_split_bi)\n",
        "print(train_split_is)\n",
        "print(val_split_is)\n",
        "print(test_split_is)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bokxOMkMRLD0",
        "outputId": "fb560b58-b8f0-4829-ce48-5506a383b48a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 34836], edge_attr=[34836, 1], num_nodes=12041, edge_label=[17418], edge_label_index=[2, 17418])\n",
            "Data(edge_index=[2, 34836], edge_attr=[34836, 1], num_nodes=12041, edge_label=[3732], edge_label_index=[2, 3732])\n",
            "Data(edge_index=[2, 42300], edge_attr=[42300, 1], num_nodes=12041, edge_label=[3732], edge_label_index=[2, 3732])\n",
            "Data(edge_index=[2, 23290], edge_attr=[23290, 1], num_nodes=7175, edge_label=[11645], edge_label_index=[2, 11645])\n",
            "Data(edge_index=[2, 23290], edge_attr=[23290, 1], num_nodes=7175, edge_label=[2494], edge_label_index=[2, 2494])\n",
            "Data(edge_index=[2, 28278], edge_attr=[28278, 1], num_nodes=7175, edge_label=[2494], edge_label_index=[2, 2494])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_split_bi_55)\n",
        "print(val_split_bi_55)\n",
        "print(test_split_bi_55)\n",
        "print(train_split_is_55)\n",
        "print(val_split_is_55)\n",
        "print(test_split_is_55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNX0BS3pRPF5",
        "outputId": "6ef45136-9596-46cf-d924-3defb61a995f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(edge_index=[2, 24882], edge_attr=[24882, 1], num_nodes=12041, edge_label=[12441], edge_label_index=[2, 12441])\n",
            "Data(edge_index=[2, 24882], edge_attr=[24882, 1], num_nodes=12041, edge_label=[0], edge_label_index=[2, 0])\n",
            "Data(edge_index=[2, 24882], edge_attr=[24882, 1], num_nodes=12041, edge_label=[12441], edge_label_index=[2, 12441])\n",
            "Data(edge_index=[2, 16634], edge_attr=[16634, 1], num_nodes=7175, edge_label=[8317], edge_label_index=[2, 8317])\n",
            "Data(edge_index=[2, 16634], edge_attr=[16634, 1], num_nodes=7175, edge_label=[0], edge_label_index=[2, 0])\n",
            "Data(edge_index=[2, 16634], edge_attr=[16634, 1], num_nodes=7175, edge_label=[8316], edge_label_index=[2, 8316])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# process splited Data format \n",
        "def pro_split_data(split_data):\n",
        "  ev = BIDataset('temp', edge_index=split_data.edge_label_index)\n",
        "  mp = Data(edge_index=split_data.edge_index)\n",
        "  return ev, mp"
      ],
      "metadata": {
        "id": "yzjD1sfKRYv1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buyer - item 0.7 0.15 0.15\n",
        "train_ev_bi,train_mp_bi = pro_split_data(train_split_bi)\n",
        "val_ev_bi,val_mp_bi = pro_split_data(val_split_bi)\n",
        "test_ev_bi,test_mp_bi = pro_split_data(test_split_bi)\n",
        "# item - seller 0.7 0.15 0.15\n",
        "train_ev_is,train_mp_is = pro_split_data(train_split_is)\n",
        "val_ev_is,val_mp_is = pro_split_data(val_split_is)\n",
        "test_ev_is,test_mp_is = pro_split_data(test_split_is)\n",
        "# buyer - item 0.5 0 0.5\n",
        "train_ev_bi_55,train_mp_bi_55 = pro_split_data(train_split_bi_55)\n",
        "val_ev_bi_55,val_mp_bi_55 = pro_split_data(val_split_bi_55)\n",
        "test_ev_bi_55,test_mp_bi_55 = pro_split_data(test_split_bi_55)\n",
        "# item - seller 0.5 0 0.5\n",
        "train_ev_is_55,train_mp_is_55 = pro_split_data(train_split_is_55)\n",
        "val_ev_is_55,val_mp_is_55 = pro_split_data(val_split_is_55)\n",
        "test_ev_is_55,test_mp_is_55 = pro_split_data(test_split_is_55)"
      ],
      "metadata": {
        "id": "vHKEvB7WSCZR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sellers = 4056\n",
        "num_buyers = 8922\n",
        "num_items = 3119"
      ],
      "metadata": {
        "id": "FfkK0y1MS9M6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buyer and Item"
      ],
      "metadata": {
        "id": "UxdQbsbFUPco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "epochs = 100     # number of training epochs \n",
        "k = 50            # value of k for recall@k. \n",
        "num_layers = 3     # number of LightGCN layers (i.e., number of hops to consider during propagation)\n",
        "batch_size = 2048  # batch size. refers to the # of start in the batch (each will come with all of its edges)\n",
        "embedding_dim = 64 # dimension to use for the start/end embeddings\n",
        "save_emb_dir = 'embeddings_bi'  # path to save multi-scale embeddings during test(). If None, will not save any embeddings\n",
        "save_emb_dir_55 = 'embeddings_bi_55' \n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "e4ba12lZS_l9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf 'embeddings_bi' \n",
        "!rm -rf 'embeddings_bi_55' "
      ],
      "metadata": {
        "id": "lVCBvYZ6U1Va"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create directories\n",
        "os.mkdir(save_emb_dir)\n",
        "os.mkdir(save_emb_dir_55)"
      ],
      "metadata": {
        "id": "5p04VoMAUtfn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_bi = DataLoader(train_ev_bi, batch_size=batch_size, shuffle=True)\n",
        "val_loader_bi = DataLoader(val_ev_bi, batch_size=batch_size, shuffle=False)\n",
        "test_loader_bi = DataLoader(test_ev_bi, batch_size=batch_size, shuffle=False)\n",
        "train_loader_bi_55 = DataLoader(train_ev_bi_55, batch_size=batch_size, shuffle=True)\n",
        "val_loader_bi_55 = DataLoader(val_ev_bi_55, batch_size=batch_size, shuffle=False)\n",
        "test_loader_bi_55 = DataLoader(test_ev_bi_55, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "kJqLqXzYTTMT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.7 0.15 0.15\n",
        "gnn_bi = GNN(embedding_dim=embedding_dim, num_nodes=data_bi.num_nodes, num_start=num_buyers, num_layers=num_layers).to(device)\n",
        "opt = torch.optim.Adam(gnn_bi.parameters(), lr=1e-3) # using Adam optimizer\n",
        "all_train_losses = [] # list of (epoch, training loss)\n",
        "all_val_recalls = []  # list of (epoch, validation recall@k)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(gnn_bi, train_mp_bi, train_loader_bi, opt, num_buyers, data_bi.num_nodes, device)\n",
        "    all_train_losses.append((epoch, train_loss))\n",
        "    \n",
        "    if epoch in range(11) or epoch % 5 == 0: # perform validation for the first ~10 epochs, then every 5 epochs after that\n",
        "        val_recall,_ = test(gnn_bi, val_mp_bi, val_loader_bi, k, device, save_emb_dir, epoch)\n",
        "        all_val_recalls.append((epoch, val_recall))\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}, val_recall={val_recall}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Print best validation recall@k value\n",
        "best_val_recall = max(all_val_recalls, key = lambda x: x[1])\n",
        "print(f\"Best validation recall@k: {best_val_recall[1]} at epoch {best_val_recall[0]}\")\n",
        "\n",
        "# Print final recall@k on test set\n",
        "test_recall, result_bi = test(gnn_bi, test_mp_bi, test_loader_bi, k, device, None, None)\n",
        "print(f\"Test set recall@k: {test_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho6dGZA9TbY9",
        "outputId": "61103381-761e-41fb-dd7d-726524e00fd5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5092, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5095, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 0: train loss=0.688631173682225, val_recall=0.020058993699260876\n",
            "pos_score: tensor(0.5099, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5105, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5106, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 1: train loss=0.6879918582400869, val_recall=0.026821686053556285\n",
            "pos_score: tensor(0.5112, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5119, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5122, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5129, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 2: train loss=0.6872430463499357, val_recall=0.03908162183448443\n",
            "pos_score: tensor(0.5128, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5145, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5143, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 3: train loss=0.6863154418330479, val_recall=0.054938355749424454\n",
            "pos_score: tensor(0.5155, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5160, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5162, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5166, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 4: train loss=0.68524161695256, val_recall=0.07711362534835817\n",
            "pos_score: tensor(0.5176, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5189, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5188, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5200, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 5: train loss=0.6839250142913641, val_recall=0.11394600681337323\n",
            "pos_score: tensor(0.5214, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5209, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 6: train loss=0.6823537079368773, val_recall=0.14913169686547548\n",
            "pos_score: tensor(0.5242, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5262, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5259, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5271, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 7: train loss=0.6805363420542383, val_recall=0.18842411034682027\n",
            "pos_score: tensor(0.5283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 8: train loss=0.6783381631517558, val_recall=0.2197160822637922\n",
            "pos_score: tensor(0.5340, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5355, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5358, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5373, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 9: train loss=0.675832082511708, val_recall=0.2475509779660543\n",
            "pos_score: tensor(0.5392, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5407, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5436, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "Epoch 10: train loss=0.6729973011269584, val_recall=0.2731900812292034\n",
            "pos_score: tensor(0.5472, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5479, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5480, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5517, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "Epoch 11: train loss=0.6696850912993509\n",
            "pos_score: tensor(0.5545, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5554, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5564, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5598, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "Epoch 12: train loss=0.6660570116136109\n",
            "pos_score: tensor(0.5626, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5632, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5667, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5681, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "Epoch 13: train loss=0.662053352344238\n",
            "pos_score: tensor(0.5705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5729, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5781, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 14: train loss=0.6576904212860907\n",
            "pos_score: tensor(0.5815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5841, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5850, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5889, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 15: train loss=0.6529978222578947, val_recall=0.32611407623335104\n",
            "pos_score: tensor(0.5913, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5959, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5018, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5947, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6018, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "Epoch 16: train loss=0.6481093849940894\n",
            "pos_score: tensor(0.6046, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6060, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6074, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6103, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "Epoch 17: train loss=0.6429108067490237\n",
            "pos_score: tensor(0.6154, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6184, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6228, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "Epoch 18: train loss=0.6378928163993408\n",
            "pos_score: tensor(0.6282, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5026, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6364, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6309, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 19: train loss=0.6323305468019519\n",
            "pos_score: tensor(0.6409, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6414, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5033, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6474, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "Epoch 20: train loss=0.6268185680957791, val_recall=0.3376648584663852\n",
            "pos_score: tensor(0.6534, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "Epoch 21: train loss=0.6212694477404657\n",
            "pos_score: tensor(0.6663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6677, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5039, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5048, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6680, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "Epoch 22: train loss=0.6159254392566929\n",
            "pos_score: tensor(0.6777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6762, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6839, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6896, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "Epoch 23: train loss=0.610551927464362\n",
            "pos_score: tensor(0.6923, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6955, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6927, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6905, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5039, grad_fn=<MeanBackward0>)\n",
            "Epoch 24: train loss=0.6052756278758421\n",
            "pos_score: tensor(0.7003, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7025, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7082, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7107, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "Epoch 25: train loss=0.6002845498073456, val_recall=0.3406591658977155\n",
            "pos_score: tensor(0.7099, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5053, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7152, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7181, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7259, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5068, grad_fn=<MeanBackward0>)\n",
            "Epoch 26: train loss=0.5958383384617754\n",
            "pos_score: tensor(0.7220, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7301, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7202, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7420, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "Epoch 27: train loss=0.5907112208694159\n",
            "pos_score: tensor(0.7320, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7373, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7418, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7420, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5082, grad_fn=<MeanBackward0>)\n",
            "Epoch 28: train loss=0.5865648181409072\n",
            "pos_score: tensor(0.7440, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7502, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5068, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7498, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7475, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "Epoch 29: train loss=0.5823934497139598\n",
            "pos_score: tensor(0.7615, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7547, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5069, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7565, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5067, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7564, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "Epoch 30: train loss=0.5781118077640967, val_recall=0.3443222278145942\n",
            "pos_score: tensor(0.7611, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5073, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5067, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7745, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7652, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "Epoch 31: train loss=0.5744110935576092\n",
            "pos_score: tensor(0.7743, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "Epoch 32: train loss=0.5710572764483994\n",
            "pos_score: tensor(0.7757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7849, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7859, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7895, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5073, grad_fn=<MeanBackward0>)\n",
            "Epoch 33: train loss=0.5673555378865229\n",
            "pos_score: tensor(0.7919, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5076, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7876, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7956, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5092, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7889, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "Epoch 34: train loss=0.5637767077433194\n",
            "pos_score: tensor(0.7936, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7991, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7981, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5085, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8075, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "Epoch 35: train loss=0.561328619856242, val_recall=0.34231077976306984\n",
            "pos_score: tensor(0.8035, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8046, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5085, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8069, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8094, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5102, grad_fn=<MeanBackward0>)\n",
            "Epoch 36: train loss=0.5583048045933553\n",
            "pos_score: tensor(0.8082, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8143, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8085, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5068, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8221, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "Epoch 37: train loss=0.5549882799539968\n",
            "pos_score: tensor(0.8176, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8192, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8171, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5071, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8229, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "Epoch 38: train loss=0.5525099022631406\n",
            "pos_score: tensor(0.8252, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8194, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8281, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "Epoch 39: train loss=0.5495891027741547\n",
            "pos_score: tensor(0.8291, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8339, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8239, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8386, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "Epoch 40: train loss=0.5469646645553058, val_recall=0.3424925318532188\n",
            "pos_score: tensor(0.8357, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8352, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8387, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8350, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "Epoch 41: train loss=0.5452464304757314\n",
            "pos_score: tensor(0.8359, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8415, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5026, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8452, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "Epoch 42: train loss=0.5422305295920837\n",
            "pos_score: tensor(0.8475, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8441, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8476, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5064, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8484, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "Epoch 43: train loss=0.5402719759567807\n",
            "pos_score: tensor(0.8524, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5056, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8520, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8526, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8478, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "Epoch 44: train loss=0.538067855074757\n",
            "pos_score: tensor(0.8633, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8504, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8552, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8550, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5073, grad_fn=<MeanBackward0>)\n",
            "Epoch 45: train loss=0.5362201886025909, val_recall=0.34556187027561075\n",
            "pos_score: tensor(0.8576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8610, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5068, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8618, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8629, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "Epoch 46: train loss=0.5347010594404453\n",
            "pos_score: tensor(0.8624, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8596, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8697, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "Epoch 47: train loss=0.5319758691505607\n",
            "pos_score: tensor(0.8660, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8727, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8657, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "Epoch 48: train loss=0.5311156349291057\n",
            "pos_score: tensor(0.8771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5033, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "Epoch 49: train loss=0.5287175004884938\n",
            "pos_score: tensor(0.8735, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5022, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 50: train loss=0.5265246042159426, val_recall=0.3479076081890968\n",
            "pos_score: tensor(0.8814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8790, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5073, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8789, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "Epoch 51: train loss=0.5261207795003907\n",
            "pos_score: tensor(0.8804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5033, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8857, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5018, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8859, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "Epoch 52: train loss=0.5245201834487047\n",
            "pos_score: tensor(0.8870, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8819, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8887, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8924, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "Epoch 53: train loss=0.5219987628511029\n",
            "pos_score: tensor(0.8916, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8871, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4974, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8871, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5022, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8977, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 54: train loss=0.5207736381545693\n",
            "pos_score: tensor(0.8951, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4992, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8886, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8939, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8970, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "Epoch 55: train loss=0.519973541156712, val_recall=0.34650811709494916\n",
            "pos_score: tensor(0.8941, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8928, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4963, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8989, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9005, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "Epoch 56: train loss=0.5177566060677813\n",
            "pos_score: tensor(0.8997, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8943, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8992, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9051, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4987, grad_fn=<MeanBackward0>)\n",
            "Epoch 57: train loss=0.516984827162457\n",
            "pos_score: tensor(0.9008, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4994, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9002, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4975, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9027, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9038, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "Epoch 58: train loss=0.5157600512318848\n",
            "pos_score: tensor(0.9083, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4978, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9017, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9041, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4950, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9027, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 59: train loss=0.5143322083884869\n",
            "pos_score: tensor(0.9055, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4985, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9045, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4979, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9098, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4998, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9080, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4928, grad_fn=<MeanBackward0>)\n",
            "Epoch 60: train loss=0.513249577518392, val_recall=0.34782013999571254\n",
            "pos_score: tensor(0.9099, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4980, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9086, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9078, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4973, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9120, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4948, grad_fn=<MeanBackward0>)\n",
            "Epoch 61: train loss=0.5120683783623228\n",
            "pos_score: tensor(0.9112, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4955, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9091, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4950, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9132, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4954, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "Epoch 62: train loss=0.5103083864902386\n",
            "pos_score: tensor(0.9149, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4981, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4949, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9116, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4968, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9162, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4954, grad_fn=<MeanBackward0>)\n",
            "Epoch 63: train loss=0.510146239772439\n",
            "pos_score: tensor(0.9144, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4989, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9170, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9145, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4962, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9196, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4944, grad_fn=<MeanBackward0>)\n",
            "Epoch 64: train loss=0.5091017800128925\n",
            "pos_score: tensor(0.9209, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4911, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9209, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9153, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4974, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9145, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4911, grad_fn=<MeanBackward0>)\n",
            "Epoch 65: train loss=0.5072965569549395, val_recall=0.3485755471203944\n",
            "pos_score: tensor(0.9204, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4868, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9202, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9206, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4945, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9194, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "Epoch 66: train loss=0.505950997390419\n",
            "pos_score: tensor(0.9221, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9213, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4953, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9211, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4917, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9251, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "Epoch 67: train loss=0.5056178310438532\n",
            "pos_score: tensor(0.9223, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4969, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9201, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4926, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9275, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4981, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9276, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4942, grad_fn=<MeanBackward0>)\n",
            "Epoch 68: train loss=0.5059961559063539\n",
            "pos_score: tensor(0.9242, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4946, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9279, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4932, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9249, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9268, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4948, grad_fn=<MeanBackward0>)\n",
            "Epoch 69: train loss=0.5046389539070136\n",
            "pos_score: tensor(0.9268, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4935, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9259, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4946, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9297, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "Epoch 70: train loss=0.5037406308067776, val_recall=0.34952974559367683\n",
            "pos_score: tensor(0.9270, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4911, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9295, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4928, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9268, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9362, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4910, grad_fn=<MeanBackward0>)\n",
            "Epoch 71: train loss=0.5022978776476864\n",
            "pos_score: tensor(0.9288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4904, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9305, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4942, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9375, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4955, grad_fn=<MeanBackward0>)\n",
            "Epoch 72: train loss=0.5025141723989461\n",
            "pos_score: tensor(0.9329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4917, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9323, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4900, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4903, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9289, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4921, grad_fn=<MeanBackward0>)\n",
            "Epoch 73: train loss=0.5011305944148826\n",
            "pos_score: tensor(0.9356, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9321, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4945, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9327, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4904, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9366, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4940, grad_fn=<MeanBackward0>)\n",
            "Epoch 74: train loss=0.5003790954621299\n",
            "pos_score: tensor(0.9364, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9356, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9352, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4906, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9341, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4966, grad_fn=<MeanBackward0>)\n",
            "Epoch 75: train loss=0.5000216042454636, val_recall=0.3481211668950218\n",
            "pos_score: tensor(0.9370, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4957, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9357, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4961, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9367, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4884, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9388, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4900, grad_fn=<MeanBackward0>)\n",
            "Epoch 76: train loss=0.5002778101639795\n",
            "pos_score: tensor(0.9382, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4895, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9398, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9371, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4906, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9376, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4830, grad_fn=<MeanBackward0>)\n",
            "Epoch 77: train loss=0.4982188681687479\n",
            "pos_score: tensor(0.9410, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9356, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4882, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9400, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4863, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9426, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4892, grad_fn=<MeanBackward0>)\n",
            "Epoch 78: train loss=0.4979420082387371\n",
            "pos_score: tensor(0.9406, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4907, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9403, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4867, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9406, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4890, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9425, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "Epoch 79: train loss=0.49745078972355294\n",
            "pos_score: tensor(0.9406, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4876, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9416, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9429, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9440, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "Epoch 80: train loss=0.4967951689688087, val_recall=0.34840742643700656\n",
            "pos_score: tensor(0.9425, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9422, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4846, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9448, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4857, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9440, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4806, grad_fn=<MeanBackward0>)\n",
            "Epoch 81: train loss=0.4946417315601079\n",
            "pos_score: tensor(0.9423, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4849, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9443, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4850, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9469, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4881, grad_fn=<MeanBackward0>)\n",
            "Epoch 82: train loss=0.4956580529570794\n",
            "pos_score: tensor(0.9463, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4869, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9447, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4891, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9450, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4875, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9468, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4843, grad_fn=<MeanBackward0>)\n",
            "Epoch 83: train loss=0.4949508021094165\n",
            "pos_score: tensor(0.9458, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9478, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4860, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9467, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4855, grad_fn=<MeanBackward0>)\n",
            "Epoch 84: train loss=0.49394661183918404\n",
            "pos_score: tensor(0.9472, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4822, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9471, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4838, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9505, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4838, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9457, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4911, grad_fn=<MeanBackward0>)\n",
            "Epoch 85: train loss=0.49321609213412787, val_recall=0.3479303272003653\n",
            "pos_score: tensor(0.9471, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9486, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9486, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9521, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4830, grad_fn=<MeanBackward0>)\n",
            "Epoch 86: train loss=0.4928368866669293\n",
            "pos_score: tensor(0.9478, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4781, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9491, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4896, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9509, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4884, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9520, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "Epoch 87: train loss=0.4926957962728532\n",
            "pos_score: tensor(0.9504, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9510, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4822, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9491, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4895, grad_fn=<MeanBackward0>)\n",
            "Epoch 88: train loss=0.49223000126139277\n",
            "pos_score: tensor(0.9531, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4820, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9510, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9499, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9534, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4806, grad_fn=<MeanBackward0>)\n",
            "Epoch 89: train loss=0.4922784300123244\n",
            "pos_score: tensor(0.9540, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4817, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9527, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4795, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9530, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4884, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9495, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "Epoch 90: train loss=0.4911376206678562, val_recall=0.3479303272003653\n",
            "pos_score: tensor(0.9549, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4792, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9513, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4873, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9545, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4848, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9531, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "Epoch 91: train loss=0.49149712933957945\n",
            "pos_score: tensor(0.9550, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9524, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9551, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4831, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9553, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4847, grad_fn=<MeanBackward0>)\n",
            "Epoch 92: train loss=0.49121441328955445\n",
            "pos_score: tensor(0.9555, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4764, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9547, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4855, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4769, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9550, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "Epoch 93: train loss=0.48882875519802743\n",
            "pos_score: tensor(0.9553, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9546, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9570, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "Epoch 94: train loss=0.49044730634002104\n",
            "pos_score: tensor(0.9567, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4823, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9584, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4829, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9549, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4798, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4806, grad_fn=<MeanBackward0>)\n",
            "Epoch 95: train loss=0.489005556112075, val_recall=0.3469761287270829\n",
            "pos_score: tensor(0.9569, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9588, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9573, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9571, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4814, grad_fn=<MeanBackward0>)\n",
            "Epoch 96: train loss=0.48932855335701053\n",
            "pos_score: tensor(0.9574, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4780, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9598, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4786, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9589, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4824, grad_fn=<MeanBackward0>)\n",
            "Epoch 97: train loss=0.4879922616913211\n",
            "pos_score: tensor(0.9594, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9586, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4806, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9578, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9610, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4738, grad_fn=<MeanBackward0>)\n",
            "Epoch 98: train loss=0.4872075083036381\n",
            "pos_score: tensor(0.9603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4766, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9594, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4831, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9595, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4767, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9599, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4895, grad_fn=<MeanBackward0>)\n",
            "Epoch 99: train loss=0.4876739155076582\n",
            "\n",
            "Best validation recall@k: 0.34952974559367683 at epoch 70\n",
            "Test set recall@k: 0.38778172561191426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0.5 0 0.5\n",
        "epochs = 150\n",
        "gnn_bi_55 = GNN(embedding_dim=embedding_dim, num_nodes=data_bi.num_nodes, num_start=num_buyers, num_layers=num_layers).to(device)\n",
        "opt_55 = torch.optim.Adam(gnn_bi_55.parameters(), lr=1e-3) # using Adam optimizer\n",
        "all_train_losses_55 = [] # list of (epoch, training loss)\n",
        "all_test_recalls_55 = []  # list of (epoch, validation recall@k)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(gnn_bi_55, train_mp_bi_55, train_loader_bi_55, opt_55, num_buyers, data_bi.num_nodes, device)\n",
        "    all_train_losses_55.append((epoch, train_loss))\n",
        "    \n",
        "    if epoch in range(11) or epoch % 5 == 0: # perform validation for the first ~10 epochs, then every 5 epochs after that\n",
        "        test_recall,_ = test(gnn_bi_55, test_mp_bi_55, test_loader_bi_55, k, device, save_emb_dir_55, epoch)\n",
        "        all_test_recalls_55.append((epoch, test_recall))\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}, test_recall={test_recall}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Print final recall@k on test set\n",
        "test_recall_55, result_bi_55 = test(gnn_bi_55, test_mp_bi_55, test_loader_bi_55, k, device, None, None)\n",
        "print(f\"Test set recall@k: {test_recall_55}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRS_uJ1xU_tA",
        "outputId": "aece563f-d86c-489b-d5e4-90758e11cec9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5125, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 0: train loss=0.6869210622295824, test_recall=0.03305797277871844\n",
            "pos_score: tensor(0.5134, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5145, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 1: train loss=0.6863135665502437, test_recall=0.04057737556745825\n",
            "pos_score: tensor(0.5143, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 2: train loss=0.6856367879146242, test_recall=0.04844320197481413\n",
            "pos_score: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5163, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5167, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "Epoch 3: train loss=0.6849461305782135, test_recall=0.056753573141613896\n",
            "pos_score: tensor(0.5175, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5178, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5191, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 4: train loss=0.6841986284421806, test_recall=0.07090845745676332\n",
            "pos_score: tensor(0.5201, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5198, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 5: train loss=0.6833357801097412, test_recall=0.08123926165466963\n",
            "pos_score: tensor(0.5203, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5225, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 6: train loss=0.6824080594802623, test_recall=0.09362243142778334\n",
            "pos_score: tensor(0.5231, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5245, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 7: train loss=0.6813444920029594, test_recall=0.1058810741213533\n",
            "pos_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5267, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5270, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 8: train loss=0.6801517883888913, test_recall=0.11926332631431612\n",
            "pos_score: tensor(0.5283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5287, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5299, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 9: train loss=0.6788906106885954, test_recall=0.13254062598829658\n",
            "pos_score: tensor(0.5305, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5327, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5325, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 10: train loss=0.6774887347330538, test_recall=0.14930892352069036\n",
            "pos_score: tensor(0.5345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5351, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5358, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 11: train loss=0.6758885876076908\n",
            "pos_score: tensor(0.5372, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5400, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 12: train loss=0.674217280665258\n",
            "pos_score: tensor(0.5420, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5414, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5446, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 13: train loss=0.6723016858958606\n",
            "pos_score: tensor(0.5462, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5465, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5481, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 14: train loss=0.6702800771733426\n",
            "pos_score: tensor(0.5502, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5511, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5535, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "Epoch 15: train loss=0.6680843589233881, test_recall=0.2037706598387148\n",
            "pos_score: tensor(0.5548, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 16: train loss=0.6657335546964598\n",
            "pos_score: tensor(0.5602, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5613, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 17: train loss=0.6631966462432136\n",
            "pos_score: tensor(0.5654, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5688, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 18: train loss=0.6604787499138148\n",
            "pos_score: tensor(0.5713, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5767, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "Epoch 19: train loss=0.6576457751378179\n",
            "pos_score: tensor(0.5770, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5808, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5843, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "Epoch 20: train loss=0.6545823898840974, test_recall=0.23473933754626594\n",
            "pos_score: tensor(0.5862, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5867, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5899, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 21: train loss=0.6513335159505114\n",
            "pos_score: tensor(0.5911, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5970, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5964, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 22: train loss=0.6480992015414236\n",
            "pos_score: tensor(0.6004, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6011, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6059, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 23: train loss=0.6443966063433745\n",
            "pos_score: tensor(0.6064, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6106, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6140, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "Epoch 24: train loss=0.640881771020121\n",
            "pos_score: tensor(0.6148, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6181, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6228, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "Epoch 25: train loss=0.6374490820866406, test_recall=0.24908101884549572\n",
            "pos_score: tensor(0.6257, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6242, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6309, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "Epoch 26: train loss=0.6335691753123067\n",
            "pos_score: tensor(0.6334, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6350, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5033, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6382, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "Epoch 27: train loss=0.6300418396741005\n",
            "pos_score: tensor(0.6449, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6418, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5024, grad_fn=<MeanBackward0>)\n",
            "Epoch 28: train loss=0.6259262311956322\n",
            "pos_score: tensor(0.6510, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5026, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6529, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6553, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 29: train loss=0.6219423258888102\n",
            "pos_score: tensor(0.6581, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6594, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6686, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 30: train loss=0.6180138657218587, test_recall=0.25911244220132224\n",
            "pos_score: tensor(0.6679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6733, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "Epoch 31: train loss=0.6144643156801122\n",
            "pos_score: tensor(0.6736, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6895, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5039, grad_fn=<MeanBackward0>)\n",
            "Epoch 32: train loss=0.6102985669986172\n",
            "pos_score: tensor(0.6898, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6897, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6867, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5053, grad_fn=<MeanBackward0>)\n",
            "Epoch 33: train loss=0.6069501671681393\n",
            "pos_score: tensor(0.6948, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5039, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6988, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6994, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "Epoch 34: train loss=0.6025378896471953\n",
            "pos_score: tensor(0.7034, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7079, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7076, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "Epoch 35: train loss=0.5986768206047229, test_recall=0.26302534140057077\n",
            "pos_score: tensor(0.7135, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7138, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7174, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "Epoch 36: train loss=0.5948774746443419\n",
            "pos_score: tensor(0.7200, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7234, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7267, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "Epoch 37: train loss=0.591612943402946\n",
            "pos_score: tensor(0.7256, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7311, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "Epoch 38: train loss=0.588298665337483\n",
            "pos_score: tensor(0.7360, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7395, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7432, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "Epoch 39: train loss=0.5843233481938117\n",
            "pos_score: tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7503, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7449, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "Epoch 40: train loss=0.5814583499728171, test_recall=0.26367721693073654\n",
            "pos_score: tensor(0.7539, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7568, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5056, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7540, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "Epoch 41: train loss=0.5780965146134207\n",
            "pos_score: tensor(0.7619, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7616, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7631, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "Epoch 42: train loss=0.5747555726151241\n",
            "pos_score: tensor(0.7636, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "Epoch 43: train loss=0.571838041038299\n",
            "pos_score: tensor(0.7724, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "Epoch 44: train loss=0.5690114646613968\n",
            "pos_score: tensor(0.7826, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7867, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "Epoch 45: train loss=0.5657124930726108, test_recall=0.2636843224731702\n",
            "pos_score: tensor(0.7908, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7906, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7863, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "Epoch 46: train loss=0.5629740948572058\n",
            "pos_score: tensor(0.7953, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7965, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7947, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "Epoch 47: train loss=0.5603542626066529\n",
            "pos_score: tensor(0.7974, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8005, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8070, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5077, grad_fn=<MeanBackward0>)\n",
            "Epoch 48: train loss=0.5580875657252731\n",
            "pos_score: tensor(0.8043, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5067, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8088, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8090, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "Epoch 49: train loss=0.5563111192824263\n",
            "pos_score: tensor(0.8149, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8110, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8128, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "Epoch 50: train loss=0.5536887797445894, test_recall=0.26481361819084337\n",
            "pos_score: tensor(0.8183, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5064, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8150, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5048, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8216, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5077, grad_fn=<MeanBackward0>)\n",
            "Epoch 51: train loss=0.551624588457979\n",
            "pos_score: tensor(0.8189, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5033, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8287, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8226, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "Epoch 52: train loss=0.5481233098872625\n",
            "pos_score: tensor(0.8240, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8313, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8303, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "Epoch 53: train loss=0.5469870151005459\n",
            "pos_score: tensor(0.8315, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5053, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8316, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8368, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "Epoch 54: train loss=0.5447600782144997\n",
            "pos_score: tensor(0.8319, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8410, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8408, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "Epoch 55: train loss=0.5419372761248242, test_recall=0.26497685499561746\n",
            "pos_score: tensor(0.8473, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8409, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8390, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "Epoch 56: train loss=0.5408530110272173\n",
            "pos_score: tensor(0.8464, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8443, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8500, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "Epoch 57: train loss=0.5386660111635342\n",
            "pos_score: tensor(0.8457, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8572, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8495, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "Epoch 58: train loss=0.5362704941221325\n",
            "pos_score: tensor(0.8542, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8536, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5048, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "Epoch 59: train loss=0.5351745055517947\n",
            "pos_score: tensor(0.8537, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8611, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5048, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8622, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4964, grad_fn=<MeanBackward0>)\n",
            "Epoch 60: train loss=0.5325879434274506, test_recall=0.2661993672204945\n",
            "pos_score: tensor(0.8626, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8644, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8614, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "Epoch 61: train loss=0.5315384379353841\n",
            "pos_score: tensor(0.8671, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8653, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8669, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 62: train loss=0.5305050991294455\n",
            "pos_score: tensor(0.8683, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8721, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "Epoch 63: train loss=0.5287764604266046\n",
            "pos_score: tensor(0.8709, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "Epoch 64: train loss=0.5277745090575277\n",
            "pos_score: tensor(0.8769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8762, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "Epoch 65: train loss=0.5264134216072073, test_recall=0.2657121964467215\n",
            "pos_score: tensor(0.8800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "Epoch 66: train loss=0.5250904276328636\n",
            "pos_score: tensor(0.8854, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4964, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "Epoch 67: train loss=0.5225997545733961\n",
            "pos_score: tensor(0.8831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4975, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8841, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8904, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "Epoch 68: train loss=0.5209096048957685\n",
            "pos_score: tensor(0.8890, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4983, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8871, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8901, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "Epoch 69: train loss=0.5201125142099449\n",
            "pos_score: tensor(0.8909, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8914, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8923, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "Epoch 70: train loss=0.519124559353914, test_recall=0.26568533947925677\n",
            "pos_score: tensor(0.8962, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8945, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8916, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4966, grad_fn=<MeanBackward0>)\n",
            "Epoch 71: train loss=0.518089285102702\n",
            "pos_score: tensor(0.8967, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4958, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8966, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8970, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4985, grad_fn=<MeanBackward0>)\n",
            "Epoch 72: train loss=0.5160013873340856\n",
            "pos_score: tensor(0.9019, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4970, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8964, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8994, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 73: train loss=0.5158945324635877\n",
            "pos_score: tensor(0.9020, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4973, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9011, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9022, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4963, grad_fn=<MeanBackward0>)\n",
            "Epoch 74: train loss=0.5143546035281187\n",
            "pos_score: tensor(0.9066, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9024, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4972, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9032, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4988, grad_fn=<MeanBackward0>)\n",
            "Epoch 75: train loss=0.5129702891425479, test_recall=0.2660978194206695\n",
            "pos_score: tensor(0.9050, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4954, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9075, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9064, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "Epoch 76: train loss=0.511387103979894\n",
            "pos_score: tensor(0.9091, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4934, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9094, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4969, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9072, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "Epoch 77: train loss=0.5104576677074223\n",
            "pos_score: tensor(0.9100, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4947, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9112, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4986, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9109, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4936, grad_fn=<MeanBackward0>)\n",
            "Epoch 78: train loss=0.5100732966843262\n",
            "pos_score: tensor(0.9142, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9109, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4986, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9131, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "Epoch 79: train loss=0.5101980731308714\n",
            "pos_score: tensor(0.9137, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4970, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9146, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4938, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9159, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "Epoch 80: train loss=0.5083075594280846, test_recall=0.2653546516485689\n",
            "pos_score: tensor(0.9156, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4992, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9179, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4986, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9163, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4979, grad_fn=<MeanBackward0>)\n",
            "Epoch 81: train loss=0.5091292887169104\n",
            "pos_score: tensor(0.9175, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4940, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9182, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4922, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4903, grad_fn=<MeanBackward0>)\n",
            "Epoch 82: train loss=0.5056964448360455\n",
            "pos_score: tensor(0.9201, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9218, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4903, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9187, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "Epoch 83: train loss=0.5047590496638057\n",
            "pos_score: tensor(0.9212, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4856, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9220, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9229, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "Epoch 84: train loss=0.5039151681687207\n",
            "pos_score: tensor(0.9204, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9262, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4935, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9246, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4921, grad_fn=<MeanBackward0>)\n",
            "Epoch 85: train loss=0.504518468780501, test_recall=0.2643393252609149\n",
            "pos_score: tensor(0.9239, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4890, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9248, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9275, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4887, grad_fn=<MeanBackward0>)\n",
            "Epoch 86: train loss=0.502359247176452\n",
            "pos_score: tensor(0.9285, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4905, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9264, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9259, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4962, grad_fn=<MeanBackward0>)\n",
            "Epoch 87: train loss=0.5031065554170745\n",
            "pos_score: tensor(0.9283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9289, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4922, grad_fn=<MeanBackward0>)\n",
            "Epoch 88: train loss=0.501836562064408\n",
            "pos_score: tensor(0.9262, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4980, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9315, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4847, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9323, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4894, grad_fn=<MeanBackward0>)\n",
            "Epoch 89: train loss=0.5008353924759079\n",
            "pos_score: tensor(0.9328, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4941, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4868, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9333, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "Epoch 90: train loss=0.5004930600441101, test_recall=0.26349593426731677\n",
            "pos_score: tensor(0.9321, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9331, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4886, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9333, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "Epoch 91: train loss=0.49936606478732687\n",
            "pos_score: tensor(0.9342, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4880, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9330, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9354, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4872, grad_fn=<MeanBackward0>)\n",
            "Epoch 92: train loss=0.4988837991034492\n",
            "pos_score: tensor(0.9335, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4894, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9362, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4851, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9371, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "Epoch 93: train loss=0.49827299201669134\n",
            "pos_score: tensor(0.9371, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4931, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9369, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4893, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9365, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "Epoch 94: train loss=0.4983352051492893\n",
            "pos_score: tensor(0.9392, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4910, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9364, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9388, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4904, grad_fn=<MeanBackward0>)\n",
            "Epoch 95: train loss=0.4994654433068124, test_recall=0.263581654437909\n",
            "pos_score: tensor(0.9381, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4875, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9391, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4949, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9407, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "Epoch 96: train loss=0.4966618636533477\n",
            "pos_score: tensor(0.9378, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4930, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9431, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4867, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "Epoch 97: train loss=0.4959592197923329\n",
            "pos_score: tensor(0.9431, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4894, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9386, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4880, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9430, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4884, grad_fn=<MeanBackward0>)\n",
            "Epoch 98: train loss=0.4959851283355483\n",
            "pos_score: tensor(0.9401, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4822, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9445, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4889, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9435, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4841, grad_fn=<MeanBackward0>)\n",
            "Epoch 99: train loss=0.4941566849234423\n",
            "pos_score: tensor(0.9440, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9436, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4843, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9438, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4877, grad_fn=<MeanBackward0>)\n",
            "Epoch 100: train loss=0.49416628496851955, test_recall=0.26269822463873327\n",
            "pos_score: tensor(0.9446, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4877, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4908, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9431, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4895, grad_fn=<MeanBackward0>)\n",
            "Epoch 101: train loss=0.4951058227435253\n",
            "pos_score: tensor(0.9463, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9457, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9456, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4925, grad_fn=<MeanBackward0>)\n",
            "Epoch 102: train loss=0.49364640169064145\n",
            "pos_score: tensor(0.9477, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4853, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4893, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9462, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4839, grad_fn=<MeanBackward0>)\n",
            "Epoch 103: train loss=0.4931202931874817\n",
            "pos_score: tensor(0.9460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9481, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4863, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9494, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4856, grad_fn=<MeanBackward0>)\n",
            "Epoch 104: train loss=0.4919618252292397\n",
            "pos_score: tensor(0.9470, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4908, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9491, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9502, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "Epoch 105: train loss=0.49347339274058566, test_recall=0.26363821849999786\n",
            "pos_score: tensor(0.9504, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4864, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9487, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4896, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9499, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "Epoch 106: train loss=0.4920594276466222\n",
            "pos_score: tensor(0.9495, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4872, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4824, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9501, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4860, grad_fn=<MeanBackward0>)\n",
            "Epoch 107: train loss=0.4913222948474036\n",
            "pos_score: tensor(0.9513, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4841, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9510, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "Epoch 108: train loss=0.4901317763416923\n",
            "pos_score: tensor(0.9533, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4829, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9532, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9504, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "Epoch 109: train loss=0.4892832036368215\n",
            "pos_score: tensor(0.9518, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4873, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9548, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4854, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9527, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "Epoch 110: train loss=0.4904327813572885, test_recall=0.2631568858363448\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4866, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9533, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9566, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4883, grad_fn=<MeanBackward0>)\n",
            "Epoch 111: train loss=0.49105081200976547\n",
            "pos_score: tensor(0.9550, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9546, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4931, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9545, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4832, grad_fn=<MeanBackward0>)\n",
            "Epoch 112: train loss=0.49059650543327876\n",
            "pos_score: tensor(0.9548, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4935, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9554, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4824, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9561, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4802, grad_fn=<MeanBackward0>)\n",
            "Epoch 113: train loss=0.4899326240133982\n",
            "pos_score: tensor(0.9570, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4780, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "Epoch 114: train loss=0.4876644521136197\n",
            "pos_score: tensor(0.9583, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4848, grad_fn=<MeanBackward0>)\n",
            "Epoch 115: train loss=0.4880299229574063, test_recall=0.262696480679807\n",
            "pos_score: tensor(0.9563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4841, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9572, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4762, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9593, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4835, grad_fn=<MeanBackward0>)\n",
            "Epoch 116: train loss=0.4874623850870065\n",
            "pos_score: tensor(0.9584, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4857, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9590, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4799, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9572, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4855, grad_fn=<MeanBackward0>)\n",
            "Epoch 117: train loss=0.48824516498222487\n",
            "pos_score: tensor(0.9576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4877, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9597, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9595, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4912, grad_fn=<MeanBackward0>)\n",
            "Epoch 118: train loss=0.4895894869708786\n",
            "pos_score: tensor(0.9602, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9583, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "Epoch 119: train loss=0.4863732838421446\n",
            "pos_score: tensor(0.9606, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4876, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9593, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4844, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9608, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4752, grad_fn=<MeanBackward0>)\n",
            "Epoch 120: train loss=0.4870878093072142, test_recall=0.26181403746310966\n",
            "pos_score: tensor(0.9602, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9613, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9610, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4880, grad_fn=<MeanBackward0>)\n",
            "Epoch 121: train loss=0.48590630642800897\n",
            "pos_score: tensor(0.9618, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4788, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9607, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4832, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9619, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "Epoch 122: train loss=0.4861415082146736\n",
            "pos_score: tensor(0.9627, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4749, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9619, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4793, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9614, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4750, grad_fn=<MeanBackward0>)\n",
            "Epoch 123: train loss=0.4841263619923974\n",
            "pos_score: tensor(0.9634, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4765, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4828, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9609, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "Epoch 124: train loss=0.4846692874785612\n",
            "pos_score: tensor(0.9636, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9627, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4828, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9632, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4769, grad_fn=<MeanBackward0>)\n",
            "Epoch 125: train loss=0.4854364069177685, test_recall=0.2619323696656233\n",
            "pos_score: tensor(0.9627, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4839, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9640, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9644, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4748, grad_fn=<MeanBackward0>)\n",
            "Epoch 126: train loss=0.4846818294673817\n",
            "pos_score: tensor(0.9636, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4876, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4708, grad_fn=<MeanBackward0>)\n",
            "Epoch 127: train loss=0.48462277347059324\n",
            "pos_score: tensor(0.9637, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4774, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9658, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4773, grad_fn=<MeanBackward0>)\n",
            "Epoch 128: train loss=0.4835785669666021\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9654, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4803, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9646, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "Epoch 129: train loss=0.485113748979844\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4825, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4774, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "Epoch 130: train loss=0.48435198100848037, test_recall=0.2615459581949577\n",
            "pos_score: tensor(0.9662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4734, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9668, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4769, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9660, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4750, grad_fn=<MeanBackward0>)\n",
            "Epoch 131: train loss=0.482302184844633\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9673, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4795, grad_fn=<MeanBackward0>)\n",
            "Epoch 132: train loss=0.4829718007245267\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4768, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9683, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4721, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "Epoch 133: train loss=0.4825022879524578\n",
            "pos_score: tensor(0.9668, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4756, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9682, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9683, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "Epoch 134: train loss=0.4824539900644777\n",
            "pos_score: tensor(0.9676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4829, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9685, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4770, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9686, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4732, grad_fn=<MeanBackward0>)\n",
            "Epoch 135: train loss=0.48280335022373133, test_recall=0.2598258333740041\n",
            "pos_score: tensor(0.9683, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4721, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9682, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4892, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4750, grad_fn=<MeanBackward0>)\n",
            "Epoch 136: train loss=0.4829685163773433\n",
            "pos_score: tensor(0.9689, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9698, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4721, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9684, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "Epoch 137: train loss=0.4821153112128661\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4809, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9687, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4739, grad_fn=<MeanBackward0>)\n",
            "Epoch 138: train loss=0.4818226549574194\n",
            "pos_score: tensor(0.9699, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4690, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4663, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4775, grad_fn=<MeanBackward0>)\n",
            "Epoch 139: train loss=0.47955765301692865\n",
            "pos_score: tensor(0.9700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4720, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9690, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4728, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4761, grad_fn=<MeanBackward0>)\n",
            "Epoch 140: train loss=0.4805125076846417, test_recall=0.2601920647485228\n",
            "pos_score: tensor(0.9710, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4762, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4682, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9710, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "Epoch 141: train loss=0.4806497587634448\n",
            "pos_score: tensor(0.9706, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4825, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9704, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4756, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4678, grad_fn=<MeanBackward0>)\n",
            "Epoch 142: train loss=0.48087709086562247\n",
            "pos_score: tensor(0.9723, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4818, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9707, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4744, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9713, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4756, grad_fn=<MeanBackward0>)\n",
            "Epoch 143: train loss=0.48154650803845855\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "Epoch 144: train loss=0.4799750243533623\n",
            "pos_score: tensor(0.9726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9727, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9713, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4732, grad_fn=<MeanBackward0>)\n",
            "Epoch 145: train loss=0.4800177013504977, test_recall=0.25998722270844643\n",
            "pos_score: tensor(0.9720, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4695, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4702, grad_fn=<MeanBackward0>)\n",
            "Epoch 146: train loss=0.4797263631322425\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4749, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4762, grad_fn=<MeanBackward0>)\n",
            "Epoch 147: train loss=0.48007177091159464\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9727, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4759, grad_fn=<MeanBackward0>)\n",
            "Epoch 148: train loss=0.4796338712397155\n",
            "pos_score: tensor(0.9724, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4750, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9749, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4644, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4633, grad_fn=<MeanBackward0>)\n",
            "Epoch 149: train loss=0.47710229194074605\n",
            "\n",
            "Test set recall@k: 0.26021994943779275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item and Seller"
      ],
      "metadata": {
        "id": "MXSCY3WjX27a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters\n",
        "epochs = 500      # number of training epochs (we are keeping it relatively low so that this Colab runs fast)\n",
        "k = 50            # value of k for recall@k. It is important to set this to a reasonable value!\n",
        "num_layers = 3     # number of LightGCN layers (i.e., number of hops to consider during propagation)\n",
        "batch_size = 2048  # batch size. refers to the # of playlists in the batch (each will come with all of its edges)\n",
        "embedding_dim = 64 # dimension to use for the playlist/song embeddings\n",
        "save_emb_dir = 'embeddings_is'  # path to save multi-scale embeddings during test(). If None, will not save any embeddings\n",
        "save_emb_dir_55 = 'embeddings_is_55'\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "W3KUrjzWX4PR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf 'embeddings_is'\n",
        "!rm -rf 'embeddings_is_55'"
      ],
      "metadata": {
        "id": "P4RqhjbsX_fd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(save_emb_dir)\n",
        "os.mkdir(save_emb_dir_55)"
      ],
      "metadata": {
        "id": "m2kfMfu4X9L8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_is = DataLoader(train_ev_is, batch_size=batch_size, shuffle=True)\n",
        "val_loader_is = DataLoader(val_ev_is, batch_size=batch_size, shuffle=False)\n",
        "test_loader_is = DataLoader(test_ev_is, batch_size=batch_size, shuffle=False)\n",
        "train_loader_is_55 = DataLoader(train_ev_is_55, batch_size=batch_size, shuffle=True)\n",
        "val_loader_is_55 = DataLoader(val_ev_is_55, batch_size=batch_size, shuffle=False)\n",
        "test_loader_is_55 = DataLoader(test_ev_is_55, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "0ESZYDh7YEEa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_is = GNN(embedding_dim=embedding_dim, num_nodes=data_is.num_nodes, num_start=num_items, num_layers=num_layers).to(device)\n",
        "opt = torch.optim.Adam(gnn_is.parameters(), lr=1e-3) # using Adam optimizer\n",
        "all_train_losses = [] # list of (epoch, training loss)\n",
        "all_val_recalls = []  # list of (epoch, validation recall@k)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(gnn_is, train_mp_is, train_loader_is, opt, num_items, data_is.num_nodes, device)\n",
        "    all_train_losses.append((epoch, train_loss))\n",
        "    \n",
        "    if epoch in range(11) or epoch % 5 == 0: # perform validation for the first ~10 epochs, then every 5 epochs after that\n",
        "        val_recall,_ = test(gnn_is, val_mp_is, val_loader_is, k, device, save_emb_dir, epoch)\n",
        "        all_val_recalls.append((epoch, val_recall))\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}, val_recall={val_recall}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Print best validation recall@k value\n",
        "best_val_recall = max(all_val_recalls, key = lambda x: x[1])\n",
        "print(f\"Best validation recall@k: {best_val_recall[1]} at epoch {best_val_recall[0]}\")\n",
        "\n",
        "# Print final recall@k on test set\n",
        "test_recall, result_is = test(gnn_is, test_mp_is, test_loader_is, k, device, None, None)\n",
        "print(f\"Test set recall@k: {test_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH4igA-pYXFw",
        "outputId": "77be5293-c2a9-4f6b-f262-dc88c2419e91"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5086, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 0: train loss=0.6891714915029803, val_recall=0.010019731856820245\n",
            "pos_score: tensor(0.5086, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 1: train loss=0.6889175122913965, val_recall=0.014331855319723606\n",
            "pos_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5082, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 2: train loss=0.6886758278391685, val_recall=0.01599755915180525\n",
            "pos_score: tensor(0.5096, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5095, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 3: train loss=0.6884337556770279, val_recall=0.020752480717818673\n",
            "pos_score: tensor(0.5103, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5096, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 4: train loss=0.688174396319077, val_recall=0.029871899715920514\n",
            "pos_score: tensor(0.5108, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5106, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 5: train loss=0.6878664664910159, val_recall=0.03363933389929924\n",
            "pos_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 6: train loss=0.6875960827672983, val_recall=0.03782635138787652\n",
            "pos_score: tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5121, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 7: train loss=0.6872811986537554, val_recall=0.04130906162968555\n",
            "pos_score: tensor(0.5125, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5135, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 8: train loss=0.6869465976732393, val_recall=0.046214192444695046\n",
            "pos_score: tensor(0.5131, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 9: train loss=0.6866116672074964, val_recall=0.04921410991601633\n",
            "pos_score: tensor(0.5143, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5144, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "Epoch 10: train loss=0.6861985921540059, val_recall=0.05566556012829844\n",
            "pos_score: tensor(0.5151, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5155, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "Epoch 11: train loss=0.6858286548739221\n",
            "pos_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5157, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "Epoch 12: train loss=0.6854010523617656\n",
            "pos_score: tensor(0.5174, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 13: train loss=0.6849498238514093\n",
            "pos_score: tensor(0.5181, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5188, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 14: train loss=0.6844474806152188\n",
            "pos_score: tensor(0.5193, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5203, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 15: train loss=0.6838387585766803, val_recall=0.10955109984273911\n",
            "pos_score: tensor(0.5207, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5211, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 16: train loss=0.6833112609656042\n",
            "pos_score: tensor(0.5222, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5225, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 17: train loss=0.6826034500279865\n",
            "pos_score: tensor(0.5238, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5018, grad_fn=<MeanBackward0>)\n",
            "Epoch 18: train loss=0.6819658220117998\n",
            "pos_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5263, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 19: train loss=0.6812914348729144\n",
            "pos_score: tensor(0.5271, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5278, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 20: train loss=0.6804372204887736, val_recall=0.17087083572770537\n",
            "pos_score: tensor(0.5285, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5315, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5024, grad_fn=<MeanBackward0>)\n",
            "Epoch 21: train loss=0.6796137437782499\n",
            "pos_score: tensor(0.5313, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5313, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "Epoch 22: train loss=0.6786636598811154\n",
            "pos_score: tensor(0.5337, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5022, grad_fn=<MeanBackward0>)\n",
            "Epoch 23: train loss=0.6776923453817422\n",
            "pos_score: tensor(0.5358, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5027, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5367, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "Epoch 24: train loss=0.6767260562513622\n",
            "pos_score: tensor(0.5370, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "Epoch 25: train loss=0.6756268217500332, val_recall=0.21078489706649628\n",
            "pos_score: tensor(0.5400, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5452, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5056, grad_fn=<MeanBackward0>)\n",
            "Epoch 26: train loss=0.6745996059473733\n",
            "pos_score: tensor(0.5442, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5040, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5446, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 27: train loss=0.6732146904489209\n",
            "pos_score: tensor(0.5478, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5464, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "Epoch 28: train loss=0.6720383705610754\n",
            "pos_score: tensor(0.5499, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5538, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "Epoch 29: train loss=0.6706539960705458\n",
            "pos_score: tensor(0.5543, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5054, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5547, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "Epoch 30: train loss=0.6691702516701049, val_recall=0.2467864016764393\n",
            "pos_score: tensor(0.5582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5064, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "Epoch 31: train loss=0.6677402624967133\n",
            "pos_score: tensor(0.5613, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "Epoch 32: train loss=0.6659575291833769\n",
            "pos_score: tensor(0.5670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5627, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "Epoch 33: train loss=0.6645130542537914\n",
            "pos_score: tensor(0.5676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "Epoch 34: train loss=0.6627724420143066\n",
            "pos_score: tensor(0.5751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "Epoch 35: train loss=0.6607920997390225, val_recall=0.2547529590140001\n",
            "pos_score: tensor(0.5795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5095, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "Epoch 36: train loss=0.6589968654290381\n",
            "pos_score: tensor(0.5848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "Epoch 37: train loss=0.6572429698892687\n",
            "pos_score: tensor(0.5895, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5116, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5885, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5101, grad_fn=<MeanBackward0>)\n",
            "Epoch 38: train loss=0.6553350669977289\n",
            "pos_score: tensor(0.5944, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5950, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "Epoch 39: train loss=0.6531281434915294\n",
            "pos_score: tensor(0.6001, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5131, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5989, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "Epoch 40: train loss=0.6513535333849784, val_recall=0.25326813053610403\n",
            "pos_score: tensor(0.6049, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5133, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6060, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "Epoch 41: train loss=0.6489521918459212\n",
            "pos_score: tensor(0.6116, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6071, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5121, grad_fn=<MeanBackward0>)\n",
            "Epoch 42: train loss=0.6468505396689083\n",
            "pos_score: tensor(0.6176, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5170, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6100, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "Epoch 43: train loss=0.6452427440219455\n",
            "pos_score: tensor(0.6236, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5176, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6150, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5134, grad_fn=<MeanBackward0>)\n",
            "Epoch 44: train loss=0.6428202371010354\n",
            "pos_score: tensor(0.6225, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6438, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5219, grad_fn=<MeanBackward0>)\n",
            "Epoch 45: train loss=0.6406109869304308, val_recall=0.25549846807839993\n",
            "pos_score: tensor(0.6345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5199, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6286, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "Epoch 46: train loss=0.6386865083638705\n",
            "pos_score: tensor(0.6392, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5202, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6382, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5180, grad_fn=<MeanBackward0>)\n",
            "Epoch 47: train loss=0.6363180164326673\n",
            "pos_score: tensor(0.6405, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5197, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6578, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5257, grad_fn=<MeanBackward0>)\n",
            "Epoch 48: train loss=0.6343739164027962\n",
            "pos_score: tensor(0.6520, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5178, grad_fn=<MeanBackward0>)\n",
            "Epoch 49: train loss=0.6319983721131068\n",
            "pos_score: tensor(0.6557, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5228, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6587, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5234, grad_fn=<MeanBackward0>)\n",
            "Epoch 50: train loss=0.6299019390055308, val_recall=0.2555053454682929\n",
            "pos_score: tensor(0.6633, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5225, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6579, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "Epoch 51: train loss=0.626936208533678\n",
            "pos_score: tensor(0.6692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5263, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6627, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5236, grad_fn=<MeanBackward0>)\n",
            "Epoch 52: train loss=0.6260726711455284\n",
            "pos_score: tensor(0.6759, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5269, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5208, grad_fn=<MeanBackward0>)\n",
            "Epoch 53: train loss=0.6234651504322065\n",
            "pos_score: tensor(0.6791, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5267, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5263, grad_fn=<MeanBackward0>)\n",
            "Epoch 54: train loss=0.6214339317750748\n",
            "pos_score: tensor(0.6846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5264, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6851, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5287, grad_fn=<MeanBackward0>)\n",
            "Epoch 55: train loss=0.6190842429860791, val_recall=0.2547336232718412\n",
            "pos_score: tensor(0.6912, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5281, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6865, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5254, grad_fn=<MeanBackward0>)\n",
            "Epoch 56: train loss=0.6169292213099032\n",
            "pos_score: tensor(0.6964, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6923, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5280, grad_fn=<MeanBackward0>)\n",
            "Epoch 57: train loss=0.6153182297201762\n",
            "pos_score: tensor(0.6996, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5297, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7056, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5329, grad_fn=<MeanBackward0>)\n",
            "Epoch 58: train loss=0.6134994486664025\n",
            "pos_score: tensor(0.7084, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5316, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6979, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5271, grad_fn=<MeanBackward0>)\n",
            "Epoch 59: train loss=0.6113031526038972\n",
            "pos_score: tensor(0.7045, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5274, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7308, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5425, grad_fn=<MeanBackward0>)\n",
            "Epoch 60: train loss=0.6093648249165051, val_recall=0.2531903369798547\n",
            "pos_score: tensor(0.7152, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5318, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7204, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5344, grad_fn=<MeanBackward0>)\n",
            "Epoch 61: train loss=0.6076187030435983\n",
            "pos_score: tensor(0.7132, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5308, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7421, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5411, grad_fn=<MeanBackward0>)\n",
            "Epoch 62: train loss=0.6060545713980161\n",
            "pos_score: tensor(0.7214, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5344, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5393, grad_fn=<MeanBackward0>)\n",
            "Epoch 63: train loss=0.6048141823565554\n",
            "pos_score: tensor(0.7329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5345, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7228, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5325, grad_fn=<MeanBackward0>)\n",
            "Epoch 64: train loss=0.6021395648699019\n",
            "pos_score: tensor(0.7380, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5357, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7260, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "Epoch 65: train loss=0.6006427069894001, val_recall=0.2521793606655855\n",
            "pos_score: tensor(0.7403, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5335, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7384, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5345, grad_fn=<MeanBackward0>)\n",
            "Epoch 66: train loss=0.5980401128048316\n",
            "pos_score: tensor(0.7483, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5269, grad_fn=<MeanBackward0>)\n",
            "Epoch 67: train loss=0.5964185095849962\n",
            "pos_score: tensor(0.7415, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5347, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7686, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5448, grad_fn=<MeanBackward0>)\n",
            "Epoch 68: train loss=0.5958558141497896\n",
            "pos_score: tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5339, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5352, grad_fn=<MeanBackward0>)\n",
            "Epoch 69: train loss=0.5927495002810519\n",
            "pos_score: tensor(0.7546, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5372, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7642, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5400, grad_fn=<MeanBackward0>)\n",
            "Epoch 70: train loss=0.5926472567207661, val_recall=0.2566565414859206\n",
            "pos_score: tensor(0.7645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5408, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7465, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "Epoch 71: train loss=0.5917826548086859\n",
            "pos_score: tensor(0.7690, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5386, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7487, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5307, grad_fn=<MeanBackward0>)\n",
            "Epoch 72: train loss=0.5888817879206759\n",
            "pos_score: tensor(0.7676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5391, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7717, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5424, grad_fn=<MeanBackward0>)\n",
            "Epoch 73: train loss=0.5885740170649744\n",
            "pos_score: tensor(0.7715, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7746, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5392, grad_fn=<MeanBackward0>)\n",
            "Epoch 74: train loss=0.5865766996830966\n",
            "pos_score: tensor(0.7782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7664, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5351, grad_fn=<MeanBackward0>)\n",
            "Epoch 75: train loss=0.5847280796394492, val_recall=0.25586220295328044\n",
            "pos_score: tensor(0.7815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5411, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5375, grad_fn=<MeanBackward0>)\n",
            "Epoch 76: train loss=0.5840964431021887\n",
            "pos_score: tensor(0.7867, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5424, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "Epoch 77: train loss=0.5826572073660001\n",
            "pos_score: tensor(0.7841, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5406, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7931, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5452, grad_fn=<MeanBackward0>)\n",
            "Epoch 78: train loss=0.5818996422463644\n",
            "pos_score: tensor(0.7930, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5395, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5347, grad_fn=<MeanBackward0>)\n",
            "Epoch 79: train loss=0.5791656515324862\n",
            "pos_score: tensor(0.7932, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5415, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7909, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5380, grad_fn=<MeanBackward0>)\n",
            "Epoch 80: train loss=0.5787444649192788, val_recall=0.25730645483080794\n",
            "pos_score: tensor(0.7977, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5418, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7893, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5400, grad_fn=<MeanBackward0>)\n",
            "Epoch 81: train loss=0.5778191672782748\n",
            "pos_score: tensor(0.7980, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5407, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8016, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5394, grad_fn=<MeanBackward0>)\n",
            "Epoch 82: train loss=0.5760801972647694\n",
            "pos_score: tensor(0.8031, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5396, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7966, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5349, grad_fn=<MeanBackward0>)\n",
            "Epoch 83: train loss=0.5741016998669944\n",
            "pos_score: tensor(0.8038, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5427, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8074, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5434, grad_fn=<MeanBackward0>)\n",
            "Epoch 84: train loss=0.5748431098048762\n",
            "pos_score: tensor(0.8101, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5445, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7979, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5426, grad_fn=<MeanBackward0>)\n",
            "Epoch 85: train loss=0.5740941466419458, val_recall=0.2573385493169752\n",
            "pos_score: tensor(0.8089, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5393, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8145, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5445, grad_fn=<MeanBackward0>)\n",
            "Epoch 86: train loss=0.5715708914557123\n",
            "pos_score: tensor(0.8095, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5382, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8233, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5459, grad_fn=<MeanBackward0>)\n",
            "Epoch 87: train loss=0.5702441547685689\n",
            "pos_score: tensor(0.8100, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5378, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8320, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5475, grad_fn=<MeanBackward0>)\n",
            "Epoch 88: train loss=0.5692145300474138\n",
            "pos_score: tensor(0.8177, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5404, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8190, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5404, grad_fn=<MeanBackward0>)\n",
            "Epoch 89: train loss=0.5682645407014573\n",
            "pos_score: tensor(0.8207, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5430, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5312, grad_fn=<MeanBackward0>)\n",
            "Epoch 90: train loss=0.5671814194822733, val_recall=0.2539365337832439\n",
            "pos_score: tensor(0.8259, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5381, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8128, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5372, grad_fn=<MeanBackward0>)\n",
            "Epoch 91: train loss=0.5652676399254741\n",
            "pos_score: tensor(0.8208, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5387, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8392, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5466, grad_fn=<MeanBackward0>)\n",
            "Epoch 92: train loss=0.5654518691658217\n",
            "pos_score: tensor(0.8293, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5362, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8217, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5431, grad_fn=<MeanBackward0>)\n",
            "Epoch 93: train loss=0.5632560847271668\n",
            "pos_score: tensor(0.8285, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5361, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8342, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5442, grad_fn=<MeanBackward0>)\n",
            "Epoch 94: train loss=0.5624844978692609\n",
            "pos_score: tensor(0.8345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5434, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8214, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5334, grad_fn=<MeanBackward0>)\n",
            "Epoch 95: train loss=0.5630179759355741, val_recall=0.2522419449136117\n",
            "pos_score: tensor(0.8341, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5368, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8343, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5431, grad_fn=<MeanBackward0>)\n",
            "Epoch 96: train loss=0.5608341183826091\n",
            "pos_score: tensor(0.8363, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5396, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8360, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5315, grad_fn=<MeanBackward0>)\n",
            "Epoch 97: train loss=0.5598553289002726\n",
            "pos_score: tensor(0.8420, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5403, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8235, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5338, grad_fn=<MeanBackward0>)\n",
            "Epoch 98: train loss=0.5595017700942515\n",
            "pos_score: tensor(0.8404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5393, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8406, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5409, grad_fn=<MeanBackward0>)\n",
            "Epoch 99: train loss=0.5589778445473921\n",
            "pos_score: tensor(0.8451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5420, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8322, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5353, grad_fn=<MeanBackward0>)\n",
            "Epoch 100: train loss=0.5585856474233375, val_recall=0.2529640708523754\n",
            "pos_score: tensor(0.8449, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8424, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5383, grad_fn=<MeanBackward0>)\n",
            "Epoch 101: train loss=0.5569527430839979\n",
            "pos_score: tensor(0.8460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5383, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8471, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5354, grad_fn=<MeanBackward0>)\n",
            "Epoch 102: train loss=0.5557397136507506\n",
            "pos_score: tensor(0.8506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5368, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8398, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5382, grad_fn=<MeanBackward0>)\n",
            "Epoch 103: train loss=0.5548964580496845\n",
            "pos_score: tensor(0.8518, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5428, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8433, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5325, grad_fn=<MeanBackward0>)\n",
            "Epoch 104: train loss=0.5555843544505051\n",
            "pos_score: tensor(0.8547, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5327, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8412, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5280, grad_fn=<MeanBackward0>)\n",
            "Epoch 105: train loss=0.5511424347106941, val_recall=0.2540552833820628\n",
            "pos_score: tensor(0.8573, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5365, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8386, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5272, grad_fn=<MeanBackward0>)\n",
            "Epoch 106: train loss=0.5517136237944612\n",
            "pos_score: tensor(0.8581, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5376, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8435, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5319, grad_fn=<MeanBackward0>)\n",
            "Epoch 107: train loss=0.5518747217972519\n",
            "pos_score: tensor(0.8603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5397, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8452, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "Epoch 108: train loss=0.5512059658613944\n",
            "pos_score: tensor(0.8574, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5356, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8634, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5417, grad_fn=<MeanBackward0>)\n",
            "Epoch 109: train loss=0.5506767182649807\n",
            "pos_score: tensor(0.8570, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5343, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5398, grad_fn=<MeanBackward0>)\n",
            "Epoch 110: train loss=0.5495840898625299, val_recall=0.25605501675094694\n",
            "pos_score: tensor(0.8563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5338, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8770, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5437, grad_fn=<MeanBackward0>)\n",
            "Epoch 111: train loss=0.5491758397003382\n",
            "pos_score: tensor(0.8626, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5371, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8669, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "Epoch 112: train loss=0.5490304726670722\n",
            "pos_score: tensor(0.8698, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5352, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8468, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5323, grad_fn=<MeanBackward0>)\n",
            "Epoch 113: train loss=0.547241375211247\n",
            "pos_score: tensor(0.8642, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5339, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5406, grad_fn=<MeanBackward0>)\n",
            "Epoch 114: train loss=0.5470425511766207\n",
            "pos_score: tensor(0.8648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5357, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5352, grad_fn=<MeanBackward0>)\n",
            "Epoch 115: train loss=0.5465166106336588, val_recall=0.2569215678774634\n",
            "pos_score: tensor(0.8680, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5367, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8745, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5386, grad_fn=<MeanBackward0>)\n",
            "Epoch 116: train loss=0.5464998689639384\n",
            "pos_score: tensor(0.8713, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5317, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5372, grad_fn=<MeanBackward0>)\n",
            "Epoch 117: train loss=0.5442219091141587\n",
            "pos_score: tensor(0.8721, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5343, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8728, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5283, grad_fn=<MeanBackward0>)\n",
            "Epoch 118: train loss=0.5437748229747655\n",
            "pos_score: tensor(0.8753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5336, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8671, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5294, grad_fn=<MeanBackward0>)\n",
            "Epoch 119: train loss=0.543095497383001\n",
            "pos_score: tensor(0.8718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5305, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5399, grad_fn=<MeanBackward0>)\n",
            "Epoch 120: train loss=0.5428139276784558, val_recall=0.2590157330998782\n",
            "pos_score: tensor(0.8773, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5316, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5315, grad_fn=<MeanBackward0>)\n",
            "Epoch 121: train loss=0.5417241871895095\n",
            "pos_score: tensor(0.8785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5278, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8736, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "Epoch 122: train loss=0.5394295490149296\n",
            "pos_score: tensor(0.8754, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5288, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8885, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5337, grad_fn=<MeanBackward0>)\n",
            "Epoch 123: train loss=0.5400443271773531\n",
            "pos_score: tensor(0.8742, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8945, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5389, grad_fn=<MeanBackward0>)\n",
            "Epoch 124: train loss=0.5403865475570206\n",
            "pos_score: tensor(0.8782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5330, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8908, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5337, grad_fn=<MeanBackward0>)\n",
            "Epoch 125: train loss=0.5405297544374003, val_recall=0.26134418807131415\n",
            "pos_score: tensor(0.8788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5275, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8919, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5344, grad_fn=<MeanBackward0>)\n",
            "Epoch 126: train loss=0.5385239851893545\n",
            "pos_score: tensor(0.8829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8854, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5279, grad_fn=<MeanBackward0>)\n",
            "Epoch 127: train loss=0.5377573462682168\n",
            "pos_score: tensor(0.8849, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5279, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5358, grad_fn=<MeanBackward0>)\n",
            "Epoch 128: train loss=0.5376590250793065\n",
            "pos_score: tensor(0.8870, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5308, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5254, grad_fn=<MeanBackward0>)\n",
            "Epoch 129: train loss=0.5373302419053291\n",
            "pos_score: tensor(0.8853, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5223, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8917, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "Epoch 130: train loss=0.5343395825726871, val_recall=0.25915717808534394\n",
            "pos_score: tensor(0.8889, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5325, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5271, grad_fn=<MeanBackward0>)\n",
            "Epoch 131: train loss=0.5372358711611717\n",
            "pos_score: tensor(0.8902, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5274, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8845, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "Epoch 132: train loss=0.5352735868128586\n",
            "pos_score: tensor(0.8887, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5286, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8940, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5342, grad_fn=<MeanBackward0>)\n",
            "Epoch 133: train loss=0.5357949139232812\n",
            "pos_score: tensor(0.8914, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5249, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8901, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5266, grad_fn=<MeanBackward0>)\n",
            "Epoch 134: train loss=0.5335684546604227\n",
            "pos_score: tensor(0.8906, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8969, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "Epoch 135: train loss=0.5334617417108238, val_recall=0.26060142996287144\n",
            "pos_score: tensor(0.8958, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8833, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "Epoch 136: train loss=0.5325535476831113\n",
            "pos_score: tensor(0.8961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5261, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8854, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5222, grad_fn=<MeanBackward0>)\n",
            "Epoch 137: train loss=0.532584458038103\n",
            "pos_score: tensor(0.8959, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5251, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8923, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5411, grad_fn=<MeanBackward0>)\n",
            "Epoch 138: train loss=0.5333758033748776\n",
            "pos_score: tensor(0.8961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5269, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5271, grad_fn=<MeanBackward0>)\n",
            "Epoch 139: train loss=0.5323876230733968\n",
            "pos_score: tensor(0.8980, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8940, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5206, grad_fn=<MeanBackward0>)\n",
            "Epoch 140: train loss=0.5301677837836004, val_recall=0.26060142996287144\n",
            "pos_score: tensor(0.8974, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5243, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9000, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "Epoch 141: train loss=0.5304486824443814\n",
            "pos_score: tensor(0.8957, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5230, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9081, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5286, grad_fn=<MeanBackward0>)\n",
            "Epoch 142: train loss=0.5302666893239378\n",
            "pos_score: tensor(0.9011, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8947, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5130, grad_fn=<MeanBackward0>)\n",
            "Epoch 143: train loss=0.5283063253672692\n",
            "pos_score: tensor(0.9009, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5215, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9000, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5180, grad_fn=<MeanBackward0>)\n",
            "Epoch 144: train loss=0.5280540044136999\n",
            "pos_score: tensor(0.9014, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5221, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9024, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5177, grad_fn=<MeanBackward0>)\n",
            "Epoch 145: train loss=0.5279571925804167, val_recall=0.26198791176529773\n",
            "pos_score: tensor(0.9028, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5194, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9015, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5180, grad_fn=<MeanBackward0>)\n",
            "Epoch 146: train loss=0.5267984681520745\n",
            "pos_score: tensor(0.9056, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8934, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "Epoch 147: train loss=0.5282721801163034\n",
            "pos_score: tensor(0.9041, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5233, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9045, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5224, grad_fn=<MeanBackward0>)\n",
            "Epoch 148: train loss=0.5276257673494402\n",
            "pos_score: tensor(0.9063, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5210, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9006, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5222, grad_fn=<MeanBackward0>)\n",
            "Epoch 149: train loss=0.5266847861583573\n",
            "pos_score: tensor(0.9062, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9047, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5222, grad_fn=<MeanBackward0>)\n",
            "Epoch 150: train loss=0.5274081587727506, val_recall=0.26227676214080325\n",
            "pos_score: tensor(0.9042, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5213, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9146, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5209, grad_fn=<MeanBackward0>)\n",
            "Epoch 151: train loss=0.5260406759039501\n",
            "pos_score: tensor(0.9070, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9093, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5160, grad_fn=<MeanBackward0>)\n",
            "Epoch 152: train loss=0.5237317428604212\n",
            "pos_score: tensor(0.9098, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5169, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9029, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5173, grad_fn=<MeanBackward0>)\n",
            "Epoch 153: train loss=0.5238701740964612\n",
            "pos_score: tensor(0.9084, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5212, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9113, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5200, grad_fn=<MeanBackward0>)\n",
            "Epoch 154: train loss=0.5250517285902719\n",
            "pos_score: tensor(0.9120, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5213, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9021, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "Epoch 155: train loss=0.5242646860886677, val_recall=0.2626233825914098\n",
            "pos_score: tensor(0.9105, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5236, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9111, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "Epoch 156: train loss=0.5256493113960968\n",
            "pos_score: tensor(0.9148, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5207, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8983, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5170, grad_fn=<MeanBackward0>)\n",
            "Epoch 157: train loss=0.5239537004769366\n",
            "pos_score: tensor(0.9101, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5178, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9180, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5139, grad_fn=<MeanBackward0>)\n",
            "Epoch 158: train loss=0.5222964991862091\n",
            "pos_score: tensor(0.9126, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5162, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9138, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5141, grad_fn=<MeanBackward0>)\n",
            "Epoch 159: train loss=0.5215888054918388\n",
            "pos_score: tensor(0.9120, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5177, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9186, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5182, grad_fn=<MeanBackward0>)\n",
            "Epoch 160: train loss=0.5223256168517221, val_recall=0.26341772112404993\n",
            "pos_score: tensor(0.9125, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5171, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9196, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "Epoch 161: train loss=0.522369221088617\n",
            "pos_score: tensor(0.9116, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5090, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9243, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5195, grad_fn=<MeanBackward0>)\n",
            "Epoch 162: train loss=0.5192620701014947\n",
            "pos_score: tensor(0.9133, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5135, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9226, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5191, grad_fn=<MeanBackward0>)\n",
            "Epoch 163: train loss=0.5202711682979464\n",
            "pos_score: tensor(0.9131, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5163, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9251, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5132, grad_fn=<MeanBackward0>)\n",
            "Epoch 164: train loss=0.5201994484643296\n",
            "pos_score: tensor(0.9165, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5221, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9183, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5211, grad_fn=<MeanBackward0>)\n",
            "Epoch 165: train loss=0.5225214134051609, val_recall=0.2637065714995554\n",
            "pos_score: tensor(0.9175, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5167, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9178, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5221, grad_fn=<MeanBackward0>)\n",
            "Epoch 166: train loss=0.5207686217261499\n",
            "pos_score: tensor(0.9175, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9208, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5163, grad_fn=<MeanBackward0>)\n",
            "Epoch 167: train loss=0.5212258352791751\n",
            "pos_score: tensor(0.9205, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9124, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5024, grad_fn=<MeanBackward0>)\n",
            "Epoch 168: train loss=0.5185313818707717\n",
            "pos_score: tensor(0.9190, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9208, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "Epoch 169: train loss=0.5191624373653102\n",
            "pos_score: tensor(0.9221, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9122, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5100, grad_fn=<MeanBackward0>)\n",
            "Epoch 170: train loss=0.5180845060978923, val_recall=0.2652952485648356\n",
            "pos_score: tensor(0.9203, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5112, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9216, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5141, grad_fn=<MeanBackward0>)\n",
            "Epoch 171: train loss=0.5172027983240929\n",
            "pos_score: tensor(0.9195, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5111, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9263, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "Epoch 172: train loss=0.5160494297995925\n",
            "pos_score: tensor(0.9231, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9176, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 173: train loss=0.5163706007725839\n",
            "pos_score: tensor(0.9227, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5153, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9212, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "Epoch 174: train loss=0.5172653558789815\n",
            "pos_score: tensor(0.9238, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9199, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "Epoch 175: train loss=0.5162810848046321, val_recall=0.26608958709747565\n",
            "pos_score: tensor(0.9249, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5132, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9186, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5071, grad_fn=<MeanBackward0>)\n",
            "Epoch 176: train loss=0.5162015304101252\n",
            "pos_score: tensor(0.9231, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9277, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5147, grad_fn=<MeanBackward0>)\n",
            "Epoch 177: train loss=0.5148886454332351\n",
            "pos_score: tensor(0.9269, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5082, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9164, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5154, grad_fn=<MeanBackward0>)\n",
            "Epoch 178: train loss=0.5149903959751427\n",
            "pos_score: tensor(0.9242, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9287, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "Epoch 179: train loss=0.5157966735887924\n",
            "pos_score: tensor(0.9274, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5137, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9196, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5068, grad_fn=<MeanBackward0>)\n",
            "Epoch 180: train loss=0.5155527897107864, val_recall=0.26695613822399217\n",
            "pos_score: tensor(0.9250, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5143, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9312, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "Epoch 181: train loss=0.5160188497609999\n",
            "pos_score: tensor(0.9264, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "Epoch 182: train loss=0.5125489050787683\n",
            "pos_score: tensor(0.9280, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5111, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9254, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "Epoch 183: train loss=0.5145674638361567\n",
            "pos_score: tensor(0.9272, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9304, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5146, grad_fn=<MeanBackward0>)\n",
            "Epoch 184: train loss=0.5137006966349713\n",
            "pos_score: tensor(0.9295, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5112, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9243, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "Epoch 185: train loss=0.5134611329721618, val_recall=0.26765763199307696\n",
            "pos_score: tensor(0.9257, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9377, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5106, grad_fn=<MeanBackward0>)\n",
            "Epoch 186: train loss=0.5128028272911127\n",
            "pos_score: tensor(0.9295, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9294, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5090, grad_fn=<MeanBackward0>)\n",
            "Epoch 187: train loss=0.5122501906125744\n",
            "pos_score: tensor(0.9306, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9278, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5097, grad_fn=<MeanBackward0>)\n",
            "Epoch 188: train loss=0.5119527195641659\n",
            "pos_score: tensor(0.9307, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9297, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 189: train loss=0.5115194803611133\n",
            "pos_score: tensor(0.9308, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5050, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9315, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "Epoch 190: train loss=0.5106911888825432, val_recall=0.2660578452979696\n",
            "pos_score: tensor(0.9337, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5092, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9221, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5099, grad_fn=<MeanBackward0>)\n",
            "Epoch 191: train loss=0.5123660660806627\n",
            "pos_score: tensor(0.9316, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9328, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "Epoch 192: train loss=0.5107209378607186\n",
            "pos_score: tensor(0.9324, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9324, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "Epoch 193: train loss=0.5113749463543066\n",
            "pos_score: tensor(0.9335, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5075, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9302, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5114, grad_fn=<MeanBackward0>)\n",
            "Epoch 194: train loss=0.5114597533475279\n",
            "pos_score: tensor(0.9333, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9333, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "Epoch 195: train loss=0.5114374447041524, val_recall=0.2649024437959477\n",
            "pos_score: tensor(0.9313, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9409, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "Epoch 196: train loss=0.5093795513301153\n",
            "pos_score: tensor(0.9329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9383, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "Epoch 197: train loss=0.5095178949787095\n",
            "pos_score: tensor(0.9347, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9343, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "Epoch 198: train loss=0.5087842799718486\n",
            "pos_score: tensor(0.9356, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9332, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "Epoch 199: train loss=0.5078375655300252\n",
            "pos_score: tensor(0.9363, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5047, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9326, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 200: train loss=0.5087059745043077, val_recall=0.2637999981961017\n",
            "pos_score: tensor(0.9367, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9332, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5024, grad_fn=<MeanBackward0>)\n",
            "Epoch 201: train loss=0.5080268614369081\n",
            "pos_score: tensor(0.9365, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5061, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9358, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5088, grad_fn=<MeanBackward0>)\n",
            "Epoch 202: train loss=0.5095407230887921\n",
            "pos_score: tensor(0.9375, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9338, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5101, grad_fn=<MeanBackward0>)\n",
            "Epoch 203: train loss=0.5086310346452418\n",
            "pos_score: tensor(0.9370, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9378, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "Epoch 204: train loss=0.5075405747500248\n",
            "pos_score: tensor(0.9367, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5056, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "Epoch 205: train loss=0.5081854672654444, val_recall=0.26554421007896173\n",
            "pos_score: tensor(0.9387, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4966, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9354, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5105, grad_fn=<MeanBackward0>)\n",
            "Epoch 206: train loss=0.5060354173476482\n",
            "pos_score: tensor(0.9388, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9372, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4968, grad_fn=<MeanBackward0>)\n",
            "Epoch 207: train loss=0.5064668294155237\n",
            "pos_score: tensor(0.9388, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9390, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4997, grad_fn=<MeanBackward0>)\n",
            "Epoch 208: train loss=0.5070321712287595\n",
            "pos_score: tensor(0.9382, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9424, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4975, grad_fn=<MeanBackward0>)\n",
            "Epoch 209: train loss=0.5069618427615985\n",
            "pos_score: tensor(0.9401, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9379, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "Epoch 210: train loss=0.505524877297971, val_recall=0.26626908697368273\n",
            "pos_score: tensor(0.9381, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4980, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9458, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4989, grad_fn=<MeanBackward0>)\n",
            "Epoch 211: train loss=0.5048403886183557\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4986, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "Epoch 212: train loss=0.5049280984329029\n",
            "pos_score: tensor(0.9412, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9394, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "Epoch 213: train loss=0.5057518546677386\n",
            "pos_score: tensor(0.9393, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9465, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4989, grad_fn=<MeanBackward0>)\n",
            "Epoch 214: train loss=0.5049288476388321\n",
            "pos_score: tensor(0.9397, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9474, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5039, grad_fn=<MeanBackward0>)\n",
            "Epoch 215: train loss=0.5052323470361177, val_recall=0.26772342568971985\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9467, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "Epoch 216: train loss=0.5045948404989603\n",
            "pos_score: tensor(0.9417, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9441, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4994, grad_fn=<MeanBackward0>)\n",
            "Epoch 217: train loss=0.5050187598362124\n",
            "pos_score: tensor(0.9433, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9404, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5057, grad_fn=<MeanBackward0>)\n",
            "Epoch 218: train loss=0.504909912185715\n",
            "pos_score: tensor(0.9430, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9428, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 219: train loss=0.504519887026784\n",
            "pos_score: tensor(0.9434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4962, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9431, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4886, grad_fn=<MeanBackward0>)\n",
            "Epoch 220: train loss=0.5019940912771493, val_recall=0.2690954649733709\n",
            "pos_score: tensor(0.9439, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9428, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "Epoch 221: train loss=0.5042586124560314\n",
            "pos_score: tensor(0.9443, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5049, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9429, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4931, grad_fn=<MeanBackward0>)\n",
            "Epoch 222: train loss=0.5049495131184953\n",
            "pos_score: tensor(0.9426, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9496, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4956, grad_fn=<MeanBackward0>)\n",
            "Epoch 223: train loss=0.5034077627959131\n",
            "pos_score: tensor(0.9452, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4962, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9433, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "Epoch 224: train loss=0.502343766521148\n",
            "pos_score: tensor(0.9450, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4985, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9453, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4871, grad_fn=<MeanBackward0>)\n",
            "Epoch 225: train loss=0.501923733580429, val_recall=0.26852808030719943\n",
            "pos_score: tensor(0.9445, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9480, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4953, grad_fn=<MeanBackward0>)\n",
            "Epoch 226: train loss=0.5036804279011291\n",
            "pos_score: tensor(0.9451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4989, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9478, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4985, grad_fn=<MeanBackward0>)\n",
            "Epoch 227: train loss=0.5030627578931167\n",
            "pos_score: tensor(0.9465, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4997, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9441, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "Epoch 228: train loss=0.5033942797318897\n",
            "pos_score: tensor(0.9463, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4994, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4902, grad_fn=<MeanBackward0>)\n",
            "Epoch 229: train loss=0.5019894714136807\n",
            "pos_score: tensor(0.9481, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9415, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4987, grad_fn=<MeanBackward0>)\n",
            "Epoch 230: train loss=0.5029132373639659, val_recall=0.2667949780541665\n",
            "pos_score: tensor(0.9469, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9476, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4991, grad_fn=<MeanBackward0>)\n",
            "Epoch 231: train loss=0.5029865838177692\n",
            "pos_score: tensor(0.9483, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4887, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5037, grad_fn=<MeanBackward0>)\n",
            "Epoch 232: train loss=0.49956155545783765\n",
            "pos_score: tensor(0.9475, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9481, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "Epoch 233: train loss=0.5027425754930226\n",
            "pos_score: tensor(0.9471, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4921, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9509, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4918, grad_fn=<MeanBackward0>)\n",
            "Epoch 234: train loss=0.4995140987080011\n",
            "pos_score: tensor(0.9485, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9474, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4980, grad_fn=<MeanBackward0>)\n",
            "Epoch 235: train loss=0.5008042604010877, val_recall=0.26852808030719943\n",
            "pos_score: tensor(0.9484, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4967, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9494, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4893, grad_fn=<MeanBackward0>)\n",
            "Epoch 236: train loss=0.5003597859968882\n",
            "pos_score: tensor(0.9499, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9449, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4944, grad_fn=<MeanBackward0>)\n",
            "Epoch 237: train loss=0.4988682848940248\n",
            "pos_score: tensor(0.9497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4867, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9476, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4998, grad_fn=<MeanBackward0>)\n",
            "Epoch 238: train loss=0.49816695016330037\n",
            "pos_score: tensor(0.9501, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4953, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9477, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "Epoch 239: train loss=0.49995575788897656\n",
            "pos_score: tensor(0.9503, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9480, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4930, grad_fn=<MeanBackward0>)\n",
            "Epoch 240: train loss=0.4983128641239278, val_recall=0.26871483701550036\n",
            "pos_score: tensor(0.9508, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9476, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "Epoch 241: train loss=0.49915090181173905\n",
            "pos_score: tensor(0.9507, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4972, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4934, grad_fn=<MeanBackward0>)\n",
            "Epoch 242: train loss=0.5003223471191003\n",
            "pos_score: tensor(0.9508, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 243: train loss=0.49867856699137175\n",
            "pos_score: tensor(0.9494, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4969, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9555, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4886, grad_fn=<MeanBackward0>)\n",
            "Epoch 244: train loss=0.4995049726199004\n",
            "pos_score: tensor(0.9502, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4966, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9546, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "Epoch 245: train loss=0.49864823993285773, val_recall=0.2687870496093767\n",
            "pos_score: tensor(0.9511, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9534, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "Epoch 246: train loss=0.49757444703239023\n",
            "pos_score: tensor(0.9516, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4963, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9531, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "Epoch 247: train loss=0.4998860726079875\n",
            "pos_score: tensor(0.9524, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4938, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9515, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "Epoch 248: train loss=0.4980838124091582\n",
            "pos_score: tensor(0.9528, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4877, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9513, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4977, grad_fn=<MeanBackward0>)\n",
            "Epoch 249: train loss=0.4970292779974572\n",
            "pos_score: tensor(0.9530, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4857, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9517, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "Epoch 250: train loss=0.49463479075811606, val_recall=0.271071030792838\n",
            "pos_score: tensor(0.9532, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9521, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "Epoch 251: train loss=0.49569953669702077\n",
            "pos_score: tensor(0.9544, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4890, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9490, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4904, grad_fn=<MeanBackward0>)\n",
            "Epoch 252: train loss=0.49641808054663916\n",
            "pos_score: tensor(0.9528, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4905, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4860, grad_fn=<MeanBackward0>)\n",
            "Epoch 253: train loss=0.49645152122189895\n",
            "pos_score: tensor(0.9535, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4863, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9548, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "Epoch 254: train loss=0.49534818016727244\n",
            "pos_score: tensor(0.9541, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4976, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9542, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4949, grad_fn=<MeanBackward0>)\n",
            "Epoch 255: train loss=0.4993457707502444, val_recall=0.271648731543849\n",
            "pos_score: tensor(0.9538, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "Epoch 256: train loss=0.49720357147332567\n",
            "pos_score: tensor(0.9541, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9564, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4761, grad_fn=<MeanBackward0>)\n",
            "Epoch 257: train loss=0.4939088348841725\n",
            "pos_score: tensor(0.9541, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9574, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "Epoch 258: train loss=0.495416693053084\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9536, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "Epoch 259: train loss=0.49473815169370217\n",
            "pos_score: tensor(0.9558, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9542, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "Epoch 260: train loss=0.49409150477867403, val_recall=0.2711845077260723\n",
            "pos_score: tensor(0.9552, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9572, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "Epoch 261: train loss=0.49591927205715997\n",
            "pos_score: tensor(0.9559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4892, grad_fn=<MeanBackward0>)\n",
            "Epoch 262: train loss=0.49627775841757965\n",
            "pos_score: tensor(0.9562, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4880, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9558, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4898, grad_fn=<MeanBackward0>)\n",
            "Epoch 263: train loss=0.49514609486559946\n",
            "pos_score: tensor(0.9574, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9522, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4905, grad_fn=<MeanBackward0>)\n",
            "Epoch 264: train loss=0.4944062932114973\n",
            "pos_score: tensor(0.9569, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4879, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4900, grad_fn=<MeanBackward0>)\n",
            "Epoch 265: train loss=0.4949180329118773, val_recall=0.2729898225729816\n",
            "pos_score: tensor(0.9578, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4864, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9536, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "Epoch 266: train loss=0.49413825488020185\n",
            "pos_score: tensor(0.9583, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4888, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9528, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "Epoch 267: train loss=0.4951089380109684\n",
            "pos_score: tensor(0.9578, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4907, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4863, grad_fn=<MeanBackward0>)\n",
            "Epoch 268: train loss=0.4950920779844429\n",
            "pos_score: tensor(0.9575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4831, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9581, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4906, grad_fn=<MeanBackward0>)\n",
            "Epoch 269: train loss=0.49314176892162254\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9564, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4888, grad_fn=<MeanBackward0>)\n",
            "Epoch 270: train loss=0.4927892579841179, val_recall=0.2738264926261699\n",
            "pos_score: tensor(0.9581, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4865, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9577, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4922, grad_fn=<MeanBackward0>)\n",
            "Epoch 271: train loss=0.4941680712073101\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4835, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9585, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4878, grad_fn=<MeanBackward0>)\n",
            "Epoch 272: train loss=0.4929372630970103\n",
            "pos_score: tensor(0.9585, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9584, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "Epoch 273: train loss=0.4939978746889615\n",
            "pos_score: tensor(0.9588, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4839, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9583, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "Epoch 274: train loss=0.49317537142240064\n",
            "pos_score: tensor(0.9590, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4834, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9587, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4945, grad_fn=<MeanBackward0>)\n",
            "Epoch 275: train loss=0.49321811743925775, val_recall=0.2747755724314022\n",
            "pos_score: tensor(0.9579, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4838, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9628, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 276: train loss=0.49379568914577726\n",
            "pos_score: tensor(0.9592, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4854, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9601, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4809, grad_fn=<MeanBackward0>)\n",
            "Epoch 277: train loss=0.49241405274994393\n",
            "pos_score: tensor(0.9594, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4852, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9604, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4973, grad_fn=<MeanBackward0>)\n",
            "Epoch 278: train loss=0.49370975593006555\n",
            "pos_score: tensor(0.9600, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9590, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4881, grad_fn=<MeanBackward0>)\n",
            "Epoch 279: train loss=0.493049096483599\n",
            "pos_score: tensor(0.9601, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9595, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "Epoch 280: train loss=0.4930493349741065, val_recall=0.2737164543878821\n",
            "pos_score: tensor(0.9600, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4876, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9609, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "Epoch 281: train loss=0.49275073153601584\n",
            "pos_score: tensor(0.9598, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4891, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9624, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4887, grad_fn=<MeanBackward0>)\n",
            "Epoch 282: train loss=0.49384207552417286\n",
            "pos_score: tensor(0.9607, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4847, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4786, grad_fn=<MeanBackward0>)\n",
            "Epoch 283: train loss=0.49154439914308584\n",
            "pos_score: tensor(0.9601, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9626, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4825, grad_fn=<MeanBackward0>)\n",
            "Epoch 284: train loss=0.49367691721003615\n",
            "pos_score: tensor(0.9614, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9595, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4771, grad_fn=<MeanBackward0>)\n",
            "Epoch 285: train loss=0.49119682486557903, val_recall=0.2733553914185002\n",
            "pos_score: tensor(0.9619, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9586, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4919, grad_fn=<MeanBackward0>)\n",
            "Epoch 286: train loss=0.4915851536444581\n",
            "pos_score: tensor(0.9615, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4818, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9611, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "Epoch 287: train loss=0.49099327502231915\n",
            "pos_score: tensor(0.9613, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9625, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4828, grad_fn=<MeanBackward0>)\n",
            "Epoch 288: train loss=0.4907177711146931\n",
            "pos_score: tensor(0.9615, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4771, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9625, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "Epoch 289: train loss=0.4892544746239085\n",
            "pos_score: tensor(0.9622, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4772, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9611, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4773, grad_fn=<MeanBackward0>)\n",
            "Epoch 290: train loss=0.48869342350326805, val_recall=0.27354795833550394\n",
            "pos_score: tensor(0.9625, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4830, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9610, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4841, grad_fn=<MeanBackward0>)\n",
            "Epoch 291: train loss=0.4910236104351805\n",
            "pos_score: tensor(0.9616, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4829, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "Epoch 292: train loss=0.4896515520400929\n",
            "pos_score: tensor(0.9628, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4833, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9616, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "Epoch 293: train loss=0.49023275095058677\n",
            "pos_score: tensor(0.9619, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9655, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "Epoch 294: train loss=0.48901229073302915\n",
            "pos_score: tensor(0.9637, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9598, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "Epoch 295: train loss=0.48912919390571336, val_recall=0.2743732451226624\n",
            "pos_score: tensor(0.9625, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "Epoch 296: train loss=0.4874173809581162\n",
            "pos_score: tensor(0.9632, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4784, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9638, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4811, grad_fn=<MeanBackward0>)\n",
            "Epoch 297: train loss=0.4888919421193682\n",
            "pos_score: tensor(0.9641, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9612, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4892, grad_fn=<MeanBackward0>)\n",
            "Epoch 298: train loss=0.4897487654334964\n",
            "pos_score: tensor(0.9628, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4851, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4726, grad_fn=<MeanBackward0>)\n",
            "Epoch 299: train loss=0.48979508030976154\n",
            "pos_score: tensor(0.9634, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4799, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9652, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4799, grad_fn=<MeanBackward0>)\n",
            "Epoch 300: train loss=0.48901014337273696, val_recall=0.2760124354309497\n",
            "pos_score: tensor(0.9635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9657, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4756, grad_fn=<MeanBackward0>)\n",
            "Epoch 301: train loss=0.4886197845940297\n",
            "pos_score: tensor(0.9644, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9637, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "Epoch 302: train loss=0.4885732814812134\n",
            "pos_score: tensor(0.9641, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4781, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9655, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4826, grad_fn=<MeanBackward0>)\n",
            "Epoch 303: train loss=0.4885303434635536\n",
            "pos_score: tensor(0.9635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4801, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4778, grad_fn=<MeanBackward0>)\n",
            "Epoch 304: train loss=0.4885407184653002\n",
            "pos_score: tensor(0.9648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4743, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "Epoch 305: train loss=0.48713551460497817, val_recall=0.2765602551086326\n",
            "pos_score: tensor(0.9647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9656, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "Epoch 306: train loss=0.4893441869376694\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9654, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4729, grad_fn=<MeanBackward0>)\n",
            "Epoch 307: train loss=0.48840918892977375\n",
            "pos_score: tensor(0.9653, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4802, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9653, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4669, grad_fn=<MeanBackward0>)\n",
            "Epoch 308: train loss=0.4872114321357967\n",
            "pos_score: tensor(0.9658, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9641, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4792, grad_fn=<MeanBackward0>)\n",
            "Epoch 309: train loss=0.48781493600267095\n",
            "pos_score: tensor(0.9652, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4773, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "Epoch 310: train loss=0.4882971206597522, val_recall=0.27881428407335296\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4755, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9655, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4754, grad_fn=<MeanBackward0>)\n",
            "Epoch 311: train loss=0.4866754945533743\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4828, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "Epoch 312: train loss=0.48912647915576984\n",
            "pos_score: tensor(0.9656, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9678, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4660, grad_fn=<MeanBackward0>)\n",
            "Epoch 313: train loss=0.4867440276324104\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4761, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4693, grad_fn=<MeanBackward0>)\n",
            "Epoch 314: train loss=0.4859940835369745\n",
            "pos_score: tensor(0.9669, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9652, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "Epoch 315: train loss=0.4880368161097048, val_recall=0.27881428407335296\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4701, grad_fn=<MeanBackward0>)\n",
            "Epoch 316: train loss=0.48767272845780424\n",
            "pos_score: tensor(0.9666, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4795, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9675, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4718, grad_fn=<MeanBackward0>)\n",
            "Epoch 317: train loss=0.4868827614284898\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4785, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "Epoch 318: train loss=0.48648631149145194\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4752, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "Epoch 319: train loss=0.48632553879937845\n",
            "pos_score: tensor(0.9673, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4730, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4781, grad_fn=<MeanBackward0>)\n",
            "Epoch 320: train loss=0.48549361050773626, val_recall=0.27955467066803946\n",
            "pos_score: tensor(0.9673, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4793, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9678, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4801, grad_fn=<MeanBackward0>)\n",
            "Epoch 321: train loss=0.4876864014367076\n",
            "pos_score: tensor(0.9667, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9701, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4745, grad_fn=<MeanBackward0>)\n",
            "Epoch 322: train loss=0.4861740394807367\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4764, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4779, grad_fn=<MeanBackward0>)\n",
            "Epoch 323: train loss=0.48648923355761337\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4779, grad_fn=<MeanBackward0>)\n",
            "Epoch 324: train loss=0.4850638835831026\n",
            "pos_score: tensor(0.9677, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4791, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "Epoch 325: train loss=0.4877042981535476, val_recall=0.28092670995169056\n",
            "pos_score: tensor(0.9678, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4685, grad_fn=<MeanBackward0>)\n",
            "Epoch 326: train loss=0.4860854385908694\n",
            "pos_score: tensor(0.9682, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4748, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9688, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4695, grad_fn=<MeanBackward0>)\n",
            "Epoch 327: train loss=0.4849611952310807\n",
            "pos_score: tensor(0.9685, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4730, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9688, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "Epoch 328: train loss=0.4856464753838682\n",
            "pos_score: tensor(0.9682, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4784, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9701, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4622, grad_fn=<MeanBackward0>)\n",
            "Epoch 329: train loss=0.48517435497398764\n",
            "pos_score: tensor(0.9688, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4741, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9687, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4767, grad_fn=<MeanBackward0>)\n",
            "Epoch 330: train loss=0.4852829215017648, val_recall=0.27919360769865764\n",
            "pos_score: tensor(0.9697, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4761, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "Epoch 331: train loss=0.48543740697474796\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4739, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9686, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "Epoch 332: train loss=0.485030104940396\n",
            "pos_score: tensor(0.9690, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4711, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9701, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4721, grad_fn=<MeanBackward0>)\n",
            "Epoch 333: train loss=0.4838791696488447\n",
            "pos_score: tensor(0.9695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4683, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4766, grad_fn=<MeanBackward0>)\n",
            "Epoch 334: train loss=0.48322247185463707\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4729, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4711, grad_fn=<MeanBackward0>)\n",
            "Epoch 335: train loss=0.4841156172093836, val_recall=0.2783384398381709\n",
            "pos_score: tensor(0.9698, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4711, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4691, grad_fn=<MeanBackward0>)\n",
            "Epoch 336: train loss=0.48341279568989304\n",
            "pos_score: tensor(0.9703, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4696, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9683, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "Epoch 337: train loss=0.4845871513657311\n",
            "pos_score: tensor(0.9699, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9703, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4698, grad_fn=<MeanBackward0>)\n",
            "Epoch 338: train loss=0.48361294185325654\n",
            "pos_score: tensor(0.9695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4795, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4665, grad_fn=<MeanBackward0>)\n",
            "Epoch 339: train loss=0.4853538633927355\n",
            "pos_score: tensor(0.9705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4681, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9694, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4829, grad_fn=<MeanBackward0>)\n",
            "Epoch 340: train loss=0.48339711010717157, val_recall=0.27920499096468737\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4782, grad_fn=<MeanBackward0>)\n",
            "Epoch 341: train loss=0.48481805852615256\n",
            "pos_score: tensor(0.9705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4749, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9706, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "Epoch 342: train loss=0.4844262383680428\n",
            "pos_score: tensor(0.9712, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4686, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4615, grad_fn=<MeanBackward0>)\n",
            "Epoch 343: train loss=0.4816641944699583\n",
            "pos_score: tensor(0.9705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4723, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9717, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4654, grad_fn=<MeanBackward0>)\n",
            "Epoch 344: train loss=0.4829299499151629\n",
            "pos_score: tensor(0.9705, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4720, grad_fn=<MeanBackward0>)\n",
            "Epoch 345: train loss=0.48447350462757255, val_recall=0.27991573363742134\n",
            "pos_score: tensor(0.9715, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4722, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9697, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4760, grad_fn=<MeanBackward0>)\n",
            "Epoch 346: train loss=0.4838443509831424\n",
            "pos_score: tensor(0.9715, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4746, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9701, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4684, grad_fn=<MeanBackward0>)\n",
            "Epoch 347: train loss=0.48390786754303905\n",
            "pos_score: tensor(0.9718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4710, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "Epoch 348: train loss=0.483070023121437\n",
            "pos_score: tensor(0.9712, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4772, grad_fn=<MeanBackward0>)\n",
            "Epoch 349: train loss=0.48381039201866965\n",
            "pos_score: tensor(0.9720, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4734, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9703, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4840, grad_fn=<MeanBackward0>)\n",
            "Epoch 350: train loss=0.4846312590719303, val_recall=0.2797824180794957\n",
            "pos_score: tensor(0.9716, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4709, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "Epoch 351: train loss=0.4829500863962778\n",
            "pos_score: tensor(0.9722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4743, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "Epoch 352: train loss=0.48392707158202747\n",
            "pos_score: tensor(0.9724, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4665, grad_fn=<MeanBackward0>)\n",
            "Epoch 353: train loss=0.4819333709105736\n",
            "pos_score: tensor(0.9723, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9716, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4679, grad_fn=<MeanBackward0>)\n",
            "Epoch 354: train loss=0.48142763583336395\n",
            "pos_score: tensor(0.9726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9711, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4666, grad_fn=<MeanBackward0>)\n",
            "Epoch 355: train loss=0.48247206892278416, val_recall=0.2801290385301023\n",
            "pos_score: tensor(0.9727, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4732, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4692, grad_fn=<MeanBackward0>)\n",
            "Epoch 356: train loss=0.4831213530489701\n",
            "pos_score: tensor(0.9726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9723, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "Epoch 357: train loss=0.4822673738706077\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4669, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9709, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "Epoch 358: train loss=0.4808366171069276\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4693, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4721, grad_fn=<MeanBackward0>)\n",
            "Epoch 359: train loss=0.4819757622219852\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4705, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "Epoch 360: train loss=0.4824310247685194, val_recall=0.28099558965661875\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9729, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4640, grad_fn=<MeanBackward0>)\n",
            "Epoch 361: train loss=0.4827255851527455\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4671, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4692, grad_fn=<MeanBackward0>)\n",
            "Epoch 362: train loss=0.48101567391139993\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9736, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "Epoch 363: train loss=0.48307479502017325\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4702, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4671, grad_fn=<MeanBackward0>)\n",
            "Epoch 364: train loss=0.4816671487280625\n",
            "pos_score: tensor(0.9735, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4691, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4584, grad_fn=<MeanBackward0>)\n",
            "Epoch 365: train loss=0.48050997886898966, val_recall=0.2806489692060122\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4703, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9735, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4666, grad_fn=<MeanBackward0>)\n",
            "Epoch 366: train loss=0.4815462236191511\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9749, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "Epoch 367: train loss=0.47987935497399103\n",
            "pos_score: tensor(0.9740, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4678, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4750, grad_fn=<MeanBackward0>)\n",
            "Epoch 368: train loss=0.4815128810808317\n",
            "pos_score: tensor(0.9746, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4688, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4687, grad_fn=<MeanBackward0>)\n",
            "Epoch 369: train loss=0.48117785435627813\n",
            "pos_score: tensor(0.9741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4644, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9743, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4570, grad_fn=<MeanBackward0>)\n",
            "Epoch 370: train loss=0.47878428222432556, val_recall=0.2801290385301023\n",
            "pos_score: tensor(0.9741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4662, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9747, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4609, grad_fn=<MeanBackward0>)\n",
            "Epoch 371: train loss=0.47964229916049317\n",
            "pos_score: tensor(0.9748, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9729, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4615, grad_fn=<MeanBackward0>)\n",
            "Epoch 372: train loss=0.47870021163911103\n",
            "pos_score: tensor(0.9747, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4699, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9738, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "Epoch 373: train loss=0.4814877632615436\n",
            "pos_score: tensor(0.9750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4626, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 374: train loss=0.47867636296132554\n",
            "pos_score: tensor(0.9744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4684, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4588, grad_fn=<MeanBackward0>)\n",
            "Epoch 375: train loss=0.4798507025332002, val_recall=0.2790699204865822\n",
            "pos_score: tensor(0.9746, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4623, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4932, grad_fn=<MeanBackward0>)\n",
            "Epoch 376: train loss=0.48082263279805143\n",
            "pos_score: tensor(0.9751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4638, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9742, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4749, grad_fn=<MeanBackward0>)\n",
            "Epoch 377: train loss=0.47990041210364326\n",
            "pos_score: tensor(0.9752, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9745, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "Epoch 378: train loss=0.47998543246305797\n",
            "pos_score: tensor(0.9750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4663, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4615, grad_fn=<MeanBackward0>)\n",
            "Epoch 379: train loss=0.47933265301223693\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4704, grad_fn=<MeanBackward0>)\n",
            "Epoch 380: train loss=0.4796367760125291, val_recall=0.27935235196485425\n",
            "pos_score: tensor(0.9755, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4679, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4641, grad_fn=<MeanBackward0>)\n",
            "Epoch 381: train loss=0.48000895578217395\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4680, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4713, grad_fn=<MeanBackward0>)\n",
            "Epoch 382: train loss=0.48061797674437295\n",
            "pos_score: tensor(0.9759, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4701, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4661, grad_fn=<MeanBackward0>)\n",
            "Epoch 383: train loss=0.4806704450849235\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4665, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "Epoch 384: train loss=0.47964195299054785\n",
            "pos_score: tensor(0.9760, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4746, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4739, grad_fn=<MeanBackward0>)\n",
            "Epoch 385: train loss=0.48277906786450286, val_recall=0.27935235196485425\n",
            "pos_score: tensor(0.9762, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4626, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4725, grad_fn=<MeanBackward0>)\n",
            "Epoch 386: train loss=0.47872454607850096\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4657, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4690, grad_fn=<MeanBackward0>)\n",
            "Epoch 387: train loss=0.47963322012953225\n",
            "pos_score: tensor(0.9761, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4713, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4796, grad_fn=<MeanBackward0>)\n",
            "Epoch 388: train loss=0.4820240062678202\n",
            "pos_score: tensor(0.9764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4680, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 389: train loss=0.4797413891518181\n",
            "pos_score: tensor(0.9767, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4626, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9758, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4709, grad_fn=<MeanBackward0>)\n",
            "Epoch 390: train loss=0.47864525264545793, val_recall=0.28065217865462894\n",
            "pos_score: tensor(0.9763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4663, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4693, grad_fn=<MeanBackward0>)\n",
            "Epoch 391: train loss=0.4796099566556583\n",
            "pos_score: tensor(0.9764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4632, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9776, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4653, grad_fn=<MeanBackward0>)\n",
            "Epoch 392: train loss=0.4784337792952152\n",
            "pos_score: tensor(0.9773, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4626, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9749, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4614, grad_fn=<MeanBackward0>)\n",
            "Epoch 393: train loss=0.47783240762240253\n",
            "pos_score: tensor(0.9767, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4628, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4605, grad_fn=<MeanBackward0>)\n",
            "Epoch 394: train loss=0.4777638895737322\n",
            "pos_score: tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9773, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4614, grad_fn=<MeanBackward0>)\n",
            "Epoch 395: train loss=0.47837046364991137, val_recall=0.2785724559509894\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4656, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "Epoch 396: train loss=0.4796966686931406\n",
            "pos_score: tensor(0.9770, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4718, grad_fn=<MeanBackward0>)\n",
            "Epoch 397: train loss=0.48106244561008765\n",
            "pos_score: tensor(0.9774, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4623, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9766, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4603, grad_fn=<MeanBackward0>)\n",
            "Epoch 398: train loss=0.4773071454545709\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4588, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9781, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4780, grad_fn=<MeanBackward0>)\n",
            "Epoch 399: train loss=0.4779144348317756\n",
            "pos_score: tensor(0.9776, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4798, grad_fn=<MeanBackward0>)\n",
            "Epoch 400: train loss=0.4793971072117509, val_recall=0.2768393536979565\n",
            "pos_score: tensor(0.9772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4671, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4577, grad_fn=<MeanBackward0>)\n",
            "Epoch 401: train loss=0.4785507027517005\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4633, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9765, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4705, grad_fn=<MeanBackward0>)\n",
            "Epoch 402: train loss=0.47846008769956705\n",
            "pos_score: tensor(0.9776, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4626, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4684, grad_fn=<MeanBackward0>)\n",
            "Epoch 403: train loss=0.4780836892056595\n",
            "pos_score: tensor(0.9776, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4669, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "Epoch 404: train loss=0.478110189419005\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4655, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9779, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4753, grad_fn=<MeanBackward0>)\n",
            "Epoch 405: train loss=0.4794762235251724, val_recall=0.2762616529469455\n",
            "pos_score: tensor(0.9781, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4661, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9778, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4690, grad_fn=<MeanBackward0>)\n",
            "Epoch 406: train loss=0.4790711554555372\n",
            "pos_score: tensor(0.9774, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4729, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4578, grad_fn=<MeanBackward0>)\n",
            "Epoch 407: train loss=0.4797605021801031\n",
            "pos_score: tensor(0.9782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4499, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4800, grad_fn=<MeanBackward0>)\n",
            "Epoch 408: train loss=0.4749163259228699\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4624, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4580, grad_fn=<MeanBackward0>)\n",
            "Epoch 409: train loss=0.4769059146250862\n",
            "pos_score: tensor(0.9790, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4657, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9760, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4676, grad_fn=<MeanBackward0>)\n",
            "Epoch 410: train loss=0.47865247177653586, val_recall=0.27645421986394914\n",
            "pos_score: tensor(0.9782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9791, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4493, grad_fn=<MeanBackward0>)\n",
            "Epoch 411: train loss=0.4791534177854403\n",
            "pos_score: tensor(0.9784, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4600, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4523, grad_fn=<MeanBackward0>)\n",
            "Epoch 412: train loss=0.47569657530649917\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4642, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9790, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4591, grad_fn=<MeanBackward0>)\n",
            "Epoch 413: train loss=0.4774355329723005\n",
            "pos_score: tensor(0.9788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4614, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4618, grad_fn=<MeanBackward0>)\n",
            "Epoch 414: train loss=0.47690629947651186\n",
            "pos_score: tensor(0.9789, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4618, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9784, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4688, grad_fn=<MeanBackward0>)\n",
            "Epoch 415: train loss=0.4773832318412402, val_recall=0.27662753008925245\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4623, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4589, grad_fn=<MeanBackward0>)\n",
            "Epoch 416: train loss=0.476710447695403\n",
            "pos_score: tensor(0.9787, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4624, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4675, grad_fn=<MeanBackward0>)\n",
            "Epoch 417: train loss=0.47742381262760053\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4628, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4659, grad_fn=<MeanBackward0>)\n",
            "Epoch 418: train loss=0.47753002581886644\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4601, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4710, grad_fn=<MeanBackward0>)\n",
            "Epoch 419: train loss=0.4769937190334354\n",
            "pos_score: tensor(0.9789, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9806, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4551, grad_fn=<MeanBackward0>)\n",
            "Epoch 420: train loss=0.4767945152329857, val_recall=0.27662753008925245\n",
            "pos_score: tensor(0.9798, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4609, grad_fn=<MeanBackward0>)\n",
            "Epoch 421: train loss=0.47620011554003466\n",
            "pos_score: tensor(0.9794, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4594, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9796, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4616, grad_fn=<MeanBackward0>)\n",
            "Epoch 422: train loss=0.4759788590546555\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9808, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4532, grad_fn=<MeanBackward0>)\n",
            "Epoch 423: train loss=0.47674430654623706\n",
            "pos_score: tensor(0.9794, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4694, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "Epoch 424: train loss=0.4793224119757523\n",
            "pos_score: tensor(0.9802, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4762, grad_fn=<MeanBackward0>)\n",
            "Epoch 425: train loss=0.4767892778671021, val_recall=0.27662753008925245\n",
            "pos_score: tensor(0.9796, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9806, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4607, grad_fn=<MeanBackward0>)\n",
            "Epoch 426: train loss=0.4755577375579373\n",
            "pos_score: tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4560, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4579, grad_fn=<MeanBackward0>)\n",
            "Epoch 427: train loss=0.4745673370220668\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "Epoch 428: train loss=0.4770338256066911\n",
            "pos_score: tensor(0.9800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4699, grad_fn=<MeanBackward0>)\n",
            "Epoch 429: train loss=0.47504420095627264\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4624, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4589, grad_fn=<MeanBackward0>)\n",
            "Epoch 430: train loss=0.47637537198496366, val_recall=0.27662753008925245\n",
            "pos_score: tensor(0.9800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4690, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4474, grad_fn=<MeanBackward0>)\n",
            "Epoch 431: train loss=0.47688162288450947\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4618, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4554, grad_fn=<MeanBackward0>)\n",
            "Epoch 432: train loss=0.4759022117332403\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4564, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4596, grad_fn=<MeanBackward0>)\n",
            "Epoch 433: train loss=0.4745457921168158\n",
            "pos_score: tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4669, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4615, grad_fn=<MeanBackward0>)\n",
            "Epoch 434: train loss=0.4776885202703138\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4656, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9806, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4525, grad_fn=<MeanBackward0>)\n",
            "Epoch 435: train loss=0.4765632658853196, val_recall=0.27655531749537604\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4417, grad_fn=<MeanBackward0>)\n",
            "Epoch 436: train loss=0.4751799707039971\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4581, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 437: train loss=0.47545445580749734\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4660, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "Epoch 438: train loss=0.47779049906758786\n",
            "pos_score: tensor(0.9810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "Epoch 439: train loss=0.474630554860768\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4625, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4457, grad_fn=<MeanBackward0>)\n",
            "Epoch 440: train loss=0.47503898802738764, val_recall=0.27655531749537604\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4596, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4543, grad_fn=<MeanBackward0>)\n",
            "Epoch 441: train loss=0.4747667534747541\n",
            "pos_score: tensor(0.9812, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4557, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4616, grad_fn=<MeanBackward0>)\n",
            "Epoch 442: train loss=0.4745369046684073\n",
            "pos_score: tensor(0.9810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4542, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "Epoch 443: train loss=0.4737371028620489\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4588, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 444: train loss=0.47547713714373957\n",
            "pos_score: tensor(0.9810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4545, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "Epoch 445: train loss=0.4735825586635455, val_recall=0.2764220019374505\n",
            "pos_score: tensor(0.9810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4639, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9827, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4550, grad_fn=<MeanBackward0>)\n",
            "Epoch 446: train loss=0.47609850807698023\n",
            "pos_score: tensor(0.9815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4594, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4640, grad_fn=<MeanBackward0>)\n",
            "Epoch 447: train loss=0.4756607859967125\n",
            "pos_score: tensor(0.9816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4592, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4414, grad_fn=<MeanBackward0>)\n",
            "Epoch 448: train loss=0.47339269438132614\n",
            "pos_score: tensor(0.9816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4593, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "Epoch 449: train loss=0.47604480934833576\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4581, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4595, grad_fn=<MeanBackward0>)\n",
            "Epoch 450: train loss=0.4746494872955574, val_recall=0.27648865971641323\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4596, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4537, grad_fn=<MeanBackward0>)\n",
            "Epoch 451: train loss=0.47465335909595885\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4504, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4683, grad_fn=<MeanBackward0>)\n",
            "Epoch 452: train loss=0.47302716497581276\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4550, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9828, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4496, grad_fn=<MeanBackward0>)\n",
            "Epoch 453: train loss=0.4728451132390735\n",
            "pos_score: tensor(0.9816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4579, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9833, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4533, grad_fn=<MeanBackward0>)\n",
            "Epoch 454: train loss=0.47395340154848076\n",
            "pos_score: tensor(0.9823, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4544, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4605, grad_fn=<MeanBackward0>)\n",
            "Epoch 455: train loss=0.4736248981891928, val_recall=0.27648865971641323\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4630, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "Epoch 456: train loss=0.47328986873668905\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4639, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4631, grad_fn=<MeanBackward0>)\n",
            "Epoch 457: train loss=0.47655639988791904\n",
            "pos_score: tensor(0.9826, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4545, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9812, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4627, grad_fn=<MeanBackward0>)\n",
            "Epoch 458: train loss=0.4736844778828149\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4744, grad_fn=<MeanBackward0>)\n",
            "Epoch 459: train loss=0.47496699838511713\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4579, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9811, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4534, grad_fn=<MeanBackward0>)\n",
            "Epoch 460: train loss=0.47382285327846163, val_recall=0.27695181635299965\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4596, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4586, grad_fn=<MeanBackward0>)\n",
            "Epoch 461: train loss=0.4747880634832523\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4480, grad_fn=<MeanBackward0>)\n",
            "Epoch 462: train loss=0.4733758274257007\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4553, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "Epoch 463: train loss=0.47490146896032903\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4481, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9821, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4591, grad_fn=<MeanBackward0>)\n",
            "Epoch 464: train loss=0.4712140571658686\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9823, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "Epoch 465: train loss=0.47539816045128136, val_recall=0.27695181635299965\n",
            "pos_score: tensor(0.9833, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4575, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4519, grad_fn=<MeanBackward0>)\n",
            "Epoch 466: train loss=0.4735648916433034\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4571, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4672, grad_fn=<MeanBackward0>)\n",
            "Epoch 467: train loss=0.47474263138656825\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4553, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4598, grad_fn=<MeanBackward0>)\n",
            "Epoch 468: train loss=0.47360779160819\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4515, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "Epoch 469: train loss=0.4723786000854008\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4536, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4535, grad_fn=<MeanBackward0>)\n",
            "Epoch 470: train loss=0.4724874845072807, val_recall=0.2783960682305271\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4536, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4699, grad_fn=<MeanBackward0>)\n",
            "Epoch 471: train loss=0.47374017665445234\n",
            "pos_score: tensor(0.9833, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4619, grad_fn=<MeanBackward0>)\n",
            "Epoch 472: train loss=0.47338743568468405\n",
            "pos_score: tensor(0.9831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4592, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9841, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4506, grad_fn=<MeanBackward0>)\n",
            "Epoch 473: train loss=0.4736957539206292\n",
            "pos_score: tensor(0.9836, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4506, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9828, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4602, grad_fn=<MeanBackward0>)\n",
            "Epoch 474: train loss=0.47201849401258233\n",
            "pos_score: tensor(0.9834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4535, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9836, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4522, grad_fn=<MeanBackward0>)\n",
            "Epoch 475: train loss=0.4720945493528348, val_recall=0.279160525689839\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4493, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4605, grad_fn=<MeanBackward0>)\n",
            "Epoch 476: train loss=0.4716624251407902\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4574, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4641, grad_fn=<MeanBackward0>)\n",
            "Epoch 477: train loss=0.47446879376363016\n",
            "pos_score: tensor(0.9834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9843, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4408, grad_fn=<MeanBackward0>)\n",
            "Epoch 478: train loss=0.4729442934099296\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4553, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4534, grad_fn=<MeanBackward0>)\n",
            "Epoch 479: train loss=0.47278601461839154\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4614, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "Epoch 480: train loss=0.47477697039924976, val_recall=0.2785250548637269\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4532, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "Epoch 481: train loss=0.47221814282854535\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4518, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9838, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4608, grad_fn=<MeanBackward0>)\n",
            "Epoch 482: train loss=0.4723436699280569\n",
            "pos_score: tensor(0.9841, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4508, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4515, grad_fn=<MeanBackward0>)\n",
            "Epoch 483: train loss=0.4711117913237715\n",
            "pos_score: tensor(0.9839, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4514, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9845, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4371, grad_fn=<MeanBackward0>)\n",
            "Epoch 484: train loss=0.47003621005751955\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4556, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9845, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4556, grad_fn=<MeanBackward0>)\n",
            "Epoch 485: train loss=0.47290397440022136, val_recall=0.2783517446384236\n",
            "pos_score: tensor(0.9842, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4555, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9842, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4536, grad_fn=<MeanBackward0>)\n",
            "Epoch 486: train loss=0.47272440890764184\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4479, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9852, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "Epoch 487: train loss=0.4712908842922312\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4557, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9851, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4474, grad_fn=<MeanBackward0>)\n",
            "Epoch 488: train loss=0.4721715446930208\n",
            "pos_score: tensor(0.9840, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4571, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9855, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4546, grad_fn=<MeanBackward0>)\n",
            "Epoch 489: train loss=0.4731986149606068\n",
            "pos_score: tensor(0.9846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4539, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9839, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4621, grad_fn=<MeanBackward0>)\n",
            "Epoch 490: train loss=0.4728366776393738, val_recall=0.2783895173798359\n",
            "pos_score: tensor(0.9845, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4522, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4547, grad_fn=<MeanBackward0>)\n",
            "Epoch 491: train loss=0.47170414118064763\n",
            "pos_score: tensor(0.9844, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4514, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9850, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4661, grad_fn=<MeanBackward0>)\n",
            "Epoch 492: train loss=0.47250947320259873\n",
            "pos_score: tensor(0.9847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4538, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9842, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4347, grad_fn=<MeanBackward0>)\n",
            "Epoch 493: train loss=0.4703317912998261\n",
            "pos_score: tensor(0.9847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4601, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9845, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4545, grad_fn=<MeanBackward0>)\n",
            "Epoch 494: train loss=0.4740824224621316\n",
            "pos_score: tensor(0.9842, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4521, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9862, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4454, grad_fn=<MeanBackward0>)\n",
            "Epoch 495: train loss=0.4706452016995826, val_recall=0.2786783677553414\n",
            "pos_score: tensor(0.9844, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4526, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9860, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4607, grad_fn=<MeanBackward0>)\n",
            "Epoch 496: train loss=0.47228064101588646\n",
            "pos_score: tensor(0.9848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4525, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9851, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4558, grad_fn=<MeanBackward0>)\n",
            "Epoch 497: train loss=0.4718580487144849\n",
            "pos_score: tensor(0.9849, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4555, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "Epoch 498: train loss=0.4729022921714108\n",
            "pos_score: tensor(0.9848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4596, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9854, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4391, grad_fn=<MeanBackward0>)\n",
            "Epoch 499: train loss=0.47214416206506404\n",
            "\n",
            "Best validation recall@k: 0.28099558965661875 at epoch 360\n",
            "Test set recall@k: 0.2635128037386786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_is_55 = GNN(embedding_dim=embedding_dim, num_nodes=data_is.num_nodes, num_start=num_items, num_layers=num_layers).to(device)\n",
        "opt_55 = torch.optim.Adam(gnn_is_55.parameters(), lr=1e-3) # using Adam optimizer\n",
        "all_train_losses = [] # list of (epoch, training loss)\n",
        "all_test_recalls = []  # list of (epoch, validation recall@k)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train(gnn_is_55, train_mp_is_55, train_loader_is_55, opt_55, num_items, data_is.num_nodes, device)\n",
        "    all_train_losses.append((epoch, train_loss))\n",
        "    \n",
        "    if epoch in range(11) or epoch % 5 == 0: # perform validation for the first ~10 epochs, then every 5 epochs after that\n",
        "        test_recall,_ = test(gnn_is_55, test_mp_is_55, test_loader_is_55, k, device, save_emb_dir_55, epoch)\n",
        "        all_test_recalls.append((epoch, test_recall))\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}, test_recall={test_recall}\")\n",
        "    else:\n",
        "        print(f\"Epoch {epoch}: train loss={train_loss}\")\n",
        "\n",
        "print()\n",
        "\n",
        "\n",
        "# Print final recall@k on test set\n",
        "test_recall, result_is = test(gnn_is_55, test_mp_is_55, test_loader_is_55, k, device, None, None)\n",
        "print(f\"Test set recall@k: {test_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J6ZZSmbY85U",
        "outputId": "de41ceff-a4a8-4804-c23a-dd35b0b755c6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_score: tensor(0.5104, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 0: train loss=0.68808812541481, test_recall=0.018118170134201982\n",
            "pos_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5105, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 1: train loss=0.6877531319295815, test_recall=0.020501358112713405\n",
            "pos_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5127, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 2: train loss=0.6875228596480367, test_recall=0.02258630410205567\n",
            "pos_score: tensor(0.5119, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5137, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 3: train loss=0.6872281539454274, test_recall=0.02459428914771221\n",
            "pos_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5119, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 4: train loss=0.6869448099752558, test_recall=0.028771432771743127\n",
            "pos_score: tensor(0.5132, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 5: train loss=0.6866402685414774, test_recall=0.03038395306848716\n",
            "pos_score: tensor(0.5138, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5127, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 6: train loss=0.6863986588431151, test_recall=0.03534551263615392\n",
            "pos_score: tensor(0.5142, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5155, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "Epoch 7: train loss=0.6861131494571416, test_recall=0.03895928573379298\n",
            "pos_score: tensor(0.5149, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5151, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 8: train loss=0.6857996273549046, test_recall=0.04010875132534229\n",
            "pos_score: tensor(0.5154, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5172, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 9: train loss=0.6855034024594002, test_recall=0.04243175197195254\n",
            "pos_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5157, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 10: train loss=0.6851349886208243, test_recall=0.046842546710257595\n",
            "pos_score: tensor(0.5168, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5002, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5188, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "Epoch 11: train loss=0.6848231065993341\n",
            "pos_score: tensor(0.5175, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5206, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "Epoch 12: train loss=0.684496379585733\n",
            "pos_score: tensor(0.5184, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5198, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 13: train loss=0.6840954766114741\n",
            "pos_score: tensor(0.5194, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5184, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 14: train loss=0.6837544836312756\n",
            "pos_score: tensor(0.5201, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5213, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "Epoch 15: train loss=0.6833346586805344, test_recall=0.06782821590106883\n",
            "pos_score: tensor(0.5210, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5220, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "Epoch 16: train loss=0.6829101283984179\n",
            "pos_score: tensor(0.5220, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 17: train loss=0.6824690613609848\n",
            "pos_score: tensor(0.5229, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5004, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "Epoch 18: train loss=0.6819707436504482\n",
            "pos_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5005, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5243, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 19: train loss=0.6814904069724813\n",
            "pos_score: tensor(0.5253, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 20: train loss=0.6809993825596968, test_recall=0.0983418780030018\n",
            "pos_score: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 21: train loss=0.6804628675353261\n",
            "pos_score: tensor(0.5274, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 22: train loss=0.6798979731308251\n",
            "pos_score: tensor(0.5289, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5295, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 23: train loss=0.6792923159341402\n",
            "pos_score: tensor(0.5304, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5301, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "Epoch 24: train loss=0.6786821934953773\n",
            "pos_score: tensor(0.5316, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "Epoch 25: train loss=0.6781145687290894, test_recall=0.1303037335565883\n",
            "pos_score: tensor(0.5336, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5013, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5322, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "Epoch 26: train loss=0.6773882659819114\n",
            "pos_score: tensor(0.5347, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5014, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5368, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "Epoch 27: train loss=0.6765792816857755\n",
            "pos_score: tensor(0.5367, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5366, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5011, grad_fn=<MeanBackward0>)\n",
            "Epoch 28: train loss=0.6758359666874039\n",
            "pos_score: tensor(0.5383, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5397, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 29: train loss=0.675017965061129\n",
            "pos_score: tensor(0.5401, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5017, grad_fn=<MeanBackward0>)\n",
            "Epoch 30: train loss=0.674251978303872, test_recall=0.15881254396566222\n",
            "pos_score: tensor(0.5423, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5021, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5423, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5020, grad_fn=<MeanBackward0>)\n",
            "Epoch 31: train loss=0.6732999960408899\n",
            "pos_score: tensor(0.5444, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5443, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 32: train loss=0.6724981870803728\n",
            "pos_score: tensor(0.5460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5507, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "Epoch 33: train loss=0.671450017306158\n",
            "pos_score: tensor(0.5487, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5503, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "Epoch 34: train loss=0.670496558606554\n",
            "pos_score: tensor(0.5510, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5029, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5529, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5024, grad_fn=<MeanBackward0>)\n",
            "Epoch 35: train loss=0.6693796243522022, test_recall=0.17879064170513126\n",
            "pos_score: tensor(0.5532, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5585, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5023, grad_fn=<MeanBackward0>)\n",
            "Epoch 36: train loss=0.6683753733102201\n",
            "pos_score: tensor(0.5563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5031, grad_fn=<MeanBackward0>)\n",
            "Epoch 37: train loss=0.6673503060892454\n",
            "pos_score: tensor(0.5575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "Epoch 38: train loss=0.6660955859840128\n",
            "pos_score: tensor(0.5618, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5038, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5615, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "Epoch 39: train loss=0.6647628213656798\n",
            "pos_score: tensor(0.5646, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5041, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5661, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "Epoch 40: train loss=0.6634858079075201, test_recall=0.19030881610075548\n",
            "pos_score: tensor(0.5667, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "Epoch 41: train loss=0.6623874535402478\n",
            "pos_score: tensor(0.5709, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5716, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5035, grad_fn=<MeanBackward0>)\n",
            "Epoch 42: train loss=0.6612011962210541\n",
            "pos_score: tensor(0.5741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5064, grad_fn=<MeanBackward0>)\n",
            "Epoch 43: train loss=0.6597731892553376\n",
            "pos_score: tensor(0.5777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5055, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "Epoch 44: train loss=0.658051516056249\n",
            "pos_score: tensor(0.5817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "Epoch 45: train loss=0.6566719645527668, test_recall=0.1940604037749339\n",
            "pos_score: tensor(0.5846, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5848, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "Epoch 46: train loss=0.6553907414567613\n",
            "pos_score: tensor(0.5886, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5076, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5065, grad_fn=<MeanBackward0>)\n",
            "Epoch 47: train loss=0.6539445400771412\n",
            "pos_score: tensor(0.5920, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5076, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5909, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5067, grad_fn=<MeanBackward0>)\n",
            "Epoch 48: train loss=0.6521902883471682\n",
            "pos_score: tensor(0.5959, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5927, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5059, grad_fn=<MeanBackward0>)\n",
            "Epoch 49: train loss=0.6506173367374177\n",
            "pos_score: tensor(0.5996, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5091, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5986, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "Epoch 50: train loss=0.6493581894871937, test_recall=0.20162042617555406\n",
            "pos_score: tensor(0.6031, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5093, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6061, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "Epoch 51: train loss=0.6477113065476134\n",
            "pos_score: tensor(0.6084, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5101, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.5978, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "Epoch 52: train loss=0.6460165406296262\n",
            "pos_score: tensor(0.6086, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5095, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6297, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5168, grad_fn=<MeanBackward0>)\n",
            "Epoch 53: train loss=0.6444612739117213\n",
            "pos_score: tensor(0.6136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5095, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6320, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5159, grad_fn=<MeanBackward0>)\n",
            "Epoch 54: train loss=0.6423756284201705\n",
            "pos_score: tensor(0.6198, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5111, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6203, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "Epoch 55: train loss=0.6409227534852101, test_recall=0.20662641557043473\n",
            "pos_score: tensor(0.6234, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6308, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5141, grad_fn=<MeanBackward0>)\n",
            "Epoch 56: train loss=0.6390659017756763\n",
            "pos_score: tensor(0.6283, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6309, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5124, grad_fn=<MeanBackward0>)\n",
            "Epoch 57: train loss=0.6372192121835301\n",
            "pos_score: tensor(0.6318, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5118, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6413, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "Epoch 58: train loss=0.6354224757154233\n",
            "pos_score: tensor(0.6380, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5137, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6303, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5108, grad_fn=<MeanBackward0>)\n",
            "Epoch 59: train loss=0.6339472251073955\n",
            "pos_score: tensor(0.6430, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5145, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6320, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5120, grad_fn=<MeanBackward0>)\n",
            "Epoch 60: train loss=0.6322581495544066, test_recall=0.20728004636197195\n",
            "pos_score: tensor(0.6462, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5135, grad_fn=<MeanBackward0>)\n",
            "Epoch 61: train loss=0.6300997340470526\n",
            "pos_score: tensor(0.6506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5148, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5131, grad_fn=<MeanBackward0>)\n",
            "Epoch 62: train loss=0.6284161889642489\n",
            "pos_score: tensor(0.6550, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5147, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6557, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5201, grad_fn=<MeanBackward0>)\n",
            "Epoch 63: train loss=0.6266932724682748\n",
            "pos_score: tensor(0.6587, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5156, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6664, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5141, grad_fn=<MeanBackward0>)\n",
            "Epoch 64: train loss=0.624767654529448\n",
            "pos_score: tensor(0.6642, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5182, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6626, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5182, grad_fn=<MeanBackward0>)\n",
            "Epoch 65: train loss=0.6240143687462458, test_recall=0.20959141333736872\n",
            "pos_score: tensor(0.6676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5177, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "Epoch 66: train loss=0.6220553361172582\n",
            "pos_score: tensor(0.6725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5176, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5166, grad_fn=<MeanBackward0>)\n",
            "Epoch 67: train loss=0.6197764302401311\n",
            "pos_score: tensor(0.6758, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5182, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6880, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "Epoch 68: train loss=0.6184290044557768\n",
            "pos_score: tensor(0.6795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5181, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6979, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5291, grad_fn=<MeanBackward0>)\n",
            "Epoch 69: train loss=0.6166635426208681\n",
            "pos_score: tensor(0.6863, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5191, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5196, grad_fn=<MeanBackward0>)\n",
            "Epoch 70: train loss=0.6146642971641219, test_recall=0.2118019517952556\n",
            "pos_score: tensor(0.6885, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7027, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5223, grad_fn=<MeanBackward0>)\n",
            "Epoch 71: train loss=0.6134945394287205\n",
            "pos_score: tensor(0.6949, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5202, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6895, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5165, grad_fn=<MeanBackward0>)\n",
            "Epoch 72: train loss=0.6111583741562415\n",
            "pos_score: tensor(0.6989, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5227, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5260, grad_fn=<MeanBackward0>)\n",
            "Epoch 73: train loss=0.6107761933703472\n",
            "pos_score: tensor(0.7028, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5228, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7033, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "Epoch 74: train loss=0.608714311730628\n",
            "pos_score: tensor(0.7081, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5225, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6960, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5169, grad_fn=<MeanBackward0>)\n",
            "Epoch 75: train loss=0.6066076360590945, test_recall=0.2104124545488722\n",
            "pos_score: tensor(0.7117, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7016, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5221, grad_fn=<MeanBackward0>)\n",
            "Epoch 76: train loss=0.6056667705761286\n",
            "pos_score: tensor(0.7170, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.6923, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5212, grad_fn=<MeanBackward0>)\n",
            "Epoch 77: train loss=0.6034976193615913\n",
            "pos_score: tensor(0.7178, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7288, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5254, grad_fn=<MeanBackward0>)\n",
            "Epoch 78: train loss=0.6026186151698414\n",
            "pos_score: tensor(0.7230, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5219, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7205, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5230, grad_fn=<MeanBackward0>)\n",
            "Epoch 79: train loss=0.5996656690887565\n",
            "pos_score: tensor(0.7274, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7196, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5242, grad_fn=<MeanBackward0>)\n",
            "Epoch 80: train loss=0.5989505034604344, test_recall=0.21169441414734172\n",
            "pos_score: tensor(0.7309, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7257, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5231, grad_fn=<MeanBackward0>)\n",
            "Epoch 81: train loss=0.5971263874391299\n",
            "pos_score: tensor(0.7354, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5253, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7198, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5195, grad_fn=<MeanBackward0>)\n",
            "Epoch 82: train loss=0.5959465394037023\n",
            "pos_score: tensor(0.7398, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5276, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7154, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5183, grad_fn=<MeanBackward0>)\n",
            "Epoch 83: train loss=0.5953071184700485\n",
            "pos_score: tensor(0.7409, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7459, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5256, grad_fn=<MeanBackward0>)\n",
            "Epoch 84: train loss=0.5928443812479988\n",
            "pos_score: tensor(0.7464, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5259, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7310, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5192, grad_fn=<MeanBackward0>)\n",
            "Epoch 85: train loss=0.5914527153808798, test_recall=0.21044749172697405\n",
            "pos_score: tensor(0.7497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5276, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5144, grad_fn=<MeanBackward0>)\n",
            "Epoch 86: train loss=0.5905477823293716\n",
            "pos_score: tensor(0.7489, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5291, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5283, grad_fn=<MeanBackward0>)\n",
            "Epoch 87: train loss=0.590135199205705\n",
            "pos_score: tensor(0.7558, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5288, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7512, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5239, grad_fn=<MeanBackward0>)\n",
            "Epoch 88: train loss=0.5883767706718174\n",
            "pos_score: tensor(0.7581, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5285, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "Epoch 89: train loss=0.5867745964397552\n",
            "pos_score: tensor(0.7623, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7591, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5204, grad_fn=<MeanBackward0>)\n",
            "Epoch 90: train loss=0.5856113157816382, test_recall=0.21334948477820764\n",
            "pos_score: tensor(0.7634, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5285, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5329, grad_fn=<MeanBackward0>)\n",
            "Epoch 91: train loss=0.5844040575082686\n",
            "pos_score: tensor(0.7690, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5280, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7612, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5204, grad_fn=<MeanBackward0>)\n",
            "Epoch 92: train loss=0.5824029586992541\n",
            "pos_score: tensor(0.7717, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5282, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5298, grad_fn=<MeanBackward0>)\n",
            "Epoch 93: train loss=0.5814033978737441\n",
            "pos_score: tensor(0.7747, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5272, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5216, grad_fn=<MeanBackward0>)\n",
            "Epoch 94: train loss=0.579401668521476\n",
            "pos_score: tensor(0.7783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5294, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7704, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5305, grad_fn=<MeanBackward0>)\n",
            "Epoch 95: train loss=0.5794248838599755, test_recall=0.2133844112810762\n",
            "pos_score: tensor(0.7798, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5277, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7870, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "Epoch 96: train loss=0.5772111855740453\n",
            "pos_score: tensor(0.7831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5262, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7856, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5402, grad_fn=<MeanBackward0>)\n",
            "Epoch 97: train loss=0.5762322704593419\n",
            "pos_score: tensor(0.7858, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5279, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7912, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5328, grad_fn=<MeanBackward0>)\n",
            "Epoch 98: train loss=0.5752317877188531\n",
            "pos_score: tensor(0.7899, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5310, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5254, grad_fn=<MeanBackward0>)\n",
            "Epoch 99: train loss=0.5749138269413143\n",
            "pos_score: tensor(0.7922, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5297, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7869, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "Epoch 100: train loss=0.5735195371363881, test_recall=0.21320404373225973\n",
            "pos_score: tensor(0.7941, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5294, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7999, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5294, grad_fn=<MeanBackward0>)\n",
            "Epoch 101: train loss=0.5721682503139021\n",
            "pos_score: tensor(0.7989, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7790, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5263, grad_fn=<MeanBackward0>)\n",
            "Epoch 102: train loss=0.5724893996850144\n",
            "pos_score: tensor(0.7974, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8193, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5472, grad_fn=<MeanBackward0>)\n",
            "Epoch 103: train loss=0.5715440896360917\n",
            "pos_score: tensor(0.8026, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5309, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7988, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5283, grad_fn=<MeanBackward0>)\n",
            "Epoch 104: train loss=0.5695203581849656\n",
            "pos_score: tensor(0.8044, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5297, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8071, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5347, grad_fn=<MeanBackward0>)\n",
            "Epoch 105: train loss=0.5683520113908863, test_recall=0.21411773512524987\n",
            "pos_score: tensor(0.8083, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5300, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7964, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5148, grad_fn=<MeanBackward0>)\n",
            "Epoch 106: train loss=0.5665936299194896\n",
            "pos_score: tensor(0.8101, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5300, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8049, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5289, grad_fn=<MeanBackward0>)\n",
            "Epoch 107: train loss=0.5661372133486677\n",
            "pos_score: tensor(0.8129, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5303, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7977, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5295, grad_fn=<MeanBackward0>)\n",
            "Epoch 108: train loss=0.5653249072015152\n",
            "pos_score: tensor(0.8142, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5291, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8143, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5323, grad_fn=<MeanBackward0>)\n",
            "Epoch 109: train loss=0.5640729652343416\n",
            "pos_score: tensor(0.8185, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7944, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5243, grad_fn=<MeanBackward0>)\n",
            "Epoch 110: train loss=0.5636317924867101, test_recall=0.21397488329329883\n",
            "pos_score: tensor(0.8196, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5320, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8088, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5251, grad_fn=<MeanBackward0>)\n",
            "Epoch 111: train loss=0.5629062636429769\n",
            "pos_score: tensor(0.8230, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5294, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.7961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5195, grad_fn=<MeanBackward0>)\n",
            "Epoch 112: train loss=0.5609011568196715\n",
            "pos_score: tensor(0.8239, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8148, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5245, grad_fn=<MeanBackward0>)\n",
            "Epoch 113: train loss=0.5601263388173645\n",
            "pos_score: tensor(0.8256, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5327, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8230, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5306, grad_fn=<MeanBackward0>)\n",
            "Epoch 114: train loss=0.5607730015153429\n",
            "pos_score: tensor(0.8295, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5291, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8048, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "Epoch 115: train loss=0.5583139664484554, test_recall=0.21415886263179246\n",
            "pos_score: tensor(0.8297, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5307, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8284, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5359, grad_fn=<MeanBackward0>)\n",
            "Epoch 116: train loss=0.5585032380055497\n",
            "pos_score: tensor(0.8316, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5314, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8317, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5234, grad_fn=<MeanBackward0>)\n",
            "Epoch 117: train loss=0.5573546720391936\n",
            "pos_score: tensor(0.8327, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5315, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8427, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5290, grad_fn=<MeanBackward0>)\n",
            "Epoch 118: train loss=0.5568150227470513\n",
            "pos_score: tensor(0.8368, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5296, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8228, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5360, grad_fn=<MeanBackward0>)\n",
            "Epoch 119: train loss=0.5554584978065736\n",
            "pos_score: tensor(0.8386, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5319, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8256, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5275, grad_fn=<MeanBackward0>)\n",
            "Epoch 120: train loss=0.555391778505418, test_recall=0.21475042946064007\n",
            "pos_score: tensor(0.8372, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5285, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8573, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5247, grad_fn=<MeanBackward0>)\n",
            "Epoch 121: train loss=0.5530947896191472\n",
            "pos_score: tensor(0.8402, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5284, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8498, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5280, grad_fn=<MeanBackward0>)\n",
            "Epoch 122: train loss=0.5524948506249238\n",
            "pos_score: tensor(0.8442, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8329, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5290, grad_fn=<MeanBackward0>)\n",
            "Epoch 123: train loss=0.5536598841098284\n",
            "pos_score: tensor(0.8449, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8447, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5241, grad_fn=<MeanBackward0>)\n",
            "Epoch 124: train loss=0.5519773101066191\n",
            "pos_score: tensor(0.8467, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5322, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8456, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5266, grad_fn=<MeanBackward0>)\n",
            "Epoch 125: train loss=0.5516749663735113, test_recall=0.2160755978915132\n",
            "pos_score: tensor(0.8497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5295, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8317, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5171, grad_fn=<MeanBackward0>)\n",
            "Epoch 126: train loss=0.5497700845917552\n",
            "pos_score: tensor(0.8494, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5343, grad_fn=<MeanBackward0>)\n",
            "Epoch 127: train loss=0.5495587640694057\n",
            "pos_score: tensor(0.8481, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5300, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5329, grad_fn=<MeanBackward0>)\n",
            "Epoch 128: train loss=0.5492255016837815\n",
            "pos_score: tensor(0.8557, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5305, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8301, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5275, grad_fn=<MeanBackward0>)\n",
            "Epoch 129: train loss=0.5484799215834083\n",
            "pos_score: tensor(0.8555, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5288, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8502, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5299, grad_fn=<MeanBackward0>)\n",
            "Epoch 130: train loss=0.5472993588020871, test_recall=0.2156169849161217\n",
            "pos_score: tensor(0.8573, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5304, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8490, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5192, grad_fn=<MeanBackward0>)\n",
            "Epoch 131: train loss=0.5467574266653843\n",
            "pos_score: tensor(0.8575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5259, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5419, grad_fn=<MeanBackward0>)\n",
            "Epoch 132: train loss=0.5453322762516803\n",
            "pos_score: tensor(0.8589, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5290, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8657, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5425, grad_fn=<MeanBackward0>)\n",
            "Epoch 133: train loss=0.546076242336083\n",
            "pos_score: tensor(0.8612, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5305, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8608, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5331, grad_fn=<MeanBackward0>)\n",
            "Epoch 134: train loss=0.5454774705308537\n",
            "pos_score: tensor(0.8639, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5311, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8469, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5186, grad_fn=<MeanBackward0>)\n",
            "Epoch 135: train loss=0.5447864918853754, test_recall=0.2165994002529541\n",
            "pos_score: tensor(0.8641, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5281, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8642, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5255, grad_fn=<MeanBackward0>)\n",
            "Epoch 136: train loss=0.5431015659577126\n",
            "pos_score: tensor(0.8637, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5246, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5182, grad_fn=<MeanBackward0>)\n",
            "Epoch 137: train loss=0.5410068583874377\n",
            "pos_score: tensor(0.8662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5245, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "Epoch 138: train loss=0.5405335799692994\n",
            "pos_score: tensor(0.8630, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5272, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8986, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5330, grad_fn=<MeanBackward0>)\n",
            "Epoch 139: train loss=0.5416130558144562\n",
            "pos_score: tensor(0.8700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5256, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8675, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5365, grad_fn=<MeanBackward0>)\n",
            "Epoch 140: train loss=0.540426739910305, test_recall=0.21658192742278543\n",
            "pos_score: tensor(0.8714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5266, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8667, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5235, grad_fn=<MeanBackward0>)\n",
            "Epoch 141: train loss=0.5397672299209872\n",
            "pos_score: tensor(0.8731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5250, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5257, grad_fn=<MeanBackward0>)\n",
            "Epoch 142: train loss=0.5387921193145203\n",
            "pos_score: tensor(0.8739, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5245, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8721, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5282, grad_fn=<MeanBackward0>)\n",
            "Epoch 143: train loss=0.538302718816517\n",
            "pos_score: tensor(0.8734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5286, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8869, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5135, grad_fn=<MeanBackward0>)\n",
            "Epoch 144: train loss=0.5385476451105845\n",
            "pos_score: tensor(0.8757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5265, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8811, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5178, grad_fn=<MeanBackward0>)\n",
            "Epoch 145: train loss=0.5375883856687534, test_recall=0.21758610884215154\n",
            "pos_score: tensor(0.8772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5249, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5344, grad_fn=<MeanBackward0>)\n",
            "Epoch 146: train loss=0.5371580660256889\n",
            "pos_score: tensor(0.8786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5219, grad_fn=<MeanBackward0>)\n",
            "Epoch 147: train loss=0.535320577785865\n",
            "pos_score: tensor(0.8781, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5219, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8939, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5292, grad_fn=<MeanBackward0>)\n",
            "Epoch 148: train loss=0.5349146140407678\n",
            "pos_score: tensor(0.8792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5261, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8961, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5284, grad_fn=<MeanBackward0>)\n",
            "Epoch 149: train loss=0.5359542700221216\n",
            "pos_score: tensor(0.8822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5263, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5186, grad_fn=<MeanBackward0>)\n",
            "Epoch 150: train loss=0.5351518911740579, test_recall=0.21751796539047982\n",
            "pos_score: tensor(0.8831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5240, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8860, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5186, grad_fn=<MeanBackward0>)\n",
            "Epoch 151: train loss=0.5338256434165015\n",
            "pos_score: tensor(0.8847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5252, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5374, grad_fn=<MeanBackward0>)\n",
            "Epoch 152: train loss=0.5346196114365906\n",
            "pos_score: tensor(0.8872, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5230, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "Epoch 153: train loss=0.5324364123351951\n",
            "pos_score: tensor(0.8862, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8909, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5308, grad_fn=<MeanBackward0>)\n",
            "Epoch 154: train loss=0.5328349667185937\n",
            "pos_score: tensor(0.8868, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5217, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8957, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5361, grad_fn=<MeanBackward0>)\n",
            "Epoch 155: train loss=0.5320761731022643, test_recall=0.217296573974744\n",
            "pos_score: tensor(0.8903, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5256, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5112, grad_fn=<MeanBackward0>)\n",
            "Epoch 156: train loss=0.5321435960425658\n",
            "pos_score: tensor(0.8887, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5244, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9009, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5213, grad_fn=<MeanBackward0>)\n",
            "Epoch 157: train loss=0.5315736865884364\n",
            "pos_score: tensor(0.8931, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5200, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8655, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5170, grad_fn=<MeanBackward0>)\n",
            "Epoch 158: train loss=0.5294977440647678\n",
            "pos_score: tensor(0.8914, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5177, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8958, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5233, grad_fn=<MeanBackward0>)\n",
            "Epoch 159: train loss=0.528502355438892\n",
            "pos_score: tensor(0.8922, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5211, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8985, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5275, grad_fn=<MeanBackward0>)\n",
            "Epoch 160: train loss=0.52945254073047, test_recall=0.21905617829614238\n",
            "pos_score: tensor(0.8943, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5238, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8905, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "Epoch 161: train loss=0.5293514748547701\n",
            "pos_score: tensor(0.8955, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5205, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8892, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "Epoch 162: train loss=0.5278159910118067\n",
            "pos_score: tensor(0.8969, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5183, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5206, grad_fn=<MeanBackward0>)\n",
            "Epoch 163: train loss=0.5271058425901438\n",
            "pos_score: tensor(0.8952, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5212, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9104, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "Epoch 164: train loss=0.5270116177416582\n",
            "pos_score: tensor(0.8977, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5226, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8996, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5174, grad_fn=<MeanBackward0>)\n",
            "Epoch 165: train loss=0.5277715356652086, test_recall=0.2201942838106461\n",
            "pos_score: tensor(0.8989, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5224, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8980, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5199, grad_fn=<MeanBackward0>)\n",
            "Epoch 166: train loss=0.5274249101598132\n",
            "pos_score: tensor(0.8981, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5173, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9132, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5285, grad_fn=<MeanBackward0>)\n",
            "Epoch 167: train loss=0.5256386280044127\n",
            "pos_score: tensor(0.9007, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5191, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9003, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5190, grad_fn=<MeanBackward0>)\n",
            "Epoch 168: train loss=0.5255083453735249\n",
            "pos_score: tensor(0.9027, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5151, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8890, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5066, grad_fn=<MeanBackward0>)\n",
            "Epoch 169: train loss=0.5231525294873915\n",
            "pos_score: tensor(0.9026, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8999, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5191, grad_fn=<MeanBackward0>)\n",
            "Epoch 170: train loss=0.5237623761791762, test_recall=0.2178318565391025\n",
            "pos_score: tensor(0.9021, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5154, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9147, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5260, grad_fn=<MeanBackward0>)\n",
            "Epoch 171: train loss=0.5236014536547494\n",
            "pos_score: tensor(0.9020, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5169, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5174, grad_fn=<MeanBackward0>)\n",
            "Epoch 172: train loss=0.5232497233437118\n",
            "pos_score: tensor(0.9040, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5170, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9134, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5134, grad_fn=<MeanBackward0>)\n",
            "Epoch 173: train loss=0.5229607742700879\n",
            "pos_score: tensor(0.9055, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9093, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5161, grad_fn=<MeanBackward0>)\n",
            "Epoch 174: train loss=0.5219448251871078\n",
            "pos_score: tensor(0.9078, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5175, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.8933, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5186, grad_fn=<MeanBackward0>)\n",
            "Epoch 175: train loss=0.5225394539008534, test_recall=0.21878851206250693\n",
            "pos_score: tensor(0.9068, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5192, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9128, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5232, grad_fn=<MeanBackward0>)\n",
            "Epoch 176: train loss=0.5231406670178939\n",
            "pos_score: tensor(0.9083, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9072, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5178, grad_fn=<MeanBackward0>)\n",
            "Epoch 177: train loss=0.5190779361572371\n",
            "pos_score: tensor(0.9088, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5145, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9107, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5171, grad_fn=<MeanBackward0>)\n",
            "Epoch 178: train loss=0.5205969995049242\n",
            "pos_score: tensor(0.9096, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5179, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9114, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5090, grad_fn=<MeanBackward0>)\n",
            "Epoch 179: train loss=0.521306926693661\n",
            "pos_score: tensor(0.9117, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5126, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9004, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5204, grad_fn=<MeanBackward0>)\n",
            "Epoch 180: train loss=0.5194050533032006, test_recall=0.21785637186862178\n",
            "pos_score: tensor(0.9117, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5125, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9057, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5220, grad_fn=<MeanBackward0>)\n",
            "Epoch 181: train loss=0.5192268366467907\n",
            "pos_score: tensor(0.9121, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5143, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9112, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5160, grad_fn=<MeanBackward0>)\n",
            "Epoch 182: train loss=0.5193118060759956\n",
            "pos_score: tensor(0.9133, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5150, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9088, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5172, grad_fn=<MeanBackward0>)\n",
            "Epoch 183: train loss=0.5193866019202528\n",
            "pos_score: tensor(0.9125, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5131, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9207, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5065, grad_fn=<MeanBackward0>)\n",
            "Epoch 184: train loss=0.5179761006245724\n",
            "pos_score: tensor(0.9137, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5188, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9187, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5123, grad_fn=<MeanBackward0>)\n",
            "Epoch 185: train loss=0.5198383894401533, test_recall=0.21739521855511945\n",
            "pos_score: tensor(0.9144, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9191, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5187, grad_fn=<MeanBackward0>)\n",
            "Epoch 186: train loss=0.5183155371540705\n",
            "pos_score: tensor(0.9169, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5179, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9004, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5135, grad_fn=<MeanBackward0>)\n",
            "Epoch 187: train loss=0.5193039585468189\n",
            "pos_score: tensor(0.9171, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5125, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9095, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5030, grad_fn=<MeanBackward0>)\n",
            "Epoch 188: train loss=0.5165268946108119\n",
            "pos_score: tensor(0.9163, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5107, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9229, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5195, grad_fn=<MeanBackward0>)\n",
            "Epoch 189: train loss=0.5163847349681169\n",
            "pos_score: tensor(0.9186, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5110, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9074, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5196, grad_fn=<MeanBackward0>)\n",
            "Epoch 190: train loss=0.5161368250376238, test_recall=0.21548033217769644\n",
            "pos_score: tensor(0.9193, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5140, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9106, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5083, grad_fn=<MeanBackward0>)\n",
            "Epoch 191: train loss=0.5166108412936512\n",
            "pos_score: tensor(0.9197, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5102, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9116, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "Epoch 192: train loss=0.5149567184957772\n",
            "pos_score: tensor(0.9204, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5103, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9136, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5184, grad_fn=<MeanBackward0>)\n",
            "Epoch 193: train loss=0.5152416999582586\n",
            "pos_score: tensor(0.9206, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5116, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9179, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5124, grad_fn=<MeanBackward0>)\n",
            "Epoch 194: train loss=0.5151708824789231\n",
            "pos_score: tensor(0.9219, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9119, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "Epoch 195: train loss=0.5138891532728901, test_recall=0.21540862558051563\n",
            "pos_score: tensor(0.9227, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5142, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9111, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5062, grad_fn=<MeanBackward0>)\n",
            "Epoch 196: train loss=0.5154986582879786\n",
            "pos_score: tensor(0.9226, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9198, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 197: train loss=0.5108576846885154\n",
            "pos_score: tensor(0.9242, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5079, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9095, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5136, grad_fn=<MeanBackward0>)\n",
            "Epoch 198: train loss=0.512744236359519\n",
            "pos_score: tensor(0.9223, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5109, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9320, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4981, grad_fn=<MeanBackward0>)\n",
            "Epoch 199: train loss=0.512993705501712\n",
            "pos_score: tensor(0.9219, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5089, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9375, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5026, grad_fn=<MeanBackward0>)\n",
            "Epoch 200: train loss=0.5122903329178696, test_recall=0.2161181724444254\n",
            "pos_score: tensor(0.9256, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5076, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9163, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5113, grad_fn=<MeanBackward0>)\n",
            "Epoch 201: train loss=0.5121286306699369\n",
            "pos_score: tensor(0.9261, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9206, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5139, grad_fn=<MeanBackward0>)\n",
            "Epoch 202: train loss=0.5121736084258718\n",
            "pos_score: tensor(0.9258, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5065, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9285, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5174, grad_fn=<MeanBackward0>)\n",
            "Epoch 203: train loss=0.511520053088814\n",
            "pos_score: tensor(0.9262, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9307, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5088, grad_fn=<MeanBackward0>)\n",
            "Epoch 204: train loss=0.5118079691250742\n",
            "pos_score: tensor(0.9272, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5121, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9272, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5170, grad_fn=<MeanBackward0>)\n",
            "Epoch 205: train loss=0.5131231908390971, test_recall=0.2160109662340313\n",
            "pos_score: tensor(0.9274, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5091, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9307, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5099, grad_fn=<MeanBackward0>)\n",
            "Epoch 206: train loss=0.5114915957104487\n",
            "pos_score: tensor(0.9272, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5088, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9365, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5019, grad_fn=<MeanBackward0>)\n",
            "Epoch 207: train loss=0.5109080276390113\n",
            "pos_score: tensor(0.9291, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5063, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9264, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5164, grad_fn=<MeanBackward0>)\n",
            "Epoch 208: train loss=0.51027205455835\n",
            "pos_score: tensor(0.9297, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5094, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9256, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4977, grad_fn=<MeanBackward0>)\n",
            "Epoch 209: train loss=0.5105082041371071\n",
            "pos_score: tensor(0.9285, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5073, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9392, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "Epoch 210: train loss=0.5097167872962144, test_recall=0.21676503805913222\n",
            "pos_score: tensor(0.9293, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5072, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9384, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4964, grad_fn=<MeanBackward0>)\n",
            "Epoch 211: train loss=0.5091652860530412\n",
            "pos_score: tensor(0.9300, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5076, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9394, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4992, grad_fn=<MeanBackward0>)\n",
            "Epoch 212: train loss=0.5093485930669086\n",
            "pos_score: tensor(0.9310, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5103, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9354, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5110, grad_fn=<MeanBackward0>)\n",
            "Epoch 213: train loss=0.5106839469615245\n",
            "pos_score: tensor(0.9316, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5071, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9342, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5087, grad_fn=<MeanBackward0>)\n",
            "Epoch 214: train loss=0.5092057695136539\n",
            "pos_score: tensor(0.9322, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9339, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "Epoch 215: train loss=0.5089141060167401, test_recall=0.21719182682606517\n",
            "pos_score: tensor(0.9314, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5060, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9455, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4925, grad_fn=<MeanBackward0>)\n",
            "Epoch 216: train loss=0.5079047779124541\n",
            "pos_score: tensor(0.9319, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5042, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9445, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4892, grad_fn=<MeanBackward0>)\n",
            "Epoch 217: train loss=0.5068967732132571\n",
            "pos_score: tensor(0.9335, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5078, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9366, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5100, grad_fn=<MeanBackward0>)\n",
            "Epoch 218: train loss=0.5087949596183647\n",
            "pos_score: tensor(0.9334, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5071, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9416, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5032, grad_fn=<MeanBackward0>)\n",
            "Epoch 219: train loss=0.5081633049369658\n",
            "pos_score: tensor(0.9340, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5046, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9412, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "Epoch 220: train loss=0.5069512435677397, test_recall=0.21712516056245854\n",
            "pos_score: tensor(0.9345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9396, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4995, grad_fn=<MeanBackward0>)\n",
            "Epoch 221: train loss=0.5069143354524075\n",
            "pos_score: tensor(0.9359, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5070, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9315, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5003, grad_fn=<MeanBackward0>)\n",
            "Epoch 222: train loss=0.5075380048684061\n",
            "pos_score: tensor(0.9358, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4993, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9371, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5007, grad_fn=<MeanBackward0>)\n",
            "Epoch 223: train loss=0.5047623117686353\n",
            "pos_score: tensor(0.9357, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5074, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9427, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "Epoch 224: train loss=0.5073073310575323\n",
            "pos_score: tensor(0.9363, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5057, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9410, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 225: train loss=0.506571591371046, test_recall=0.21789073519701746\n",
            "pos_score: tensor(0.9375, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4997, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9345, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5162, grad_fn=<MeanBackward0>)\n",
            "Epoch 226: train loss=0.504941862936882\n",
            "pos_score: tensor(0.9378, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5028, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9364, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5080, grad_fn=<MeanBackward0>)\n",
            "Epoch 227: train loss=0.5056598478515676\n",
            "pos_score: tensor(0.9383, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5036, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9359, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "Epoch 228: train loss=0.5054767432299424\n",
            "pos_score: tensor(0.9390, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5000, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9319, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 229: train loss=0.5040547635260656\n",
            "pos_score: tensor(0.9393, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5034, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9343, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4946, grad_fn=<MeanBackward0>)\n",
            "Epoch 230: train loss=0.5049534410391219, test_recall=0.21799948488630408\n",
            "pos_score: tensor(0.9386, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4998, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9448, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5072, grad_fn=<MeanBackward0>)\n",
            "Epoch 231: train loss=0.5040045516289196\n",
            "pos_score: tensor(0.9393, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4990, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9442, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4958, grad_fn=<MeanBackward0>)\n",
            "Epoch 232: train loss=0.5029567448084786\n",
            "pos_score: tensor(0.9393, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4987, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9469, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5043, grad_fn=<MeanBackward0>)\n",
            "Epoch 233: train loss=0.5031388660593556\n",
            "pos_score: tensor(0.9414, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4993, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9310, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5155, grad_fn=<MeanBackward0>)\n",
            "Epoch 234: train loss=0.503594803400676\n",
            "pos_score: tensor(0.9413, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4999, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9369, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5056, grad_fn=<MeanBackward0>)\n",
            "Epoch 235: train loss=0.503435056152148, test_recall=0.21882965656072198\n",
            "pos_score: tensor(0.9415, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9395, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4943, grad_fn=<MeanBackward0>)\n",
            "Epoch 236: train loss=0.502710670785757\n",
            "pos_score: tensor(0.9413, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4980, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9459, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4968, grad_fn=<MeanBackward0>)\n",
            "Epoch 237: train loss=0.5019146920834926\n",
            "pos_score: tensor(0.9420, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4949, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9431, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "Epoch 238: train loss=0.5011718614679651\n",
            "pos_score: tensor(0.9430, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9372, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "Epoch 239: train loss=0.5022345764462235\n",
            "pos_score: tensor(0.9434, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4968, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9375, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "Epoch 240: train loss=0.5011915537946741, test_recall=0.21902221710077455\n",
            "pos_score: tensor(0.9427, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9484, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "Epoch 241: train loss=0.5020762779145104\n",
            "pos_score: tensor(0.9432, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5001, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9482, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5016, grad_fn=<MeanBackward0>)\n",
            "Epoch 242: train loss=0.5023667297954386\n",
            "pos_score: tensor(0.9423, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9547, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "Epoch 243: train loss=0.5011527287142734\n",
            "pos_score: tensor(0.9446, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9428, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5082, grad_fn=<MeanBackward0>)\n",
            "Epoch 244: train loss=0.5015357216967926\n",
            "pos_score: tensor(0.9451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4989, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9416, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 245: train loss=0.5015149628791327, test_recall=0.2196659223977605\n",
            "pos_score: tensor(0.9454, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5015, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9428, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5052, grad_fn=<MeanBackward0>)\n",
            "Epoch 246: train loss=0.5023463493758933\n",
            "pos_score: tensor(0.9459, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4970, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9416, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4955, grad_fn=<MeanBackward0>)\n",
            "Epoch 247: train loss=0.5003203696162313\n",
            "pos_score: tensor(0.9461, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4921, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9435, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4897, grad_fn=<MeanBackward0>)\n",
            "Epoch 248: train loss=0.4982180402990799\n",
            "pos_score: tensor(0.9460, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9480, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5084, grad_fn=<MeanBackward0>)\n",
            "Epoch 249: train loss=0.5011428358335529\n",
            "pos_score: tensor(0.9453, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4935, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4965, grad_fn=<MeanBackward0>)\n",
            "Epoch 250: train loss=0.4988196642089163, test_recall=0.2200511232997937\n",
            "pos_score: tensor(0.9463, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4970, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9521, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4865, grad_fn=<MeanBackward0>)\n",
            "Epoch 251: train loss=0.49955354532704166\n",
            "pos_score: tensor(0.9473, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9466, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "Epoch 252: train loss=0.4975473824606583\n",
            "pos_score: tensor(0.9471, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4960, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9517, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4731, grad_fn=<MeanBackward0>)\n",
            "Epoch 253: train loss=0.4982961140928935\n",
            "pos_score: tensor(0.9484, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4992, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9430, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4971, grad_fn=<MeanBackward0>)\n",
            "Epoch 254: train loss=0.5003395580173966\n",
            "pos_score: tensor(0.9489, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4884, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9398, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4875, grad_fn=<MeanBackward0>)\n",
            "Epoch 255: train loss=0.4960452846585645, test_recall=0.22091693813372934\n",
            "pos_score: tensor(0.9489, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4861, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9442, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5012, grad_fn=<MeanBackward0>)\n",
            "Epoch 256: train loss=0.4955407517421307\n",
            "pos_score: tensor(0.9493, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4911, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9447, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "Epoch 257: train loss=0.49694266078785576\n",
            "pos_score: tensor(0.9487, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9534, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4901, grad_fn=<MeanBackward0>)\n",
            "Epoch 258: train loss=0.4969965747970235\n",
            "pos_score: tensor(0.9495, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4979, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4889, grad_fn=<MeanBackward0>)\n",
            "Epoch 259: train loss=0.49895780008707347\n",
            "pos_score: tensor(0.9493, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4928, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9542, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5010, grad_fn=<MeanBackward0>)\n",
            "Epoch 260: train loss=0.4975951642233347, test_recall=0.2203191068665233\n",
            "pos_score: tensor(0.9497, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4947, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9545, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4939, grad_fn=<MeanBackward0>)\n",
            "Epoch 261: train loss=0.49785778051160606\n",
            "pos_score: tensor(0.9501, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9541, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4907, grad_fn=<MeanBackward0>)\n",
            "Epoch 262: train loss=0.49634707873315304\n",
            "pos_score: tensor(0.9506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4891, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9529, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4902, grad_fn=<MeanBackward0>)\n",
            "Epoch 263: train loss=0.49553797526694643\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9410, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5008, grad_fn=<MeanBackward0>)\n",
            "Epoch 264: train loss=0.49655664782098036\n",
            "pos_score: tensor(0.9520, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4944, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9451, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "Epoch 265: train loss=0.4973359774846688, test_recall=0.22106481902163141\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4908, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9506, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4824, grad_fn=<MeanBackward0>)\n",
            "Epoch 266: train loss=0.4953484202250162\n",
            "pos_score: tensor(0.9521, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4934, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9516, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4857, grad_fn=<MeanBackward0>)\n",
            "Epoch 267: train loss=0.49631262462081716\n",
            "pos_score: tensor(0.9526, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4929, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9498, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4891, grad_fn=<MeanBackward0>)\n",
            "Epoch 268: train loss=0.4962585388531668\n",
            "pos_score: tensor(0.9527, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4866, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9519, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "Epoch 269: train loss=0.49410187969836517\n",
            "pos_score: tensor(0.9531, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4924, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9518, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4947, grad_fn=<MeanBackward0>)\n",
            "Epoch 270: train loss=0.49615573061816176, test_recall=0.2208740807105293\n",
            "pos_score: tensor(0.9530, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4914, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9552, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4903, grad_fn=<MeanBackward0>)\n",
            "Epoch 271: train loss=0.49552624184279903\n",
            "pos_score: tensor(0.9544, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4868, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9435, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4855, grad_fn=<MeanBackward0>)\n",
            "Epoch 272: train loss=0.49362911841072116\n",
            "pos_score: tensor(0.9543, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4883, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9479, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5100, grad_fn=<MeanBackward0>)\n",
            "Epoch 273: train loss=0.49475953590793037\n",
            "pos_score: tensor(0.9538, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4938, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9563, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "Epoch 274: train loss=0.4958607384618575\n",
            "pos_score: tensor(0.9544, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4875, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9539, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5025, grad_fn=<MeanBackward0>)\n",
            "Epoch 275: train loss=0.49424773186409937, test_recall=0.2210323795125641\n",
            "pos_score: tensor(0.9544, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4932, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9566, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4866, grad_fn=<MeanBackward0>)\n",
            "Epoch 276: train loss=0.4954837602303991\n",
            "pos_score: tensor(0.9552, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4862, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9524, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4922, grad_fn=<MeanBackward0>)\n",
            "Epoch 277: train loss=0.49306924553478465\n",
            "pos_score: tensor(0.9545, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4891, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9607, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4945, grad_fn=<MeanBackward0>)\n",
            "Epoch 278: train loss=0.4943335798558851\n",
            "pos_score: tensor(0.9556, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4909, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9540, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4937, grad_fn=<MeanBackward0>)\n",
            "Epoch 279: train loss=0.49463334921975405\n",
            "pos_score: tensor(0.9555, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4894, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5045, grad_fn=<MeanBackward0>)\n",
            "Epoch 280: train loss=0.4943421025278694, test_recall=0.2206322951293465\n",
            "pos_score: tensor(0.9560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4875, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9564, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5058, grad_fn=<MeanBackward0>)\n",
            "Epoch 281: train loss=0.4938879513767208\n",
            "pos_score: tensor(0.9560, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4887, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9584, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "Epoch 282: train loss=0.4930900357980323\n",
            "pos_score: tensor(0.9557, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4915, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9631, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4846, grad_fn=<MeanBackward0>)\n",
            "Epoch 283: train loss=0.49424467075889184\n",
            "pos_score: tensor(0.9565, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9588, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4955, grad_fn=<MeanBackward0>)\n",
            "Epoch 284: train loss=0.49354067174976385\n",
            "pos_score: tensor(0.9570, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4888, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9572, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "Epoch 285: train loss=0.49292943777732434, test_recall=0.22078099807021465\n",
            "pos_score: tensor(0.9577, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4839, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9518, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4918, grad_fn=<MeanBackward0>)\n",
            "Epoch 286: train loss=0.4915062233850758\n",
            "pos_score: tensor(0.9576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4815, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9557, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5044, grad_fn=<MeanBackward0>)\n",
            "Epoch 287: train loss=0.4911285297017864\n",
            "pos_score: tensor(0.9575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9594, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4834, grad_fn=<MeanBackward0>)\n",
            "Epoch 288: train loss=0.49104666656170226\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4851, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9559, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4912, grad_fn=<MeanBackward0>)\n",
            "Epoch 289: train loss=0.49157592458918875\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4867, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "Epoch 290: train loss=0.49186317732670165, test_recall=0.22104663506635386\n",
            "pos_score: tensor(0.9574, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4876, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4688, grad_fn=<MeanBackward0>)\n",
            "Epoch 291: train loss=0.49129916577531185\n",
            "pos_score: tensor(0.9577, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4849, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4925, grad_fn=<MeanBackward0>)\n",
            "Epoch 292: train loss=0.4914863915651437\n",
            "pos_score: tensor(0.9590, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4858, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9575, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4985, grad_fn=<MeanBackward0>)\n",
            "Epoch 293: train loss=0.49188601196886816\n",
            "pos_score: tensor(0.9593, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4899, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9569, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "Epoch 294: train loss=0.4928631022237197\n",
            "pos_score: tensor(0.9589, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9622, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "Epoch 295: train loss=0.48934444840024344, test_recall=0.2221400683511506\n",
            "pos_score: tensor(0.9600, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4816, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9539, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4951, grad_fn=<MeanBackward0>)\n",
            "Epoch 296: train loss=0.4899796108844045\n",
            "pos_score: tensor(0.9596, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9612, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "Epoch 297: train loss=0.4886192460799942\n",
            "pos_score: tensor(0.9605, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9546, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4864, grad_fn=<MeanBackward0>)\n",
            "Epoch 298: train loss=0.4895143274383053\n",
            "pos_score: tensor(0.9604, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4921, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9589, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4860, grad_fn=<MeanBackward0>)\n",
            "Epoch 299: train loss=0.4932363764057506\n",
            "pos_score: tensor(0.9607, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4852, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9576, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4678, grad_fn=<MeanBackward0>)\n",
            "Epoch 300: train loss=0.49001036372399986, test_recall=0.22116948870665287\n",
            "pos_score: tensor(0.9603, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4815, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9633, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "Epoch 301: train loss=0.4886346844712878\n",
            "pos_score: tensor(0.9609, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4805, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9609, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4779, grad_fn=<MeanBackward0>)\n",
            "Epoch 302: train loss=0.48856176865980927\n",
            "pos_score: tensor(0.9604, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4685, grad_fn=<MeanBackward0>)\n",
            "Epoch 303: train loss=0.4892216900145165\n",
            "pos_score: tensor(0.9614, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4870, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9608, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4903, grad_fn=<MeanBackward0>)\n",
            "Epoch 304: train loss=0.4911924098091449\n",
            "pos_score: tensor(0.9614, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9630, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5051, grad_fn=<MeanBackward0>)\n",
            "Epoch 305: train loss=0.4898737628517347, test_recall=0.22131295724084216\n",
            "pos_score: tensor(0.9616, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4859, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9631, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4889, grad_fn=<MeanBackward0>)\n",
            "Epoch 306: train loss=0.4907778383697518\n",
            "pos_score: tensor(0.9621, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4835, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9599, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4905, grad_fn=<MeanBackward0>)\n",
            "Epoch 307: train loss=0.4896619725633662\n",
            "pos_score: tensor(0.9621, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4836, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9631, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "Epoch 308: train loss=0.48987862583853287\n",
            "pos_score: tensor(0.9610, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4848, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9698, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4581, grad_fn=<MeanBackward0>)\n",
            "Epoch 309: train loss=0.48835911346761973\n",
            "pos_score: tensor(0.9629, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9589, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4784, grad_fn=<MeanBackward0>)\n",
            "Epoch 310: train loss=0.48859183581459914, test_recall=0.22151603064022427\n",
            "pos_score: tensor(0.9631, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4873, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9587, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4828, grad_fn=<MeanBackward0>)\n",
            "Epoch 311: train loss=0.49044433461237713\n",
            "pos_score: tensor(0.9634, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9591, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4923, grad_fn=<MeanBackward0>)\n",
            "Epoch 312: train loss=0.4899226062696911\n",
            "pos_score: tensor(0.9630, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4845, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9640, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4695, grad_fn=<MeanBackward0>)\n",
            "Epoch 313: train loss=0.4888574925280352\n",
            "pos_score: tensor(0.9637, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4827, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9586, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4984, grad_fn=<MeanBackward0>)\n",
            "Epoch 314: train loss=0.4892316216472764\n",
            "pos_score: tensor(0.9640, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4806, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9582, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5009, grad_fn=<MeanBackward0>)\n",
            "Epoch 315: train loss=0.4884668774182176, test_recall=0.22072939194562693\n",
            "pos_score: tensor(0.9638, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4837, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9620, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4834, grad_fn=<MeanBackward0>)\n",
            "Epoch 316: train loss=0.4889403153350595\n",
            "pos_score: tensor(0.9638, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "Epoch 317: train loss=0.4870442412043578\n",
            "pos_score: tensor(0.9640, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4830, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9650, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "Epoch 318: train loss=0.4882643397175367\n",
            "pos_score: tensor(0.9646, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4819, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9612, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4946, grad_fn=<MeanBackward0>)\n",
            "Epoch 319: train loss=0.48860367992972525\n",
            "pos_score: tensor(0.9645, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4821, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9639, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "Epoch 320: train loss=0.48798117865181423, test_recall=0.2207093543171411\n",
            "pos_score: tensor(0.9649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4789, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9625, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.5006, grad_fn=<MeanBackward0>)\n",
            "Epoch 321: train loss=0.4876397090658481\n",
            "pos_score: tensor(0.9647, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9660, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 322: train loss=0.48567771422171185\n",
            "pos_score: tensor(0.9654, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4804, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9618, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4961, grad_fn=<MeanBackward0>)\n",
            "Epoch 323: train loss=0.48784559522354065\n",
            "pos_score: tensor(0.9648, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9689, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4996, grad_fn=<MeanBackward0>)\n",
            "Epoch 324: train loss=0.4875165829416607\n",
            "pos_score: tensor(0.9649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4837, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9688, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4754, grad_fn=<MeanBackward0>)\n",
            "Epoch 325: train loss=0.48802647285986017, test_recall=0.2206235790520092\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4808, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9622, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4760, grad_fn=<MeanBackward0>)\n",
            "Epoch 326: train loss=0.4871593033472069\n",
            "pos_score: tensor(0.9661, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4810, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9616, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4857, grad_fn=<MeanBackward0>)\n",
            "Epoch 327: train loss=0.4875633946758051\n",
            "pos_score: tensor(0.9662, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4737, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4693, grad_fn=<MeanBackward0>)\n",
            "Epoch 328: train loss=0.48439282393013117\n",
            "pos_score: tensor(0.9665, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9621, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4959, grad_fn=<MeanBackward0>)\n",
            "Epoch 329: train loss=0.48779401993779764\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9664, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "Epoch 330: train loss=0.48666176134025535, test_recall=0.2207298156628774\n",
            "pos_score: tensor(0.9663, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4817, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9681, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4723, grad_fn=<MeanBackward0>)\n",
            "Epoch 331: train loss=0.4871017500858179\n",
            "pos_score: tensor(0.9669, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4770, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9635, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4975, grad_fn=<MeanBackward0>)\n",
            "Epoch 332: train loss=0.48594452489566015\n",
            "pos_score: tensor(0.9666, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4772, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4842, grad_fn=<MeanBackward0>)\n",
            "Epoch 333: train loss=0.48584065005989163\n",
            "pos_score: tensor(0.9668, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4760, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9681, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4885, grad_fn=<MeanBackward0>)\n",
            "Epoch 334: train loss=0.48552585515258717\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4773, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9667, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4896, grad_fn=<MeanBackward0>)\n",
            "Epoch 335: train loss=0.4857168438631008, test_recall=0.22017135779574418\n",
            "pos_score: tensor(0.9673, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9669, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4764, grad_fn=<MeanBackward0>)\n",
            "Epoch 336: train loss=0.4850351395246496\n",
            "pos_score: tensor(0.9677, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4769, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9656, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4978, grad_fn=<MeanBackward0>)\n",
            "Epoch 337: train loss=0.48613422443512505\n",
            "pos_score: tensor(0.9664, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4776, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9747, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4666, grad_fn=<MeanBackward0>)\n",
            "Epoch 338: train loss=0.4847590000413879\n",
            "pos_score: tensor(0.9681, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9649, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4777, grad_fn=<MeanBackward0>)\n",
            "Epoch 339: train loss=0.48402679553626793\n",
            "pos_score: tensor(0.9676, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4783, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9703, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4731, grad_fn=<MeanBackward0>)\n",
            "Epoch 340: train loss=0.485294754908483, test_recall=0.21992323095365762\n",
            "pos_score: tensor(0.9681, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4781, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9678, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4900, grad_fn=<MeanBackward0>)\n",
            "Epoch 341: train loss=0.48588667847809314\n",
            "pos_score: tensor(0.9679, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4838, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9711, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4486, grad_fn=<MeanBackward0>)\n",
            "Epoch 342: train loss=0.4859193827599534\n",
            "pos_score: tensor(0.9684, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4718, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9685, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4818, grad_fn=<MeanBackward0>)\n",
            "Epoch 343: train loss=0.4832975196123029\n",
            "pos_score: tensor(0.9685, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4787, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4644, grad_fn=<MeanBackward0>)\n",
            "Epoch 344: train loss=0.48499270195489746\n",
            "pos_score: tensor(0.9691, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9659, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4824, grad_fn=<MeanBackward0>)\n",
            "Epoch 345: train loss=0.4829269213093819, test_recall=0.21950512704619943\n",
            "pos_score: tensor(0.9682, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9743, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4627, grad_fn=<MeanBackward0>)\n",
            "Epoch 346: train loss=0.48512849721928647\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4813, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9670, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "Epoch 347: train loss=0.4854889272474775\n",
            "pos_score: tensor(0.9692, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4805, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9694, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4817, grad_fn=<MeanBackward0>)\n",
            "Epoch 348: train loss=0.48606587799540757\n",
            "pos_score: tensor(0.9700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4770, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9622, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4982, grad_fn=<MeanBackward0>)\n",
            "Epoch 349: train loss=0.485199129543017\n",
            "pos_score: tensor(0.9695, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4782, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9693, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4677, grad_fn=<MeanBackward0>)\n",
            "Epoch 350: train loss=0.48458933109028557, test_recall=0.2196375287479716\n",
            "pos_score: tensor(0.9694, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4747, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "Epoch 351: train loss=0.483372232034373\n",
            "pos_score: tensor(0.9696, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4797, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4672, grad_fn=<MeanBackward0>)\n",
            "Epoch 352: train loss=0.48509118732362533\n",
            "pos_score: tensor(0.9700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9694, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4910, grad_fn=<MeanBackward0>)\n",
            "Epoch 353: train loss=0.4829635058936202\n",
            "pos_score: tensor(0.9699, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4801, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9723, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4530, grad_fn=<MeanBackward0>)\n",
            "Epoch 354: train loss=0.484642296413761\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4782, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9706, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4767, grad_fn=<MeanBackward0>)\n",
            "Epoch 355: train loss=0.4847740741337047, test_recall=0.2198436751370039\n",
            "pos_score: tensor(0.9703, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9706, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4503, grad_fn=<MeanBackward0>)\n",
            "Epoch 356: train loss=0.4820751852307732\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4687, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9672, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4887, grad_fn=<MeanBackward0>)\n",
            "Epoch 357: train loss=0.48165703457913156\n",
            "pos_score: tensor(0.9707, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4734, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4754, grad_fn=<MeanBackward0>)\n",
            "Epoch 358: train loss=0.48299835252281803\n",
            "pos_score: tensor(0.9700, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4774, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9765, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4687, grad_fn=<MeanBackward0>)\n",
            "Epoch 359: train loss=0.4838466807240984\n",
            "pos_score: tensor(0.9712, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9677, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4837, grad_fn=<MeanBackward0>)\n",
            "Epoch 360: train loss=0.4800089624998271, test_recall=0.2187662197810251\n",
            "pos_score: tensor(0.9708, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4757, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4683, grad_fn=<MeanBackward0>)\n",
            "Epoch 361: train loss=0.48311217094129727\n",
            "pos_score: tensor(0.9710, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4729, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4621, grad_fn=<MeanBackward0>)\n",
            "Epoch 362: train loss=0.4819769447399513\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4666, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4849, grad_fn=<MeanBackward0>)\n",
            "Epoch 363: train loss=0.48058166359895027\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4744, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9723, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4737, grad_fn=<MeanBackward0>)\n",
            "Epoch 364: train loss=0.48280963506380464\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4761, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9686, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4927, grad_fn=<MeanBackward0>)\n",
            "Epoch 365: train loss=0.4839177162714076, test_recall=0.2189115286613431\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4710, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4545, grad_fn=<MeanBackward0>)\n",
            "Epoch 366: train loss=0.4810902500077288\n",
            "pos_score: tensor(0.9719, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4763, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9714, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4529, grad_fn=<MeanBackward0>)\n",
            "Epoch 367: train loss=0.4825575218567457\n",
            "pos_score: tensor(0.9722, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4754, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9701, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4825, grad_fn=<MeanBackward0>)\n",
            "Epoch 368: train loss=0.48339577265704425\n",
            "pos_score: tensor(0.9720, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4689, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4616, grad_fn=<MeanBackward0>)\n",
            "Epoch 369: train loss=0.48018954751726545\n",
            "pos_score: tensor(0.9725, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4732, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9698, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4877, grad_fn=<MeanBackward0>)\n",
            "Epoch 370: train loss=0.4828486158269254, test_recall=0.21860252710473602\n",
            "pos_score: tensor(0.9718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4738, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4515, grad_fn=<MeanBackward0>)\n",
            "Epoch 371: train loss=0.48136933074764304\n",
            "pos_score: tensor(0.9727, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4689, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9702, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4865, grad_fn=<MeanBackward0>)\n",
            "Epoch 372: train loss=0.48090762787076075\n",
            "pos_score: tensor(0.9728, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9718, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4689, grad_fn=<MeanBackward0>)\n",
            "Epoch 373: train loss=0.47980743145406174\n",
            "pos_score: tensor(0.9733, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9655, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4740, grad_fn=<MeanBackward0>)\n",
            "Epoch 374: train loss=0.4814682270856512\n",
            "pos_score: tensor(0.9726, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4707, grad_fn=<MeanBackward0>)\n",
            "Epoch 375: train loss=0.4816422870534394, test_recall=0.21877891926691576\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4723, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4654, grad_fn=<MeanBackward0>)\n",
            "Epoch 376: train loss=0.48125043557276614\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4710, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9743, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4706, grad_fn=<MeanBackward0>)\n",
            "Epoch 377: train loss=0.48105178405727456\n",
            "pos_score: tensor(0.9733, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4753, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4849, grad_fn=<MeanBackward0>)\n",
            "Epoch 378: train loss=0.48291175479417664\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4708, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9736, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4677, grad_fn=<MeanBackward0>)\n",
            "Epoch 379: train loss=0.48072004186070144\n",
            "pos_score: tensor(0.9736, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4732, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9729, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4672, grad_fn=<MeanBackward0>)\n",
            "Epoch 380: train loss=0.4815972692865434, test_recall=0.21831551242767\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4752, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9733, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4683, grad_fn=<MeanBackward0>)\n",
            "Epoch 381: train loss=0.4823466795363667\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4680, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9743, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4684, grad_fn=<MeanBackward0>)\n",
            "Epoch 382: train loss=0.4796689998940396\n",
            "pos_score: tensor(0.9733, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4709, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4623, grad_fn=<MeanBackward0>)\n",
            "Epoch 383: train loss=0.4803099954366715\n",
            "pos_score: tensor(0.9737, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4682, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9761, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4696, grad_fn=<MeanBackward0>)\n",
            "Epoch 384: train loss=0.47986039970325534\n",
            "pos_score: tensor(0.9739, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4711, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4741, grad_fn=<MeanBackward0>)\n",
            "Epoch 385: train loss=0.4810356530904425, test_recall=0.21823793703435243\n",
            "pos_score: tensor(0.9745, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4703, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9713, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4682, grad_fn=<MeanBackward0>)\n",
            "Epoch 386: train loss=0.4802413042210673\n",
            "pos_score: tensor(0.9744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4805, grad_fn=<MeanBackward0>)\n",
            "Epoch 387: train loss=0.4797650304910838\n",
            "pos_score: tensor(0.9746, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4685, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9730, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4779, grad_fn=<MeanBackward0>)\n",
            "Epoch 388: train loss=0.48016783212310216\n",
            "pos_score: tensor(0.9744, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4715, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9762, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4660, grad_fn=<MeanBackward0>)\n",
            "Epoch 389: train loss=0.480603508465948\n",
            "pos_score: tensor(0.9748, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4658, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4920, grad_fn=<MeanBackward0>)\n",
            "Epoch 390: train loss=0.47948011775944854, test_recall=0.21759652898754053\n",
            "pos_score: tensor(0.9749, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4664, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9732, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4769, grad_fn=<MeanBackward0>)\n",
            "Epoch 391: train loss=0.47914428156541355\n",
            "pos_score: tensor(0.9750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4648, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9728, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4778, grad_fn=<MeanBackward0>)\n",
            "Epoch 392: train loss=0.4784908937747454\n",
            "pos_score: tensor(0.9746, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4691, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4457, grad_fn=<MeanBackward0>)\n",
            "Epoch 393: train loss=0.47911555670345907\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4681, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9731, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4831, grad_fn=<MeanBackward0>)\n",
            "Epoch 394: train loss=0.47994391173653767\n",
            "pos_score: tensor(0.9755, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4646, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9711, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4814, grad_fn=<MeanBackward0>)\n",
            "Epoch 395: train loss=0.478371837132384, test_recall=0.2171423443935694\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4694, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9759, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4719, grad_fn=<MeanBackward0>)\n",
            "Epoch 396: train loss=0.47981745541950704\n",
            "pos_score: tensor(0.9755, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4647, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9750, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "Epoch 397: train loss=0.47826335008622217\n",
            "pos_score: tensor(0.9751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4729, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9784, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4477, grad_fn=<MeanBackward0>)\n",
            "Epoch 398: train loss=0.47975206065686193\n",
            "pos_score: tensor(0.9754, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4677, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4486, grad_fn=<MeanBackward0>)\n",
            "Epoch 399: train loss=0.47811989796633847\n",
            "pos_score: tensor(0.9758, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4654, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4848, grad_fn=<MeanBackward0>)\n",
            "Epoch 400: train loss=0.47898354849888786, test_recall=0.21749651187367453\n",
            "pos_score: tensor(0.9751, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4752, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4369, grad_fn=<MeanBackward0>)\n",
            "Epoch 401: train loss=0.4796307843121153\n",
            "pos_score: tensor(0.9755, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4692, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4503, grad_fn=<MeanBackward0>)\n",
            "Epoch 402: train loss=0.47871919416929487\n",
            "pos_score: tensor(0.9757, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4697, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4520, grad_fn=<MeanBackward0>)\n",
            "Epoch 403: train loss=0.478926113866351\n",
            "pos_score: tensor(0.9766, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4672, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9716, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4925, grad_fn=<MeanBackward0>)\n",
            "Epoch 404: train loss=0.4794689164865737\n",
            "pos_score: tensor(0.9763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4708, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9759, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4779, grad_fn=<MeanBackward0>)\n",
            "Epoch 405: train loss=0.48037669861500226, test_recall=0.2167829889598203\n",
            "pos_score: tensor(0.9763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4678, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9774, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4437, grad_fn=<MeanBackward0>)\n",
            "Epoch 406: train loss=0.47782972804463714\n",
            "pos_score: tensor(0.9764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4687, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "Epoch 407: train loss=0.4791591268751963\n",
            "pos_score: tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4653, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4818, grad_fn=<MeanBackward0>)\n",
            "Epoch 408: train loss=0.4783936558600899\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4706, grad_fn=<MeanBackward0>)\n",
            "Epoch 409: train loss=0.477859588712748\n",
            "pos_score: tensor(0.9770, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4679, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9756, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4765, grad_fn=<MeanBackward0>)\n",
            "Epoch 410: train loss=0.47909856153987146, test_recall=0.21685379400114874\n",
            "pos_score: tensor(0.9772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4609, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9734, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4790, grad_fn=<MeanBackward0>)\n",
            "Epoch 411: train loss=0.4764495673760378\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4692, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9762, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4820, grad_fn=<MeanBackward0>)\n",
            "Epoch 412: train loss=0.4795264956009578\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4633, grad_fn=<MeanBackward0>)\n",
            "Epoch 413: train loss=0.47835877586750786\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4618, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9784, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4724, grad_fn=<MeanBackward0>)\n",
            "Epoch 414: train loss=0.4766344230556852\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4656, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9759, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4691, grad_fn=<MeanBackward0>)\n",
            "Epoch 415: train loss=0.4779163081091569, test_recall=0.21700943386258587\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4641, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9761, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4714, grad_fn=<MeanBackward0>)\n",
            "Epoch 416: train loss=0.47724134341747076\n",
            "pos_score: tensor(0.9775, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4613, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4802, grad_fn=<MeanBackward0>)\n",
            "Epoch 417: train loss=0.47651917432966884\n",
            "pos_score: tensor(0.9777, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4649, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9771, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4665, grad_fn=<MeanBackward0>)\n",
            "Epoch 418: train loss=0.477339728696046\n",
            "pos_score: tensor(0.9774, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4720, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4688, grad_fn=<MeanBackward0>)\n",
            "Epoch 419: train loss=0.4797987697594792\n",
            "pos_score: tensor(0.9776, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4704, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9790, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4421, grad_fn=<MeanBackward0>)\n",
            "Epoch 420: train loss=0.4784513651218708, test_recall=0.21690813197205697\n",
            "pos_score: tensor(0.9780, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4595, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9768, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4700, grad_fn=<MeanBackward0>)\n",
            "Epoch 421: train loss=0.47542562027372237\n",
            "pos_score: tensor(0.9783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4602, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9748, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4786, grad_fn=<MeanBackward0>)\n",
            "Epoch 422: train loss=0.4760646909369436\n",
            "pos_score: tensor(0.9783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4625, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9760, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4605, grad_fn=<MeanBackward0>)\n",
            "Epoch 423: train loss=0.47623780654486675\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4650, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9741, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4799, grad_fn=<MeanBackward0>)\n",
            "Epoch 424: train loss=0.4777053884611834\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4625, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9753, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4736, grad_fn=<MeanBackward0>)\n",
            "Epoch 425: train loss=0.4767601511434185, test_recall=0.2172929727092467\n",
            "pos_score: tensor(0.9783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4629, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9791, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4739, grad_fn=<MeanBackward0>)\n",
            "Epoch 426: train loss=0.4766773397294389\n",
            "pos_score: tensor(0.9785, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4569, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9783, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4738, grad_fn=<MeanBackward0>)\n",
            "Epoch 427: train loss=0.47461357966098744\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4653, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9778, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4552, grad_fn=<MeanBackward0>)\n",
            "Epoch 428: train loss=0.47689316756773314\n",
            "pos_score: tensor(0.9788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4660, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9778, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4580, grad_fn=<MeanBackward0>)\n",
            "Epoch 429: train loss=0.47720654821973174\n",
            "pos_score: tensor(0.9788, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4657, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9782, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4510, grad_fn=<MeanBackward0>)\n",
            "Epoch 430: train loss=0.47669815824194667, test_recall=0.2171943111172965\n",
            "pos_score: tensor(0.9791, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4659, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9764, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4695, grad_fn=<MeanBackward0>)\n",
            "Epoch 431: train loss=0.47744502081872914\n",
            "pos_score: tensor(0.9784, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4656, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4577, grad_fn=<MeanBackward0>)\n",
            "Epoch 432: train loss=0.4769866610415783\n",
            "pos_score: tensor(0.9793, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4642, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9760, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4730, grad_fn=<MeanBackward0>)\n",
            "Epoch 433: train loss=0.4770549278790142\n",
            "pos_score: tensor(0.9793, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4647, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9766, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "Epoch 434: train loss=0.4768538393736168\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9787, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4688, grad_fn=<MeanBackward0>)\n",
            "Epoch 435: train loss=0.473362361342362, test_recall=0.2173282042385219\n",
            "pos_score: tensor(0.9796, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4647, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9769, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4627, grad_fn=<MeanBackward0>)\n",
            "Epoch 436: train loss=0.476642776741952\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4595, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9774, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4566, grad_fn=<MeanBackward0>)\n",
            "Epoch 437: train loss=0.4746507753555924\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4664, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9763, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4872, grad_fn=<MeanBackward0>)\n",
            "Epoch 438: train loss=0.47803733006153065\n",
            "pos_score: tensor(0.9794, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4598, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4712, grad_fn=<MeanBackward0>)\n",
            "Epoch 439: train loss=0.47508521136256765\n",
            "pos_score: tensor(0.9789, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4602, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9850, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4529, grad_fn=<MeanBackward0>)\n",
            "Epoch 440: train loss=0.47465064651417976, test_recall=0.2181611401584002\n",
            "pos_score: tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4632, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9772, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4519, grad_fn=<MeanBackward0>)\n",
            "Epoch 441: train loss=0.4757474865673686\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4657, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4402, grad_fn=<MeanBackward0>)\n",
            "Epoch 442: train loss=0.47594237470724093\n",
            "pos_score: tensor(0.9799, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9786, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4739, grad_fn=<MeanBackward0>)\n",
            "Epoch 443: train loss=0.4765358481858652\n",
            "pos_score: tensor(0.9798, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4665, grad_fn=<MeanBackward0>)\n",
            "Epoch 444: train loss=0.47514402005119943\n",
            "pos_score: tensor(0.9802, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4624, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9781, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4679, grad_fn=<MeanBackward0>)\n",
            "Epoch 445: train loss=0.4759688614928294, test_recall=0.2174331473404205\n",
            "pos_score: tensor(0.9798, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4648, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4316, grad_fn=<MeanBackward0>)\n",
            "Epoch 446: train loss=0.47509392014709423\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4676, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4468, grad_fn=<MeanBackward0>)\n",
            "Epoch 447: train loss=0.4767892166554481\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4572, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9789, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4648, grad_fn=<MeanBackward0>)\n",
            "Epoch 448: train loss=0.47387459991809366\n",
            "pos_score: tensor(0.9797, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4649, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9844, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4528, grad_fn=<MeanBackward0>)\n",
            "Epoch 449: train loss=0.4758553937526577\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4621, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9800, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4406, grad_fn=<MeanBackward0>)\n",
            "Epoch 450: train loss=0.4746987658325724, test_recall=0.2169201569720889\n",
            "pos_score: tensor(0.9806, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4597, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4498, grad_fn=<MeanBackward0>)\n",
            "Epoch 451: train loss=0.4741468689271942\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4604, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4807, grad_fn=<MeanBackward0>)\n",
            "Epoch 452: train loss=0.47569059933827323\n",
            "pos_score: tensor(0.9802, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4592, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4444, grad_fn=<MeanBackward0>)\n",
            "Epoch 453: train loss=0.47357139214902727\n",
            "pos_score: tensor(0.9808, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4642, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4588, grad_fn=<MeanBackward0>)\n",
            "Epoch 454: train loss=0.475969901922926\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4606, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4677, grad_fn=<MeanBackward0>)\n",
            "Epoch 455: train loss=0.47513956966518117, test_recall=0.21699062931605118\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4603, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9801, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4674, grad_fn=<MeanBackward0>)\n",
            "Epoch 456: train loss=0.4749396579103072\n",
            "pos_score: tensor(0.9809, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9816, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4562, grad_fn=<MeanBackward0>)\n",
            "Epoch 457: train loss=0.47560769728977975\n",
            "pos_score: tensor(0.9812, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4636, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9793, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4717, grad_fn=<MeanBackward0>)\n",
            "Epoch 458: train loss=0.4761978181581275\n",
            "pos_score: tensor(0.9813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4590, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9787, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4734, grad_fn=<MeanBackward0>)\n",
            "Epoch 459: train loss=0.4745338725281289\n",
            "pos_score: tensor(0.9813, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4570, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9792, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4676, grad_fn=<MeanBackward0>)\n",
            "Epoch 460: train loss=0.4736100763870801, test_recall=0.21695390864174663\n",
            "pos_score: tensor(0.9812, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4533, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4767, grad_fn=<MeanBackward0>)\n",
            "Epoch 461: train loss=0.4726510990888041\n",
            "pos_score: tensor(0.9812, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4607, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4703, grad_fn=<MeanBackward0>)\n",
            "Epoch 462: train loss=0.47502232717987675\n",
            "pos_score: tensor(0.9814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4610, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9810, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4491, grad_fn=<MeanBackward0>)\n",
            "Epoch 463: train loss=0.47453031710989146\n",
            "pos_score: tensor(0.9815, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4617, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9807, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4393, grad_fn=<MeanBackward0>)\n",
            "Epoch 464: train loss=0.47436606620452737\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4552, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4426, grad_fn=<MeanBackward0>)\n",
            "Epoch 465: train loss=0.4721052309002809, test_recall=0.21815048611349186\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4645, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9811, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4540, grad_fn=<MeanBackward0>)\n",
            "Epoch 466: train loss=0.475743796460204\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4548, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9817, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4635, grad_fn=<MeanBackward0>)\n",
            "Epoch 467: train loss=0.4725444672421133\n",
            "pos_score: tensor(0.9820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4651, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9795, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4666, grad_fn=<MeanBackward0>)\n",
            "Epoch 468: train loss=0.47632165508280305\n",
            "pos_score: tensor(0.9820, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4571, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4653, grad_fn=<MeanBackward0>)\n",
            "Epoch 469: train loss=0.4732713476382269\n",
            "pos_score: tensor(0.9821, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4603, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9796, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4743, grad_fn=<MeanBackward0>)\n",
            "Epoch 470: train loss=0.47460028309934404, test_recall=0.21791207352936454\n",
            "pos_score: tensor(0.9823, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4538, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9778, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4863, grad_fn=<MeanBackward0>)\n",
            "Epoch 471: train loss=0.4728533229571861\n",
            "pos_score: tensor(0.9819, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4617, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4580, grad_fn=<MeanBackward0>)\n",
            "Epoch 472: train loss=0.47465610955950305\n",
            "pos_score: tensor(0.9818, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4633, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4492, grad_fn=<MeanBackward0>)\n",
            "Epoch 473: train loss=0.4748617699780359\n",
            "pos_score: tensor(0.9821, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4554, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4775, grad_fn=<MeanBackward0>)\n",
            "Epoch 474: train loss=0.473231360926128\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4551, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9804, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4646, grad_fn=<MeanBackward0>)\n",
            "Epoch 475: train loss=0.472713124985004, test_recall=0.21746464623629966\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4576, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9805, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4685, grad_fn=<MeanBackward0>)\n",
            "Epoch 476: train loss=0.4737398366047091\n",
            "pos_score: tensor(0.9823, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4532, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4464, grad_fn=<MeanBackward0>)\n",
            "Epoch 477: train loss=0.4712850150622448\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4565, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4837, grad_fn=<MeanBackward0>)\n",
            "Epoch 478: train loss=0.47350766520654547\n",
            "pos_score: tensor(0.9826, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4595, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9823, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4504, grad_fn=<MeanBackward0>)\n",
            "Epoch 479: train loss=0.4735807557963497\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4593, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9796, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4673, grad_fn=<MeanBackward0>)\n",
            "Epoch 480: train loss=0.47406098684255565, test_recall=0.21661494597384773\n",
            "pos_score: tensor(0.9828, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4577, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9819, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4822, grad_fn=<MeanBackward0>)\n",
            "Epoch 481: train loss=0.47399512313356335\n",
            "pos_score: tensor(0.9827, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4615, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9828, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4569, grad_fn=<MeanBackward0>)\n",
            "Epoch 482: train loss=0.4746075087133905\n",
            "pos_score: tensor(0.9826, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4627, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9839, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4361, grad_fn=<MeanBackward0>)\n",
            "Epoch 483: train loss=0.47384064880181714\n",
            "pos_score: tensor(0.9831, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4600, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9803, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4695, grad_fn=<MeanBackward0>)\n",
            "Epoch 484: train loss=0.47429071623081437\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4563, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4609, grad_fn=<MeanBackward0>)\n",
            "Epoch 485: train loss=0.4727618638850118, test_recall=0.2166300372954694\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4556, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9814, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4591, grad_fn=<MeanBackward0>)\n",
            "Epoch 486: train loss=0.47234524514098153\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4577, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4361, grad_fn=<MeanBackward0>)\n",
            "Epoch 487: train loss=0.4721975872345325\n",
            "pos_score: tensor(0.9832, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4590, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9825, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4613, grad_fn=<MeanBackward0>)\n",
            "Epoch 488: train loss=0.47361337431858586\n",
            "pos_score: tensor(0.9830, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4598, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9850, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4742, grad_fn=<MeanBackward0>)\n",
            "Epoch 489: train loss=0.47430078599982894\n",
            "pos_score: tensor(0.9834, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4556, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9824, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4812, grad_fn=<MeanBackward0>)\n",
            "Epoch 490: train loss=0.47300821748638266, test_recall=0.2171147501962897\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4530, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9822, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4602, grad_fn=<MeanBackward0>)\n",
            "Epoch 491: train loss=0.47146452016807855\n",
            "pos_score: tensor(0.9836, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4587, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9821, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4481, grad_fn=<MeanBackward0>)\n",
            "Epoch 492: train loss=0.47301522924062656\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4526, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9829, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4459, grad_fn=<MeanBackward0>)\n",
            "Epoch 493: train loss=0.4708210544211878\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4531, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9842, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4592, grad_fn=<MeanBackward0>)\n",
            "Epoch 494: train loss=0.471448207991047\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4582, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9826, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4682, grad_fn=<MeanBackward0>)\n",
            "Epoch 495: train loss=0.47348949694369935, test_recall=0.21715154294934774\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4637, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9852, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4554, grad_fn=<MeanBackward0>)\n",
            "Epoch 496: train loss=0.4747298348497475\n",
            "pos_score: tensor(0.9835, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4592, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9855, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4531, grad_fn=<MeanBackward0>)\n",
            "Epoch 497: train loss=0.4732788726363877\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4543, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9847, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4593, grad_fn=<MeanBackward0>)\n",
            "Epoch 498: train loss=0.47174768445758164\n",
            "pos_score: tensor(0.9837, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4586, grad_fn=<MeanBackward0>)\n",
            "pos_score: tensor(0.9853, grad_fn=<MeanBackward0>)\n",
            "neg_score: tensor(0.4570, grad_fn=<MeanBackward0>)\n",
            "Epoch 499: train loss=0.4730565975623502\n",
            "\n",
            "Test set recall@k: 0.21643934579966037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the uniform metric"
      ],
      "metadata": {
        "id": "edF6NYISbbjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_car(whole,pred,num):\n",
        "  # ground truth\n",
        "  src = pd.read_csv(whole, sep =' ', header = None)\n",
        "  src.columns = ['src','dst','num']\n",
        "  src_record = defaultdict(list)\n",
        "  for i in range(src.shape[0]):\n",
        "    src_record[src.loc[i,'src']].append(src.loc[i,'dst'] + num)\n",
        "  # top k result\n",
        "  topk_record = {}\n",
        "  for i in list(pred.keys()):\n",
        "    topk_record[i.item()] = list(pred[i][1]['top_k'])\n",
        "  # calculate \n",
        "  record_accr = {}\n",
        "  for i in list(topk_record.keys()):\n",
        "    ground_truth = src_record[i]\n",
        "    top_k = topk_record[i]\n",
        "    record_accr[i] = len(set(ground_truth).intersection(set(top_k)))/len(ground_truth)\n",
        "  return record_accr , np.mean(list(record_accr.values()))"
      ],
      "metadata": {
        "id": "x3e1WHulbd5k"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_recall_bi, result_bi = test(gnn_bi, test_mp_bi, test_loader_bi, k, device, None, None,flag = 0)\n",
        "test_recall_bi_55, result_bi_55 = test(gnn_bi_55, test_mp_bi_55, test_loader_bi_55, k, device, None, None,flag = 0)\n",
        "test_recall_is, result_is = test(gnn_is, test_mp_is, test_loader_is, k, device, None, None,flag = 0)\n",
        "test_recall_is_55, result_is_55 = test(gnn_is_55, test_mp_is_55, test_loader_is_55, k, device, None, None,flag = 0)"
      ],
      "metadata": {
        "id": "8cyCMOU1ckEv"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buyer_all_accr, bi_accr = cal_car('buyer_item.txt',result_bi, 8922)\n",
        "item_all_accr, is_accr = cal_car('item_seller.txt',result_is, 3119)\n",
        "buyer_all_accr_55, bi_accr_55 = cal_car('buyer_item.txt',result_bi_55, 8922)\n",
        "item_all_accr_55, is_accr_55 = cal_car('item_seller.txt',result_is_55, 3119)\n",
        "print(bi_accr)\n",
        "print(is_accr)\n",
        "print(bi_accr_55)\n",
        "print(is_accr_55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV0Romp0fg4D",
        "outputId": "e8adf72e-0b79-4ff6-91d5-fa7ebc0817ac"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4787933020669268\n",
            "0.5132386782106615\n",
            "0.3891466503329534\n",
            "0.3910483389929552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine buyer-item and item-seller and calculate the combined metric"
      ],
      "metadata": {
        "id": "WNtzvu5qlc32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_model_result(res):\n",
        "  gd = {}\n",
        "  tk = {}\n",
        "  overlap = {}\n",
        "  for i in list(res.keys()):\n",
        "    gd[i.item()] = list(res[i][0]['ground_truth'])\n",
        "    tk[i.item()] = list(res[i][1]['top_k'])\n",
        "    overlap[i.item()] = list(set(res[i][0]['ground_truth']).intersection(set(res[i][1]['top_k'])))\n",
        "  return gd,tk,overlap"
      ],
      "metadata": {
        "id": "kvePxjj9nRak"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcualte_combin_accr(buyer_result, buyer_accr, item_accr):\n",
        "  # find all buyer have successfully recommended items\n",
        "  _,_,overlap_bi = process_model_result(buyer_result)\n",
        "  qualified_key = []\n",
        "  for i in list(overlap_bi.keys()):\n",
        "    if overlap_bi[i]:\n",
        "      qualified_key.append(i)\n",
        "\n",
        "  # record success probability for all buyers\n",
        "  bis_accr = []\n",
        "  # all items have success probability\n",
        "  item_has_accr = [t+8922 for t in list(item_accr.keys())]\n",
        "\n",
        "  # check whether all successfully recommender items have success probability\n",
        "  for i in qualified_key:\n",
        "    ground_truth = overlap_bi[i]\n",
        "    # some recommended items have no success probability\n",
        "    if not set(ground_truth).issubset(set(item_has_accr)):\n",
        "      continue\n",
        "\n",
        "    item_accr_record = 0\n",
        "    for t in ground_truth:\n",
        "      item_accr_record+=item_accr[t-8922]\n",
        "    item_accr_record /= len(ground_truth)\n",
        "    bis_accr.append(buyer_accr[i]*item_accr_record)\n",
        "  return np.mean(bis_accr)"
      ],
      "metadata": {
        "id": "yT7TwgOan-wQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcualte_combin_accr(result_bi,buyer_all_accr,item_all_accr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V87jGS4lpBjm",
        "outputId": "6a452db4-3627-4832-d964-6d6c038a9b06"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19917765315060426"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calcualte_combin_accr(result_bi_55,buyer_all_accr_55,item_all_accr_55)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j7W9ogLpIG5",
        "outputId": "41d9bb9b-a030-4830-c1bd-aa11bc0c793a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26018647195227407"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw bipartite graphs"
      ],
      "metadata": {
        "id": "Ex6LPeBaVjiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all unique connected edges\n",
        "def process_edge_index(src,num):\n",
        "  record_connected = defaultdict(list)\n",
        "  edge_num = src.numpy().shape[1]\n",
        "  for i in range(edge_num):\n",
        "    one_edge = src.numpy()[:,i]\n",
        "    fir = one_edge[0]\n",
        "    sec = one_edge[1]\n",
        "    if fir < num:\n",
        "      record_connected[fir].append(sec)\n",
        "    else:\n",
        "      record_connected[sec].append(fir)\n",
        "  # remove duplicate\n",
        "  record_connect_uni = {}\n",
        "  for i in list(record_connected.keys()):\n",
        "    record_connect_uni[i] = list(set(record_connected[i]))\n",
        "  return record_connect_uni"
      ],
      "metadata": {
        "id": "fioyj2gOVrsr"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_sample_for_plot(con,n_con, num, res_bi):\n",
        "  attrs = {}\n",
        "  res_bi_key_f = []\n",
        "  for i in list(res_bi.keys()):\n",
        "    if len(res_bi[i]) ==1 :\n",
        "      res_bi_key_f.append(i)\n",
        "  \n",
        "  srcs = list(set(n_con.keys()).intersection(set(con.keys())).intersection(set(res_bi_key_f)))\n",
        "  fir = []\n",
        "  sec = []\n",
        "  predicted = {}\n",
        "  #srcs = list(n_con.keys())\n",
        "  for i in range(num):\n",
        "    src = srcs[i]\n",
        "    fir.append(src)\n",
        "    # existing edges\n",
        "    for i in con[src]:\n",
        "      attrs[(src,i)] = {'color':'green','width':0.3}\n",
        "      predicted[(src,i)] = {'color':'green','width':0.3}\n",
        "      sec.append(i)\n",
        "    # ground truth\n",
        "    for i in n_con[src]:\n",
        "      attrs[(src,i)] = {'color':'orange','width':1.5}\n",
        "      predicted[(src,i)] = {'color':'orange','width':1.5}\n",
        "      sec.append(i)\n",
        "    # correctly predicted connections\n",
        "    for i in res_bi[src]:\n",
        "      predicted[(src,i)] = {'color':'red','width':1.5}\n",
        "    \n",
        "  return predicted, attrs,fir, list(set(sec))"
      ],
      "metadata": {
        "id": "LRNEgQj-WFm1"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connected_edge = process_edge_index(test_split_bi.edge_index, 8922)\n",
        "not_connected_edge = process_edge_index(test_split_bi.edge_label_index, 8922)"
      ],
      "metadata": {
        "id": "y_CvK0V4WVii"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,_,op_bi = process_model_result(result_bi)"
      ],
      "metadata": {
        "id": "SLYPUsWjWoH3"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_pre,draw_r, draw_fir, draw_sec = draw_sample_for_plot(connected_edge, not_connected_edge,5,op_bi)"
      ],
      "metadata": {
        "id": "0DBUUuRtWZk6"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "G.add_nodes_from(draw_fir, bipartite=0)\n",
        "G.add_nodes_from(draw_sec,bipartite=1)\n",
        "#G.add_edges_from([(16, 8964), (501, 9252), (629, 9759), (729, 9925), (4774, 10142)])\n",
        "G.add_edges_from(list(draw_r.keys()))\n",
        "nx.set_edge_attributes(G, draw_r)\n",
        "bipartite.is_bipartite(G)\n",
        "color_attr = nx.get_edge_attributes(G, \"color\")\n",
        "width_attr = nx.get_edge_attributes(G, \"width\")\n",
        "colors = []\n",
        "widths = []\n",
        "for i in list(G.edges):\n",
        "  colors.append(color_attr[i])\n",
        "  widths.append(width_attr[i])\n",
        "f = plt.figure()\n",
        "nx.draw_networkx(G, pos = nx.drawing.layout.bipartite_layout(G, draw_fir), width = widths, node_size = 30,font_size = 1,edge_color= colors,ax=f.add_subplot(111))\n",
        "f.savefig(\"graph_before_pre.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "yZ39EdHiW0KQ",
        "outputId": "a05c2253-4fad-40e9-f7b4-7739ea6b4e84"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "G.add_nodes_from(draw_fir, bipartite=0)\n",
        "G.add_nodes_from(draw_sec,bipartite=1)\n",
        "#G.add_edges_from([(16, 8964), (501, 9252), (629, 9759), (729, 9925), (4774, 10142)])\n",
        "G.add_edges_from(list(draw_r.keys()))\n",
        "nx.set_edge_attributes(G, draw_pre)\n",
        "bipartite.is_bipartite(G)\n",
        "color_attr = nx.get_edge_attributes(G, \"color\")\n",
        "width_attr = nx.get_edge_attributes(G, \"width\")\n",
        "colors = []\n",
        "widths = []\n",
        "for i in list(G.edges):\n",
        "  colors.append(color_attr[i])\n",
        "  widths.append(width_attr[i])\n",
        "\n",
        "f = plt.figure()\n",
        "nx.draw_networkx(G, pos = nx.drawing.layout.bipartite_layout(G, draw_fir), width = widths, node_size = 30,font_size = 1,edge_color= colors,ax=f.add_subplot(111))\n",
        "f.savefig(\"graph_after_pre.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "OosEMaH4W5_R",
        "outputId": "fd953266-d669-42e0-d229-37d71f860af5"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}